{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1000001",
   "metadata": {},
   "source": [
    "# Chapter 30: Advanced Data Formats\n",
    "\n",
    "This notebook covers advanced data processing patterns: CSV dialects and quoting, binary data packing with `struct`, property list files with `plistlib`, and data validation techniques.\n",
    "\n",
    "## Key Concepts\n",
    "- **CSV dialects**: Customizing delimiters, quoting, and escaping for non-standard CSV\n",
    "- **struct module**: Packing and unpacking binary data with format strings\n",
    "- **plistlib**: Reading and writing Apple property list files\n",
    "- **Data validation**: Verifying data integrity after parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000002",
   "metadata": {},
   "source": [
    "## Section 1: CSV Dialects and Custom Delimiters\n",
    "\n",
    "The `csv` module supports more than just comma-separated files. You can customize the delimiter, quoting behavior, and line terminators using dialects or keyword arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import io\n",
    "\n",
    "# Pipe-delimited data (common in legacy systems)\n",
    "pipe_data: str = \"name|age|city\\nAlice|30|NYC\\nBob|25|LA\"\n",
    "\n",
    "reader = csv.DictReader(io.StringIO(pipe_data), delimiter=\"|\")\n",
    "rows: list[dict[str, str]] = list(reader)\n",
    "\n",
    "print(f\"Number of rows: {len(rows)}\")\n",
    "for row in rows:\n",
    "    print(f\"  {row['name']}, age {row['age']}, lives in {row['city']}\")\n",
    "\n",
    "# Verify specific values\n",
    "print(f\"\\nFirst name: {rows[0]['name']}\")\n",
    "print(f\"Second city: {rows[1]['city']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registering a custom dialect for reuse\n",
    "csv.register_dialect(\n",
    "    \"pipes\",\n",
    "    delimiter=\"|\",\n",
    "    quoting=csv.QUOTE_MINIMAL,\n",
    "    lineterminator=\"\\n\",\n",
    ")\n",
    "\n",
    "# Write using the custom dialect\n",
    "output = io.StringIO()\n",
    "writer = csv.writer(output, dialect=\"pipes\")\n",
    "writer.writerow([\"product\", \"price\", \"quantity\"])\n",
    "writer.writerow([\"Widget\", \"9.99\", \"100\"])\n",
    "writer.writerow([\"Gadget\", \"19.99\", \"50\"])\n",
    "\n",
    "result: str = output.getvalue()\n",
    "print(\"Custom dialect output:\")\n",
    "print(result)\n",
    "\n",
    "# Read it back with the same dialect\n",
    "reader = csv.DictReader(io.StringIO(result), dialect=\"pipes\")\n",
    "for row in reader:\n",
    "    print(f\"  {row['product']}: ${row['price']} x {row['quantity']}\")\n",
    "\n",
    "# Clean up\n",
    "csv.unregister_dialect(\"pipes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV quoting handles fields with special characters\n",
    "output = io.StringIO()\n",
    "writer = csv.writer(output)\n",
    "writer.writerow([\"name\", \"note\"])\n",
    "writer.writerow([\"Alice\", 'She said \"hello\"'])\n",
    "writer.writerow([\"Bob\", \"Line1\\nLine2\"])\n",
    "writer.writerow([\"Charlie\", \"simple\"])\n",
    "\n",
    "content: str = output.getvalue()\n",
    "print(\"CSV with special characters:\")\n",
    "print(repr(content))\n",
    "print()\n",
    "print(content)\n",
    "\n",
    "# Embedded quotes are doubled\n",
    "print(f\"Contains doubled quotes: {'\"\"hello\"\"' in content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different quoting strategies\n",
    "data_rows: list[list[str]] = [\n",
    "    [\"name\", \"value\"],\n",
    "    [\"Alice\", \"100\"],\n",
    "    [\"Bob\", \"has, comma\"],\n",
    "]\n",
    "\n",
    "# QUOTE_MINIMAL: only quote when necessary (default)\n",
    "buf = io.StringIO()\n",
    "csv.writer(buf, quoting=csv.QUOTE_MINIMAL).writerows(data_rows)\n",
    "print(f\"QUOTE_MINIMAL:\\n{buf.getvalue()}\")\n",
    "\n",
    "# QUOTE_ALL: quote every field\n",
    "buf = io.StringIO()\n",
    "csv.writer(buf, quoting=csv.QUOTE_ALL).writerows(data_rows)\n",
    "print(f\"QUOTE_ALL:\\n{buf.getvalue()}\")\n",
    "\n",
    "# QUOTE_NONNUMERIC: quote non-numeric fields\n",
    "buf = io.StringIO()\n",
    "csv.writer(buf, quoting=csv.QUOTE_NONNUMERIC).writerows(data_rows)\n",
    "print(f\"QUOTE_NONNUMERIC:\\n{buf.getvalue()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000007",
   "metadata": {},
   "source": [
    "## Section 2: Binary Data with struct\n",
    "\n",
    "The `struct` module converts between Python values and C-style binary data. This is essential for working with binary file formats, network protocols, and hardware interfaces.\n",
    "\n",
    "Format characters:\n",
    "- `>` big-endian, `<` little-endian, `!` network byte order\n",
    "- `h` short (2 bytes), `i` int (4 bytes), `q` long long (8 bytes)\n",
    "- `f` float (4 bytes), `d` double (8 bytes)\n",
    "- `s` char[] (string), `?` bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "# Pack a short integer and a float (big-endian)\n",
    "packed: bytes = struct.pack(\">hf\", 42, 3.14)\n",
    "\n",
    "print(f\"Packed bytes: {packed}\")\n",
    "print(f\"Hex: {packed.hex()}\")\n",
    "print(f\"Length: {len(packed)} bytes\")\n",
    "print(f\"Is bytes: {isinstance(packed, bytes)}\")\n",
    "\n",
    "# Unpack back to Python values\n",
    "short_val: int\n",
    "float_val: float\n",
    "short_val, float_val = struct.unpack(\">hf\", packed)\n",
    "\n",
    "print(f\"\\nUnpacked short: {short_val}\")\n",
    "print(f\"Unpacked float: {float_val:.4f}\")\n",
    "print(f\"Float close to 3.14: {abs(float_val - 3.14) < 0.01}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcsize tells you how many bytes a format requires\n",
    "formats: dict[str, str] = {\n",
    "    \">i\": \"int (4 bytes)\",\n",
    "    \">d\": \"double (8 bytes)\",\n",
    "    \">hh\": \"two shorts (4 bytes)\",\n",
    "    \">f\": \"float (4 bytes)\",\n",
    "    \">q\": \"long long (8 bytes)\",\n",
    "    \">10s\": \"10-char string (10 bytes)\",\n",
    "    \">?ii\": \"bool + two ints (9 bytes)\",\n",
    "}\n",
    "\n",
    "print(\"Format sizes:\")\n",
    "for fmt, desc in formats.items():\n",
    "    size: int = struct.calcsize(fmt)\n",
    "    print(f\"  {fmt:>8s} = {size:2d} bytes  ({desc})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practical example: packing a simple binary message header\n",
    "# Format: version(byte) + message_type(short) + payload_length(int) + checksum(int)\n",
    "HEADER_FORMAT: str = \">BHI I\"  # Spaces are allowed for readability\n",
    "HEADER_SIZE: int = struct.calcsize(HEADER_FORMAT)\n",
    "\n",
    "# Pack a header\n",
    "version: int = 1\n",
    "msg_type: int = 42\n",
    "payload_len: int = 256\n",
    "checksum: int = 0xDEADBEEF\n",
    "\n",
    "header: bytes = struct.pack(HEADER_FORMAT, version, msg_type, payload_len, checksum)\n",
    "print(f\"Header ({HEADER_SIZE} bytes): {header.hex()}\")\n",
    "\n",
    "# Unpack the header\n",
    "v, mt, pl, cs = struct.unpack(HEADER_FORMAT, header)\n",
    "print(f\"\\nVersion: {v}\")\n",
    "print(f\"Message type: {mt}\")\n",
    "print(f\"Payload length: {pl}\")\n",
    "print(f\"Checksum: 0x{cs:08X}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Struct with iter_unpack for repeated structures\n",
    "# Pack a sequence of (x, y) coordinate pairs\n",
    "POINT_FORMAT: str = \">ff\"  # Two floats per point\n",
    "\n",
    "points: list[tuple[float, float]] = [(1.0, 2.0), (3.0, 4.0), (5.0, 6.0)]\n",
    "packed_points: bytes = b\"\".join(\n",
    "    struct.pack(POINT_FORMAT, x, y) for x, y in points\n",
    ")\n",
    "\n",
    "print(f\"Packed {len(points)} points in {len(packed_points)} bytes\")\n",
    "\n",
    "# Unpack all points at once using iter_unpack\n",
    "unpacked: list[tuple[float, float]] = [\n",
    "    (round(x, 1), round(y, 1))\n",
    "    for x, y in struct.iter_unpack(POINT_FORMAT, packed_points)\n",
    "]\n",
    "print(f\"Unpacked points: {unpacked}\")\n",
    "print(f\"Match original: {unpacked == points}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000012",
   "metadata": {},
   "source": [
    "## Section 3: Property Lists with plistlib\n",
    "\n",
    "The `plistlib` module reads and writes Apple property list files, commonly used in macOS and iOS for configuration and data storage. Plists support dicts, lists, strings, ints, floats, booleans, bytes, and datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plistlib\n",
    "from datetime import datetime\n",
    "\n",
    "# Create a property list\n",
    "app_config: dict = {\n",
    "    \"AppName\": \"MyApp\",\n",
    "    \"Version\": 2,\n",
    "    \"Debug\": False,\n",
    "    \"MaxRetries\": 3,\n",
    "    \"Timeout\": 30.5,\n",
    "    \"Features\": [\"dark_mode\", \"notifications\", \"sync\"],\n",
    "    \"BuildDate\": datetime(2025, 1, 15, 12, 0, 0),\n",
    "}\n",
    "\n",
    "# Serialize to XML plist format\n",
    "plist_bytes: bytes = plistlib.dumps(app_config, fmt=plistlib.FMT_XML)\n",
    "print(\"XML plist output:\")\n",
    "print(plist_bytes.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the plist back\n",
    "loaded: dict = plistlib.loads(plist_bytes)\n",
    "\n",
    "print(\"Loaded plist data:\")\n",
    "for key, value in loaded.items():\n",
    "    print(f\"  {key}: {value!r} ({type(value).__name__})\")\n",
    "\n",
    "# Types are preserved\n",
    "print(f\"\\nVersion is int: {isinstance(loaded['Version'], int)}\")\n",
    "print(f\"Debug is bool: {isinstance(loaded['Debug'], bool)}\")\n",
    "print(f\"Features is list: {isinstance(loaded['Features'], list)}\")\n",
    "print(f\"BuildDate is datetime: {isinstance(loaded['BuildDate'], datetime)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary plist format (more compact)\n",
    "binary_plist: bytes = plistlib.dumps(app_config, fmt=plistlib.FMT_BINARY)\n",
    "xml_plist: bytes = plistlib.dumps(app_config, fmt=plistlib.FMT_XML)\n",
    "\n",
    "print(f\"XML plist size:    {len(xml_plist)} bytes\")\n",
    "print(f\"Binary plist size: {len(binary_plist)} bytes\")\n",
    "print(f\"Savings: {len(xml_plist) - len(binary_plist)} bytes\")\n",
    "\n",
    "# Both formats parse to identical data\n",
    "from_binary: dict = plistlib.loads(binary_plist)\n",
    "from_xml: dict = plistlib.loads(xml_plist)\n",
    "print(f\"\\nBinary == XML: {from_binary == from_xml}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000016",
   "metadata": {},
   "source": [
    "## Section 4: Data Validation Patterns\n",
    "\n",
    "After parsing data from any format (CSV, XML, config files), you should validate it before use. Here are common patterns for data validation in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "def validate_record(record: dict[str, str]) -> list[str]:\n",
    "    \"\"\"Validate a parsed CSV record and return a list of errors.\"\"\"\n",
    "    errors: list[str] = []\n",
    "\n",
    "    # Required fields\n",
    "    required: list[str] = [\"name\", \"age\", \"email\"]\n",
    "    for field in required:\n",
    "        if field not in record or not record[field].strip():\n",
    "            errors.append(f\"Missing required field: {field}\")\n",
    "\n",
    "    # Type validation\n",
    "    if \"age\" in record and record[\"age\"].strip():\n",
    "        try:\n",
    "            age: int = int(record[\"age\"])\n",
    "            if not (0 <= age <= 150):\n",
    "                errors.append(f\"Age out of range: {age}\")\n",
    "        except ValueError:\n",
    "            errors.append(f\"Invalid age: {record['age']}\")\n",
    "\n",
    "    # Format validation\n",
    "    if \"email\" in record and record[\"email\"].strip():\n",
    "        if \"@\" not in record[\"email\"]:\n",
    "            errors.append(f\"Invalid email: {record['email']}\")\n",
    "\n",
    "    return errors\n",
    "\n",
    "\n",
    "# Test with various records\n",
    "test_records: list[dict[str, str]] = [\n",
    "    {\"name\": \"Alice\", \"age\": \"30\", \"email\": \"alice@example.com\"},\n",
    "    {\"name\": \"Bob\", \"age\": \"abc\", \"email\": \"bob@example.com\"},\n",
    "    {\"name\": \"\", \"age\": \"25\", \"email\": \"no-at-sign\"},\n",
    "    {\"name\": \"Diana\", \"age\": \"200\", \"email\": \"diana@example.com\"},\n",
    "]\n",
    "\n",
    "for record in test_records:\n",
    "    errors = validate_record(record)\n",
    "    name: str = record.get(\"name\", \"(empty)\")\n",
    "    if errors:\n",
    "        print(f\"{name or '(empty)'}: INVALID - {errors}\")\n",
    "    else:\n",
    "        print(f\"{name}: VALID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ValidatedConfig:\n",
    "    \"\"\"A configuration object that validates its fields on creation.\"\"\"\n",
    "\n",
    "    host: str\n",
    "    port: int\n",
    "    database: str\n",
    "    pool_size: int = 5\n",
    "    timeout: float = 30.0\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        \"\"\"Validate all fields after initialization.\"\"\"\n",
    "        errors: list[str] = []\n",
    "\n",
    "        if not self.host:\n",
    "            errors.append(\"host cannot be empty\")\n",
    "        if not (1 <= self.port <= 65535):\n",
    "            errors.append(f\"port must be 1-65535, got {self.port}\")\n",
    "        if not self.database:\n",
    "            errors.append(\"database cannot be empty\")\n",
    "        if self.pool_size < 1:\n",
    "            errors.append(f\"pool_size must be >= 1, got {self.pool_size}\")\n",
    "        if self.timeout <= 0:\n",
    "            errors.append(f\"timeout must be > 0, got {self.timeout}\")\n",
    "\n",
    "        if errors:\n",
    "            raise ValueError(f\"Invalid config: {'; '.join(errors)}\")\n",
    "\n",
    "\n",
    "# Valid configuration\n",
    "config = ValidatedConfig(host=\"localhost\", port=5432, database=\"mydb\")\n",
    "print(f\"Valid config: {config}\")\n",
    "\n",
    "# Invalid configurations\n",
    "invalid_cases: list[dict[str, Any]] = [\n",
    "    {\"host\": \"\", \"port\": 5432, \"database\": \"mydb\"},\n",
    "    {\"host\": \"localhost\", \"port\": 99999, \"database\": \"mydb\"},\n",
    "    {\"host\": \"localhost\", \"port\": 5432, \"database\": \"mydb\", \"pool_size\": -1},\n",
    "]\n",
    "\n",
    "for case in invalid_cases:\n",
    "    try:\n",
    "        ValidatedConfig(**case)\n",
    "    except ValueError as e:\n",
    "        print(f\"Rejected: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "def validate_xml_schema(root: ET.Element, required_children: list[str]) -> list[str]:\n",
    "    \"\"\"Basic XML structure validation: check for required child elements.\"\"\"\n",
    "    errors: list[str] = []\n",
    "\n",
    "    for child_tag in required_children:\n",
    "        found: ET.Element | None = root.find(child_tag)\n",
    "        if found is None:\n",
    "            errors.append(f\"Missing required element: <{child_tag}>\")\n",
    "        elif not (found.text and found.text.strip()):\n",
    "            errors.append(f\"Empty required element: <{child_tag}>\")\n",
    "\n",
    "    return errors\n",
    "\n",
    "\n",
    "# Validate XML documents\n",
    "good_xml: str = \"<user><name>Alice</name><email>alice@test.com</email></user>\"\n",
    "bad_xml: str = \"<user><name>Bob</name></user>\"\n",
    "empty_xml: str = \"<user><name></name><email>test@test.com</email></user>\"\n",
    "\n",
    "required: list[str] = [\"name\", \"email\"]\n",
    "\n",
    "for label, xml_str in [(\"Good\", good_xml), (\"Missing\", bad_xml), (\"Empty\", empty_xml)]:\n",
    "    root = ET.fromstring(xml_str)\n",
    "    errors = validate_xml_schema(root, required)\n",
    "    status: str = \"VALID\" if not errors else f\"INVALID: {errors}\"\n",
    "    print(f\"{label}: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000020",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### CSV Dialects\n",
    "- **`delimiter`**: Change separator from comma to pipe, tab, etc.\n",
    "- **`csv.DictReader`/`csv.DictWriter`**: Row-level dict access with headers\n",
    "- **`register_dialect()`**: Define reusable dialect configurations\n",
    "- **Quoting modes**: `QUOTE_MINIMAL`, `QUOTE_ALL`, `QUOTE_NONNUMERIC`\n",
    "- Embedded quotes are doubled: `\"She said \"\"hello\"\"\"` \n",
    "\n",
    "### Binary struct Packing\n",
    "- **`struct.pack(fmt, ...)`**: Convert Python values to bytes\n",
    "- **`struct.unpack(fmt, data)`**: Convert bytes back to Python values\n",
    "- **`struct.calcsize(fmt)`**: Calculate the byte size of a format\n",
    "- **`struct.iter_unpack(fmt, data)`**: Iterate over repeated structures\n",
    "- Byte order: `>` big-endian, `<` little-endian, `!` network\n",
    "\n",
    "### plistlib\n",
    "- **`plistlib.dumps()`/`plistlib.loads()`**: Serialize/deserialize plists\n",
    "- Supports XML (`FMT_XML`) and binary (`FMT_BINARY`) formats\n",
    "- Native types: dict, list, str, int, float, bool, bytes, datetime\n",
    "\n",
    "### Data Validation\n",
    "- Always validate parsed data before use\n",
    "- Check required fields, types, ranges, and formats\n",
    "- Use `dataclass.__post_init__()` for self-validating objects\n",
    "- Return error lists rather than raising on first error for batch validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}