{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# Chapter 41: Thread-Safe Patterns\n",
    "\n",
    "This notebook covers thread-safe data structures and patterns for concurrent programming. You will learn how to use `Queue` for safe inter-thread communication, implement the producer-consumer pattern, manage per-thread state with `threading.local`, and control queue capacity.\n",
    "\n",
    "## Key Concepts\n",
    "- **`Queue`**: Thread-safe FIFO queue for passing data between threads\n",
    "- **Producer-consumer pattern**: Decouple data production from consumption using a queue\n",
    "- **Sentinel values**: Signal termination to consumers via a special value (e.g., `None`)\n",
    "- **`threading.local`**: Per-thread storage where each thread sees its own data\n",
    "- **Queue `maxsize`**: Limit queue capacity to apply backpressure on producers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2d3e4",
   "metadata": {},
   "source": [
    "## Section 1: Queue Basics -- Thread-Safe FIFO\n",
    "\n",
    "The `queue.Queue` class provides a thread-safe FIFO (first-in, first-out) data structure. Multiple threads can safely `put()` and `get()` items without additional locking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "\n",
    "# Basic FIFO queue\n",
    "q: Queue[int] = Queue()\n",
    "\n",
    "# Put items into the queue\n",
    "q.put(1)\n",
    "q.put(2)\n",
    "q.put(3)\n",
    "\n",
    "# Get items in FIFO order\n",
    "first: int = q.get()\n",
    "second: int = q.get()\n",
    "third: int = q.get()\n",
    "\n",
    "print(f\"First: {first}\")\n",
    "print(f\"Second: {second}\")\n",
    "print(f\"Third: {third}\")\n",
    "print(f\"FIFO order correct: {first == 1 and second == 2 and third == 3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e2f3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "\n",
    "# Queue utility methods\n",
    "q: Queue[str] = Queue()\n",
    "\n",
    "print(f\"Empty at start: {q.empty()}\")\n",
    "print(f\"Size at start: {q.qsize()}\")\n",
    "\n",
    "q.put(\"alpha\")\n",
    "q.put(\"beta\")\n",
    "\n",
    "print(f\"\\nAfter adding 2 items:\")\n",
    "print(f\"Empty: {q.empty()}\")\n",
    "print(f\"Size: {q.qsize()}\")\n",
    "\n",
    "# task_done() and join() for tracking completion\n",
    "item: str = q.get()\n",
    "q.task_done()  # Signal that the item has been processed\n",
    "print(f\"\\nProcessed: {item}\")\n",
    "print(f\"Remaining size: {q.qsize()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2a3b4",
   "metadata": {},
   "source": [
    "## Section 2: Queue Timeout and Empty Exception\n",
    "\n",
    "By default, `Queue.get()` blocks until an item is available. You can pass a `timeout` parameter to raise `queue.Empty` if no item arrives within the timeout period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a2b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Empty, Queue\n",
    "\n",
    "q: Queue[int] = Queue()\n",
    "\n",
    "# get() with timeout raises Empty if the queue is empty\n",
    "try:\n",
    "    q.get(timeout=0.01)\n",
    "    print(\"Got an item (unexpected)\")\n",
    "except Empty:\n",
    "    print(\"Caught Empty exception -- queue was empty after timeout\")\n",
    "\n",
    "# Non-blocking get with block=False\n",
    "try:\n",
    "    q.get(block=False)\n",
    "    print(\"Got an item (unexpected)\")\n",
    "except Empty:\n",
    "    print(\"Caught Empty exception -- non-blocking get on empty queue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b3c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Empty, Queue\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Practical pattern: drain a queue with timeout\n",
    "q: Queue[int] = Queue()\n",
    "collected: list[int] = []\n",
    "\n",
    "\n",
    "def delayed_producer() -> None:\n",
    "    \"\"\"Add items to the queue with small delays.\"\"\"\n",
    "    for i in range(3):\n",
    "        time.sleep(0.02)\n",
    "        q.put(i)\n",
    "\n",
    "\n",
    "t: threading.Thread = threading.Thread(target=delayed_producer)\n",
    "t.start()\n",
    "\n",
    "# Collect items with timeout-based polling\n",
    "while True:\n",
    "    try:\n",
    "        item: int = q.get(timeout=0.1)\n",
    "        collected.append(item)\n",
    "    except Empty:\n",
    "        # No more items within timeout\n",
    "        break\n",
    "\n",
    "t.join()\n",
    "\n",
    "print(f\"Collected items: {collected}\")\n",
    "print(f\"All items received: {collected == [0, 1, 2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5",
   "metadata": {},
   "source": [
    "## Section 3: Producer-Consumer Pattern\n",
    "\n",
    "The producer-consumer pattern decouples threads that generate data (producers) from threads that process data (consumers). A `Queue` serves as the buffer between them. A sentinel value (typically `None`) signals the consumer to stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d3e4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from queue import Queue\n",
    "\n",
    "q: Queue[int | None] = Queue()\n",
    "results: list[int] = []\n",
    "lock: threading.Lock = threading.Lock()\n",
    "\n",
    "\n",
    "def producer() -> None:\n",
    "    \"\"\"Produce 5 items, then send a sentinel to stop the consumer.\"\"\"\n",
    "    for i in range(5):\n",
    "        q.put(i)\n",
    "    q.put(None)  # Sentinel signals end of data\n",
    "\n",
    "\n",
    "def consumer() -> None:\n",
    "    \"\"\"Consume items until the sentinel is received.\"\"\"\n",
    "    while True:\n",
    "        item: int | None = q.get()\n",
    "        if item is None:\n",
    "            break\n",
    "        with lock:\n",
    "            results.append(item)\n",
    "\n",
    "\n",
    "t1: threading.Thread = threading.Thread(target=producer)\n",
    "t2: threading.Thread = threading.Thread(target=consumer)\n",
    "t1.start()\n",
    "t2.start()\n",
    "t1.join()\n",
    "t2.join()\n",
    "\n",
    "print(f\"Consumed results: {sorted(results)}\")\n",
    "print(f\"Expected: [0, 1, 2, 3, 4]\")\n",
    "print(f\"Correct: {sorted(results) == [0, 1, 2, 3, 4]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e3f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from queue import Queue\n",
    "\n",
    "# Multiple producers and consumers\n",
    "q: Queue[int | None] = Queue()\n",
    "results: list[int] = []\n",
    "lock: threading.Lock = threading.Lock()\n",
    "NUM_PRODUCERS: int = 2\n",
    "NUM_CONSUMERS: int = 2\n",
    "ITEMS_PER_PRODUCER: int = 5\n",
    "\n",
    "\n",
    "def multi_producer(producer_id: int) -> None:\n",
    "    \"\"\"Produce items tagged with producer ID.\"\"\"\n",
    "    for i in range(ITEMS_PER_PRODUCER):\n",
    "        q.put(producer_id * 100 + i)\n",
    "\n",
    "\n",
    "def multi_consumer() -> None:\n",
    "    \"\"\"Consume items until sentinel.\"\"\"\n",
    "    while True:\n",
    "        item: int | None = q.get()\n",
    "        if item is None:\n",
    "            break\n",
    "        with lock:\n",
    "            results.append(item)\n",
    "\n",
    "\n",
    "# Start producers\n",
    "producers: list[threading.Thread] = [\n",
    "    threading.Thread(target=multi_producer, args=(pid,))\n",
    "    for pid in range(NUM_PRODUCERS)\n",
    "]\n",
    "for p in producers:\n",
    "    p.start()\n",
    "for p in producers:\n",
    "    p.join()\n",
    "\n",
    "# Send one sentinel per consumer\n",
    "for _ in range(NUM_CONSUMERS):\n",
    "    q.put(None)\n",
    "\n",
    "# Start consumers\n",
    "consumers: list[threading.Thread] = [\n",
    "    threading.Thread(target=multi_consumer) for _ in range(NUM_CONSUMERS)\n",
    "]\n",
    "for c in consumers:\n",
    "    c.start()\n",
    "for c in consumers:\n",
    "    c.join()\n",
    "\n",
    "print(f\"Total items consumed: {len(results)}\")\n",
    "print(f\"Expected: {NUM_PRODUCERS * ITEMS_PER_PRODUCER}\")\n",
    "print(f\"All items accounted for: {len(results) == NUM_PRODUCERS * ITEMS_PER_PRODUCER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f3a4b5",
   "metadata": {},
   "source": [
    "## Section 4: Queue maxsize -- Backpressure\n",
    "\n",
    "A `Queue` can be created with a `maxsize` to limit the number of items it can hold. When the queue is full, `put()` blocks until space is available. This provides natural backpressure on fast producers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "\n",
    "# Create a queue with maximum size of 2\n",
    "q: Queue[int] = Queue(maxsize=2)\n",
    "\n",
    "q.put(1)\n",
    "q.put(2)\n",
    "\n",
    "print(f\"Queue size: {q.qsize()}\")\n",
    "print(f\"Queue full: {q.full()}\")\n",
    "print(f\"Max size: {q.maxsize}\")\n",
    "\n",
    "# Remove one item to make room\n",
    "removed: int = q.get()\n",
    "print(f\"\\nRemoved: {removed}\")\n",
    "print(f\"Queue full after get: {q.full()}\")\n",
    "print(f\"Queue size: {q.qsize()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Full, Queue\n",
    "\n",
    "# Non-blocking put on a full queue\n",
    "q: Queue[int] = Queue(maxsize=2)\n",
    "q.put(1)\n",
    "q.put(2)\n",
    "\n",
    "# Try to put without blocking\n",
    "try:\n",
    "    q.put(3, block=False)\n",
    "    print(\"Put succeeded (unexpected)\")\n",
    "except Full:\n",
    "    print(\"Caught Full exception -- queue at maxsize\")\n",
    "\n",
    "# Try with timeout\n",
    "try:\n",
    "    q.put(3, timeout=0.01)\n",
    "    print(\"Put succeeded (unexpected)\")\n",
    "except Full:\n",
    "    print(\"Caught Full exception -- queue still full after timeout\")\n",
    "\n",
    "print(f\"\\nQueue size: {q.qsize()}\")\n",
    "print(f\"Queue full: {q.full()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c4d5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "from queue import Queue\n",
    "\n",
    "# Backpressure in action: fast producer, slow consumer\n",
    "q: Queue[int | None] = Queue(maxsize=3)\n",
    "produced_at: list[float] = []\n",
    "consumed_at: list[float] = []\n",
    "start_time: float = time.perf_counter()\n",
    "\n",
    "\n",
    "def fast_producer() -> None:\n",
    "    \"\"\"Produce items as fast as possible.\"\"\"\n",
    "    for i in range(6):\n",
    "        q.put(i)  # Blocks when queue is full\n",
    "        produced_at.append(time.perf_counter() - start_time)\n",
    "    q.put(None)\n",
    "\n",
    "\n",
    "def slow_consumer() -> None:\n",
    "    \"\"\"Consume items slowly.\"\"\"\n",
    "    while True:\n",
    "        item: int | None = q.get()\n",
    "        if item is None:\n",
    "            break\n",
    "        consumed_at.append(time.perf_counter() - start_time)\n",
    "        time.sleep(0.03)  # Slow processing\n",
    "\n",
    "\n",
    "t1: threading.Thread = threading.Thread(target=fast_producer)\n",
    "t2: threading.Thread = threading.Thread(target=slow_consumer)\n",
    "t1.start()\n",
    "t2.start()\n",
    "t1.join()\n",
    "t2.join()\n",
    "\n",
    "print(\"Backpressure demonstration:\")\n",
    "print(f\"Items produced: {len(produced_at)}\")\n",
    "print(f\"Items consumed: {len(consumed_at)}\")\n",
    "print(f\"Producer was slowed by full queue (backpressure applied)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a4b5c6",
   "metadata": {},
   "source": [
    "## Section 5: Thread-Local Storage\n",
    "\n",
    "`threading.local()` creates an object where each thread sees its own independent copy of the data. This is useful for per-thread caches, database connections, or other state that should not be shared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "# Each thread gets its own copy of local.data\n",
    "local: threading.local = threading.local()\n",
    "results: list[int] = []\n",
    "lock: threading.Lock = threading.Lock()\n",
    "\n",
    "\n",
    "def worker(value: int) -> None:\n",
    "    \"\"\"Set thread-local data and verify it persists.\"\"\"\n",
    "    local.data = value\n",
    "    time.sleep(0.01)  # Let other threads run\n",
    "    # Each thread still sees its own value\n",
    "    with lock:\n",
    "        results.append(local.data)\n",
    "\n",
    "\n",
    "threads: list[threading.Thread] = [\n",
    "    threading.Thread(target=worker, args=(i,)) for i in range(4)\n",
    "]\n",
    "for t in threads:\n",
    "    t.start()\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(f\"Results (sorted): {sorted(results)}\")\n",
    "print(f\"Each thread kept its own value: {sorted(results) == [0, 1, 2, 3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e4f5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# Thread-local storage with multiple attributes\n",
    "local: threading.local = threading.local()\n",
    "reports: list[str] = []\n",
    "lock: threading.Lock = threading.Lock()\n",
    "\n",
    "\n",
    "def database_worker(worker_id: int, db_name: str) -> None:\n",
    "    \"\"\"Simulate a worker with its own database connection.\"\"\"\n",
    "    local.worker_id = worker_id\n",
    "    local.db_name = db_name\n",
    "    local.query_count = 0\n",
    "\n",
    "    # Simulate queries\n",
    "    for _ in range(3):\n",
    "        local.query_count += 1\n",
    "\n",
    "    report: str = (\n",
    "        f\"Worker {local.worker_id} on {local.db_name}: \"\n",
    "        f\"{local.query_count} queries\"\n",
    "    )\n",
    "    with lock:\n",
    "        reports.append(report)\n",
    "\n",
    "\n",
    "threads: list[threading.Thread] = [\n",
    "    threading.Thread(target=database_worker, args=(i, f\"db_{i}\"))\n",
    "    for i in range(3)\n",
    "]\n",
    "for t in threads:\n",
    "    t.start()\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "for report in sorted(reports):\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f4a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# Thread-local attributes are not shared\n",
    "local: threading.local = threading.local()\n",
    "local.main_value = \"set in main thread\"\n",
    "\n",
    "child_saw: list[str] = []\n",
    "\n",
    "\n",
    "def child_thread() -> None:\n",
    "    \"\"\"Check if the child thread can see the main thread's local data.\"\"\"\n",
    "    has_attr: bool = hasattr(local, \"main_value\")\n",
    "    child_saw.append(f\"has main_value: {has_attr}\")\n",
    "\n",
    "    # Set our own value\n",
    "    local.child_value = \"set in child thread\"\n",
    "    child_saw.append(f\"child_value: {local.child_value}\")\n",
    "\n",
    "\n",
    "t: threading.Thread = threading.Thread(target=child_thread)\n",
    "t.start()\n",
    "t.join()\n",
    "\n",
    "for msg in child_saw:\n",
    "    print(f\"Child thread: {msg}\")\n",
    "\n",
    "print(f\"\\nMain thread: main_value = {local.main_value}\")\n",
    "print(f\"Main thread: has child_value = {hasattr(local, 'child_value')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b5c6d7",
   "metadata": {},
   "source": [
    "## Section 6: Practical Patterns -- Pipeline with Queues\n",
    "\n",
    "Queues can be chained together to form processing pipelines where each stage runs in its own thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c5d6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from queue import Queue\n",
    "\n",
    "# Two-stage pipeline: generate -> transform -> collect\n",
    "stage1_q: Queue[int | None] = Queue()\n",
    "stage2_q: Queue[str | None] = Queue()\n",
    "final_results: list[str] = []\n",
    "\n",
    "\n",
    "def generator() -> None:\n",
    "    \"\"\"Stage 1: Generate raw numbers.\"\"\"\n",
    "    for i in range(5):\n",
    "        stage1_q.put(i)\n",
    "    stage1_q.put(None)\n",
    "\n",
    "\n",
    "def transformer() -> None:\n",
    "    \"\"\"Stage 2: Transform numbers to formatted strings.\"\"\"\n",
    "    while True:\n",
    "        item: int | None = stage1_q.get()\n",
    "        if item is None:\n",
    "            stage2_q.put(None)\n",
    "            break\n",
    "        stage2_q.put(f\"item-{item:03d}\")\n",
    "\n",
    "\n",
    "def collector() -> None:\n",
    "    \"\"\"Stage 3: Collect final results.\"\"\"\n",
    "    while True:\n",
    "        item: str | None = stage2_q.get()\n",
    "        if item is None:\n",
    "            break\n",
    "        final_results.append(item)\n",
    "\n",
    "\n",
    "threads: list[threading.Thread] = [\n",
    "    threading.Thread(target=generator),\n",
    "    threading.Thread(target=transformer),\n",
    "    threading.Thread(target=collector),\n",
    "]\n",
    "for t in threads:\n",
    "    t.start()\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(f\"Pipeline results: {final_results}\")\n",
    "print(f\"Expected 5 items: {len(final_results) == 5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d5e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from queue import Queue\n",
    "\n",
    "# Worker pool pattern: multiple workers processing from a shared queue\n",
    "task_queue: Queue[int | None] = Queue()\n",
    "results: list[int] = []\n",
    "lock: threading.Lock = threading.Lock()\n",
    "NUM_WORKERS: int = 3\n",
    "\n",
    "\n",
    "def pool_worker(worker_id: int) -> None:\n",
    "    \"\"\"Process tasks from the shared queue.\"\"\"\n",
    "    while True:\n",
    "        task: int | None = task_queue.get()\n",
    "        if task is None:\n",
    "            break\n",
    "        result: int = task * task  # Square the number\n",
    "        with lock:\n",
    "            results.append(result)\n",
    "\n",
    "\n",
    "# Add tasks\n",
    "for i in range(10):\n",
    "    task_queue.put(i)\n",
    "\n",
    "# Add sentinel for each worker\n",
    "for _ in range(NUM_WORKERS):\n",
    "    task_queue.put(None)\n",
    "\n",
    "# Start workers\n",
    "workers: list[threading.Thread] = [\n",
    "    threading.Thread(target=pool_worker, args=(wid,))\n",
    "    for wid in range(NUM_WORKERS)\n",
    "]\n",
    "for w in workers:\n",
    "    w.start()\n",
    "for w in workers:\n",
    "    w.join()\n",
    "\n",
    "print(f\"Results (sorted): {sorted(results)}\")\n",
    "expected: list[int] = [i * i for i in range(10)]\n",
    "print(f\"Expected: {expected}\")\n",
    "print(f\"Correct: {sorted(results) == expected}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7",
   "metadata": {},
   "source": [
    "## Section 7: Other Queue Types\n",
    "\n",
    "The `queue` module also provides `LifoQueue` (stack) and `PriorityQueue` for different ordering needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f5a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import LifoQueue, PriorityQueue\n",
    "\n",
    "# LifoQueue -- last-in, first-out (stack behavior)\n",
    "lifo: LifoQueue[str] = LifoQueue()\n",
    "lifo.put(\"first\")\n",
    "lifo.put(\"second\")\n",
    "lifo.put(\"third\")\n",
    "\n",
    "print(\"LifoQueue (stack order):\")\n",
    "print(f\"  {lifo.get()}\")  # third\n",
    "print(f\"  {lifo.get()}\")  # second\n",
    "print(f\"  {lifo.get()}\")  # first\n",
    "\n",
    "# PriorityQueue -- lowest value first\n",
    "pq: PriorityQueue[tuple[int, str]] = PriorityQueue()\n",
    "pq.put((3, \"low priority\"))\n",
    "pq.put((1, \"high priority\"))\n",
    "pq.put((2, \"medium priority\"))\n",
    "\n",
    "print(\"\\nPriorityQueue (lowest value first):\")\n",
    "while not pq.empty():\n",
    "    priority, message = pq.get()\n",
    "    print(f\"  Priority {priority}: {message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a5b6c7",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Queue Basics\n",
    "- **`Queue()`**: Thread-safe FIFO queue; `put()` adds items, `get()` removes them in order\n",
    "- **`Queue(maxsize=N)`**: Limits capacity; `put()` blocks when full, providing backpressure\n",
    "- **`q.full()`** / **`q.empty()`** / **`q.qsize()`**: Check queue state (approximate in threaded code)\n",
    "- **`q.get(timeout=N)`**: Raises `queue.Empty` if no item is available within `N` seconds\n",
    "\n",
    "### Producer-Consumer Pattern\n",
    "- Producers call `q.put(item)` to add work; consumers call `q.get()` to retrieve it\n",
    "- Use a **sentinel value** (e.g., `None`) to signal consumers to stop\n",
    "- For multiple consumers, send one sentinel per consumer\n",
    "\n",
    "### Thread-Local Storage\n",
    "- **`threading.local()`**: Each thread gets its own independent copy of attributes\n",
    "- Attributes set in one thread are invisible to other threads\n",
    "- Useful for per-thread caches, connections, or context\n",
    "\n",
    "### Additional Queue Types\n",
    "- **`LifoQueue`**: Last-in, first-out (stack) ordering\n",
    "- **`PriorityQueue`**: Items are retrieved in priority order (lowest value first)\n",
    "\n",
    "### Best Practices\n",
    "- Always use sentinel values or `task_done()` / `join()` for clean shutdown\n",
    "- Use `maxsize` to prevent unbounded memory growth from fast producers\n",
    "- Prefer `threading.local()` over manual per-thread dictionaries for thread-specific state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}