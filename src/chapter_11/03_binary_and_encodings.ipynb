{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 11: Binary Data and Encodings\n",
    "\n",
    "This notebook covers the practical side of working with binary data and text encodings. We explore how UTF-8 and other encodings represent characters as bytes, how to handle encoding errors gracefully, and how to work with binary data using `struct` and `memoryview`.\n",
    "\n",
    "## Key Concepts\n",
    "- **UTF-8**: Variable-length encoding (1-4 bytes per character), dominant on the web\n",
    "- **Encoding error handlers**: `strict`, `replace`, `ignore`, `xmlcharrefreplace`\n",
    "- **Latin-1**: Bijective encoding mapping every byte 0-255 to a character\n",
    "- **struct**: Pack and unpack binary data to/from C-compatible formats\n",
    "- **memoryview**: Zero-copy slicing of binary data\n",
    "- **BOM**: Byte Order Mark for detecting encoding and endianness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UTF-8 Variable-Length Encoding\n",
    "\n",
    "UTF-8 encodes each Unicode code point using 1 to 4 bytes. ASCII characters (U+0000 to U+007F) use a single byte, making UTF-8 backward-compatible with ASCII. Characters from other scripts use more bytes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# UTF-8 uses 1-4 bytes per character\n",
    "examples: list[tuple[str, str]] = [\n",
    "    (\"A\", \"ASCII (1 byte)\"),\n",
    "    (\"√©\", \"Latin accent (2 bytes)\"),\n",
    "    (\"‰∏≠\", \"CJK ideograph (3 bytes)\"),\n",
    "    (\"üéâ\", \"Emoji (4 bytes)\"),\n",
    "]\n",
    "\n",
    "print(f\"{'Char':<6} {'Codepoint':<12} {'UTF-8 Hex':<20} {'Bytes':<8} {'Binary'}\")\n",
    "print(\"-\" * 75)\n",
    "for char, desc in examples:\n",
    "    encoded = char.encode(\"utf-8\")\n",
    "    binary = \" \".join(f\"{b:08b}\" for b in encoded)\n",
    "    print(f\"{char:<6} U+{ord(char):04X}{'':>5} {encoded.hex(' '):<20} {len(encoded):<8} {binary}\")\n",
    "\n",
    "# Verify byte counts match expectations\n",
    "assert len(\"A\".encode(\"utf-8\")) == 1\n",
    "assert len(\"√©\".encode(\"utf-8\")) == 2\n",
    "assert len(\"‰∏≠\".encode(\"utf-8\")) == 3\n",
    "assert len(\"üéâ\".encode(\"utf-8\")) == 4\n",
    "print(\"\\nAll byte count assertions passed.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Encodings: UTF-8, Latin-1, UTF-16, ASCII\n",
    "\n",
    "Different encodings represent the same text differently. Each has trade-offs in terms of compatibility, compactness, and character coverage."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Comparing how different encodings represent the same text\n",
    "text: str = \"caf√©\"\n",
    "\n",
    "encodings: dict[str, str] = {\n",
    "    \"utf-8\": \"Variable-length, web standard, ASCII-compatible\",\n",
    "    \"latin-1\": \"Fixed 1-byte, covers Western European languages\",\n",
    "    \"utf-16\": \"Fixed 2 or 4 bytes, includes BOM\",\n",
    "    \"ascii\": \"7-bit, English only (will fail on accented chars)\",\n",
    "}\n",
    "\n",
    "print(f\"Encoding {text!r}:\\n\")\n",
    "for enc, desc in encodings.items():\n",
    "    try:\n",
    "        encoded = text.encode(enc)\n",
    "        print(f\"{enc:>10}: {encoded.hex(' '):<30} ({len(encoded)} bytes)\")\n",
    "        print(f\"{'':>10}  {desc}\")\n",
    "    except UnicodeEncodeError as e:\n",
    "        print(f\"{enc:>10}: FAILED - {e}\")\n",
    "        print(f\"{'':>10}  {desc}\")\n",
    "    print()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Error Handling\n",
    "\n",
    "When encoding text to bytes, characters that cannot be represented in the target encoding cause errors. Python provides several error handlers to control what happens."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Encoding error handlers\n",
    "text: str = \"caf√© üêç\"\n",
    "\n",
    "handlers: list[tuple[str, str]] = [\n",
    "    (\"strict\", \"Raise UnicodeEncodeError (default)\"),\n",
    "    (\"replace\", \"Replace with '?' for bytes\"),\n",
    "    (\"ignore\", \"Silently drop unencodable characters\"),\n",
    "    (\"xmlcharrefreplace\", \"Replace with XML character reference\"),\n",
    "    (\"backslashreplace\", \"Replace with Python backslash escape\"),\n",
    "    (\"namereplace\", \"Replace with \\\\N{...} escape\"),\n",
    "]\n",
    "\n",
    "print(f\"Encoding {text!r} to ASCII with different error handlers:\\n\")\n",
    "for handler, desc in handlers:\n",
    "    try:\n",
    "        result = text.encode(\"ascii\", errors=handler)\n",
    "        print(f\"{handler:<20} -> {result}\")\n",
    "        print(f\"{'':>20}    {desc}\")\n",
    "    except UnicodeEncodeError as e:\n",
    "        print(f\"{handler:<20} -> UnicodeEncodeError: {e}\")\n",
    "        print(f\"{'':>20}    {desc}\")\n",
    "    print()\n",
    "\n",
    "# Verify behaviors from the test file\n",
    "assert b\"?\" in \"caf√©\".encode(\"ascii\", errors=\"replace\")\n",
    "assert \"caf√©\".encode(\"ascii\", errors=\"ignore\") == b\"caf\"\n",
    "print(\"Error handling assertions passed.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Decoding error handlers work similarly\n",
    "# Simulate corrupted UTF-8 data\n",
    "bad_utf8: bytes = b\"caf\\xc3\"  # Incomplete UTF-8 sequence (missing second byte of '√©')\n",
    "\n",
    "print(f\"Decoding corrupted bytes {bad_utf8!r}:\\n\")\n",
    "for handler in [\"strict\", \"replace\", \"ignore\"]:\n",
    "    try:\n",
    "        result = bad_utf8.decode(\"utf-8\", errors=handler)\n",
    "        print(f\"{handler:<10} -> {result!r}\")\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"{handler:<10} -> UnicodeDecodeError: {e}\")\n",
    "\n",
    "# Practical pattern: try UTF-8, fall back to Latin-1\n",
    "def safe_decode(data: bytes, preferred: str = \"utf-8\") -> str:\n",
    "    \"\"\"Decode bytes, falling back to Latin-1 which never fails.\"\"\"\n",
    "    try:\n",
    "        return data.decode(preferred)\n",
    "    except UnicodeDecodeError:\n",
    "        return data.decode(\"latin-1\")  # Latin-1 never fails\n",
    "\n",
    "print(f\"\\nSafe decode of valid UTF-8:   {safe_decode(b'caf\\xc3\\xa9')!r}\")\n",
    "print(f\"Safe decode of invalid UTF-8: {safe_decode(bad_utf8)!r}  (Latin-1 fallback)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latin-1 Bijective Property\n",
    "\n",
    "Latin-1 (ISO 8859-1) has a unique property: every byte value 0-255 maps to exactly one character, and every character maps back to exactly one byte. This makes it useful as a \"pass-through\" encoding that never fails."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Latin-1 is bijective: every byte 0-255 maps to a character and back\n",
    "all_pass = True\n",
    "for i in range(256):\n",
    "    byte_val: bytes = bytes([i])\n",
    "    char: str = byte_val.decode(\"latin-1\")\n",
    "    roundtrip: bytes = char.encode(\"latin-1\")\n",
    "    if roundtrip != byte_val:\n",
    "        all_pass = False\n",
    "        print(f\"FAILED at byte {i}\")\n",
    "\n",
    "print(f\"Latin-1 bijective property verified for all 256 byte values: {all_pass}\")\n",
    "\n",
    "# Show a sample of the mapping\n",
    "print(f\"\\nSample Latin-1 mappings:\")\n",
    "print(f\"{'Byte':<8} {'Hex':<8} {'Char':<8} {'Name'}\")\n",
    "print(\"-\" * 55)\n",
    "import unicodedata\n",
    "for i in [0, 32, 65, 97, 128, 169, 192, 223, 233, 255]:\n",
    "    char = bytes([i]).decode(\"latin-1\")\n",
    "    name = unicodedata.name(char, f\"<control U+{i:04X}>\")\n",
    "    display = char if i >= 32 else \".\"\n",
    "    print(f\"{i:<8} 0x{i:02X}{'':>4} {display:<8} {name}\")\n",
    "\n",
    "# This is why Latin-1 is a safe fallback -- it can decode ANY byte sequence\n",
    "random_bytes: bytes = bytes(range(0, 256))\n",
    "decoded = random_bytes.decode(\"latin-1\")\n",
    "print(f\"\\nDecoded all 256 bytes successfully: {len(decoded)} characters\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## struct Module for Binary Data\n",
    "\n",
    "The `struct` module packs and unpacks binary data according to format strings. This is essential for reading/writing binary file formats and network protocols."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import struct\n",
    "\n",
    "# Pack Python values into binary format\n",
    "# Format: '>' big-endian, 'H' unsigned short, 'I' unsigned int, 'f' float\n",
    "packed: bytes = struct.pack(\">HIf\", 256, 100_000, 3.14)\n",
    "print(f\"Packed bytes: {packed.hex(' ')}\")\n",
    "print(f\"Packed length: {len(packed)} bytes\")\n",
    "\n",
    "# Unpack binary data back to Python values\n",
    "unpacked: tuple = struct.unpack(\">HIf\", packed)\n",
    "print(f\"\\nUnpacked values: {unpacked}\")\n",
    "print(f\"  unsigned short: {unpacked[0]}\")\n",
    "print(f\"  unsigned int:   {unpacked[1]}\")\n",
    "print(f\"  float:          {unpacked[2]:.2f}\")\n",
    "\n",
    "# Common format characters\n",
    "formats: list[tuple[str, str, object]] = [\n",
    "    (\"b\", \"signed byte\", -42),\n",
    "    (\"B\", \"unsigned byte\", 255),\n",
    "    (\"h\", \"signed short (2 bytes)\", -1000),\n",
    "    (\"H\", \"unsigned short (2 bytes)\", 65535),\n",
    "    (\"i\", \"signed int (4 bytes)\", -100_000),\n",
    "    (\"I\", \"unsigned int (4 bytes)\", 3_000_000),\n",
    "    (\"f\", \"float (4 bytes)\", 3.14),\n",
    "    (\"d\", \"double (8 bytes)\", 3.141592653589793),\n",
    "]\n",
    "\n",
    "print(f\"\\n{'Format':<8} {'Type':<25} {'Value':<20} {'Packed Hex'}\")\n",
    "print(\"-\" * 70)\n",
    "for fmt, desc, val in formats:\n",
    "    p = struct.pack(f\">{fmt}\", val)\n",
    "    print(f\"{fmt:<8} {desc:<25} {str(val):<20} {p.hex(' ')}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import struct\n",
    "\n",
    "# Practical example: parsing a simple binary header\n",
    "# Imagine a binary file format with:\n",
    "#   - Magic number: 2 bytes (unsigned short)\n",
    "#   - Version: 1 byte (unsigned char)\n",
    "#   - Record count: 4 bytes (unsigned int)\n",
    "#   - Timestamp: 8 bytes (double)\n",
    "\n",
    "HEADER_FORMAT: str = \">HBI d\"  # big-endian\n",
    "HEADER_SIZE: int = struct.calcsize(HEADER_FORMAT)\n",
    "\n",
    "# Write a header\n",
    "header: bytes = struct.pack(HEADER_FORMAT, 0xCAFE, 2, 1_000_000, 1708500000.0)\n",
    "print(f\"Header size: {HEADER_SIZE} bytes\")\n",
    "print(f\"Header hex: {header.hex(' ')}\")\n",
    "\n",
    "# Parse the header back\n",
    "magic, version, count, timestamp = struct.unpack(HEADER_FORMAT, header)\n",
    "print(f\"\\nParsed header:\")\n",
    "print(f\"  Magic:     0x{magic:04X}\")\n",
    "print(f\"  Version:   {version}\")\n",
    "print(f\"  Records:   {count:,}\")\n",
    "print(f\"  Timestamp: {timestamp}\")\n",
    "\n",
    "# struct.calcsize tells you the byte count for a format\n",
    "print(f\"\\nFormat sizes:\")\n",
    "for fmt in [\"B\", \"H\", \"I\", \"Q\", \"f\", \"d\"]:\n",
    "    print(f\"  {fmt}: {struct.calcsize(fmt)} bytes\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## memoryview for Zero-Copy Slicing\n",
    "\n",
    "`memoryview` provides a way to access the internal data of an object (like `bytes`, `bytearray`, or `array.array`) without copying it. This is important for performance when working with large binary buffers."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import struct\n",
    "\n",
    "# memoryview allows zero-copy slicing of binary data\n",
    "data = bytearray(b\"Hello, World! Extra data here...\")\n",
    "view = memoryview(data)\n",
    "\n",
    "# Slicing a memoryview does NOT copy data\n",
    "slice1 = view[0:5]\n",
    "slice2 = view[7:12]\n",
    "print(f\"Original: {bytes(data)}\")\n",
    "print(f\"Slice [0:5]: {bytes(slice1)}\")\n",
    "print(f\"Slice [7:12]: {bytes(slice2)}\")\n",
    "\n",
    "# Modifying through the view modifies the original (zero-copy!)\n",
    "slice1[0] = ord(\"h\")\n",
    "print(f\"\\nAfter modifying view: {bytes(data)}\")\n",
    "print(\"The original bytearray was modified through the memoryview.\")\n",
    "\n",
    "# Practical: parse fields from a binary buffer without copying\n",
    "buffer = bytearray(struct.pack(\">HI8s\", 42, 100, b\"TestData\"))\n",
    "mv = memoryview(buffer)\n",
    "\n",
    "# Extract fields by slicing the memoryview (no copy)\n",
    "field1 = struct.unpack(\">H\", mv[0:2])[0]\n",
    "field2 = struct.unpack(\">I\", mv[2:6])[0]\n",
    "field3 = bytes(mv[6:14])\n",
    "print(f\"\\nParsed from memoryview:\")\n",
    "print(f\"  Field 1 (ushort): {field1}\")\n",
    "print(f\"  Field 2 (uint):   {field2}\")\n",
    "print(f\"  Field 3 (bytes):  {field3}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOM (Byte Order Mark) Handling\n",
    "\n",
    "The Byte Order Mark (BOM) is a special Unicode character (U+FEFF) placed at the beginning of a text file to indicate encoding and byte order. UTF-16 and UTF-32 use BOMs to distinguish big-endian from little-endian."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import codecs\n",
    "\n",
    "text: str = \"Hello\"\n",
    "\n",
    "# UTF-16 encoding adds a BOM by default\n",
    "utf16: bytes = text.encode(\"utf-16\")\n",
    "utf16_le: bytes = text.encode(\"utf-16-le\")  # Little-endian, no BOM\n",
    "utf16_be: bytes = text.encode(\"utf-16-be\")  # Big-endian, no BOM\n",
    "\n",
    "print(f\"UTF-16 (with BOM): {utf16.hex(' ')}\")\n",
    "print(f\"UTF-16-LE (no BOM): {utf16_le.hex(' ')}\")\n",
    "print(f\"UTF-16-BE (no BOM): {utf16_be.hex(' ')}\")\n",
    "\n",
    "# The BOM bytes\n",
    "print(f\"\\nBOM constants:\")\n",
    "print(f\"  BOM_UTF16_LE: {codecs.BOM_UTF16_LE.hex(' ')}  (FF FE = little-endian)\")\n",
    "print(f\"  BOM_UTF16_BE: {codecs.BOM_UTF16_BE.hex(' ')}  (FE FF = big-endian)\")\n",
    "print(f\"  BOM_UTF8:     {codecs.BOM_UTF8.hex(' ')}  (EF BB BF)\")\n",
    "\n",
    "# Detect BOM in data\n",
    "def detect_bom(data: bytes) -> str:\n",
    "    \"\"\"Detect the BOM at the start of binary data.\"\"\"\n",
    "    if data.startswith(codecs.BOM_UTF8):\n",
    "        return \"UTF-8 BOM\"\n",
    "    elif data.startswith(codecs.BOM_UTF16_LE):\n",
    "        return \"UTF-16 Little-Endian\"\n",
    "    elif data.startswith(codecs.BOM_UTF16_BE):\n",
    "        return \"UTF-16 Big-Endian\"\n",
    "    elif data.startswith(codecs.BOM_UTF32_LE):\n",
    "        return \"UTF-32 Little-Endian\"\n",
    "    elif data.startswith(codecs.BOM_UTF32_BE):\n",
    "        return \"UTF-32 Big-Endian\"\n",
    "    return \"No BOM detected\"\n",
    "\n",
    "# Test BOM detection\n",
    "test_data: list[tuple[str, bytes]] = [\n",
    "    (\"utf-8-sig\", text.encode(\"utf-8-sig\")),\n",
    "    (\"utf-16\", text.encode(\"utf-16\")),\n",
    "    (\"utf-8\", text.encode(\"utf-8\")),\n",
    "]\n",
    "\n",
    "print(f\"\\nBOM detection:\")\n",
    "for enc, data in test_data:\n",
    "    print(f\"  {enc:<12} -> {detect_bom(data):<25} hex: {data[:4].hex(' ')}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Practical BOM handling: reading files with BOM\n",
    "text: str = \"Hello, World!\"\n",
    "\n",
    "# Write a file with UTF-8 BOM (common in Windows)\n",
    "with tempfile.NamedTemporaryFile(mode=\"wb\", suffix=\".txt\", delete=False) as f:\n",
    "    f.write(b\"\\xef\\xbb\\xbf\")  # UTF-8 BOM\n",
    "    f.write(text.encode(\"utf-8\"))\n",
    "    temp_path: str = f.name\n",
    "\n",
    "try:\n",
    "    # Reading with 'utf-8' keeps the BOM as a character\n",
    "    with open(temp_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content_with_bom = f.read()\n",
    "    print(f\"Read with 'utf-8':     {content_with_bom!r}\")\n",
    "    print(f\"Starts with BOM char:  {content_with_bom[0] == chr(0xFEFF)}\")\n",
    "\n",
    "    # Reading with 'utf-8-sig' automatically strips the BOM\n",
    "    with open(temp_path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        content_no_bom = f.read()\n",
    "    print(f\"\\nRead with 'utf-8-sig': {content_no_bom!r}\")\n",
    "    print(f\"BOM stripped:          {content_no_bom == text}\")\n",
    "finally:\n",
    "    os.unlink(temp_path)\n",
    "\n",
    "print(\"\\nTip: Use 'utf-8-sig' when reading files that may have a UTF-8 BOM.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **UTF-8** uses 1-4 bytes per character and is backward-compatible with ASCII; it is the default encoding for the modern web\n",
    "- **Latin-1** is bijective -- every byte 0-255 maps to a character, making it useful as a safe fallback decoder\n",
    "- **Encoding error handlers** (`strict`, `replace`, `ignore`, `xmlcharrefreplace`, `backslashreplace`, `namereplace`) control what happens when characters cannot be encoded\n",
    "- The **`struct`** module packs/unpacks binary data to C-compatible formats -- essential for binary file formats and protocols\n",
    "- **`memoryview`** provides zero-copy slicing of binary buffers, avoiding expensive copies for large data\n",
    "- **BOM (Byte Order Mark)** indicates encoding and endianness; use `utf-8-sig` to handle UTF-8 files with BOM transparently\n",
    "- Always be explicit about encodings -- never rely on platform defaults"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}