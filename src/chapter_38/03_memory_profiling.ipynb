{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1000001",
   "metadata": {},
   "source": [
    "# Chapter 38: Memory Profiling\n",
    "\n",
    "This notebook covers tools for measuring and optimizing memory usage in Python. You will learn how to inspect object sizes with `sys.getsizeof`, reduce per-instance memory with `__slots__`, and trace allocations with `tracemalloc`.\n",
    "\n",
    "## Key Concepts\n",
    "- **`sys.getsizeof()`**: Returns the memory size of an object in bytes\n",
    "- **`__slots__`**: Eliminates the per-instance `__dict__`, saving memory\n",
    "- **`tracemalloc`**: Traces memory allocations to find where memory is used\n",
    "- **`tracemalloc.take_snapshot()`**: Captures a snapshot of all current allocations\n",
    "- **`tracemalloc.get_traced_memory()`**: Reports current and peak memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000002",
   "metadata": {},
   "source": [
    "## Section 1: `sys.getsizeof` -- Measuring Object Size\n",
    "\n",
    "`sys.getsizeof()` returns the size of an object in bytes. This is the **shallow** size -- it does not include the size of objects that the target references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Basic types and their sizes\n",
    "print(\"Sizes of basic types (in bytes):\")\n",
    "print(f\"  int(0):           {sys.getsizeof(0)}\")\n",
    "print(f\"  int(1):           {sys.getsizeof(1)}\")\n",
    "print(f\"  int(2**30):       {sys.getsizeof(2**30)}\")\n",
    "print(f\"  float(3.14):      {sys.getsizeof(3.14)}\")\n",
    "print(f\"  bool(True):       {sys.getsizeof(True)}\")\n",
    "print(f\"  None:             {sys.getsizeof(None)}\")\n",
    "\n",
    "# All sizes are positive\n",
    "print(f\"\\ngetsizeof(0) > 0: {sys.getsizeof(0) > 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Container sizes grow with their contents\n",
    "empty_list: list[int] = []\n",
    "small_list: list[int] = [1, 2, 3, 4, 5]\n",
    "\n",
    "print(\"List sizes:\")\n",
    "print(f\"  []:              {sys.getsizeof(empty_list)}\")\n",
    "print(f\"  [1,2,3,4,5]:     {sys.getsizeof(small_list)}\")\n",
    "print(f\"  Empty < filled:  {sys.getsizeof(empty_list) < sys.getsizeof(small_list)}\")\n",
    "\n",
    "# String sizes grow with length\n",
    "empty_str: str = \"\"\n",
    "hello_str: str = \"hello world\"\n",
    "\n",
    "print(f\"\\nString sizes:\")\n",
    "print(f\"  '':              {sys.getsizeof(empty_str)}\")\n",
    "print(f\"  'hello world':   {sys.getsizeof(hello_str)}\")\n",
    "print(f\"  Empty < filled:  {sys.getsizeof(empty_str) < sys.getsizeof(hello_str)}\")\n",
    "\n",
    "# Tuple sizes\n",
    "empty_tuple: tuple[()] = ()\n",
    "small_tuple: tuple[int, int, int] = (1, 2, 3)\n",
    "\n",
    "print(f\"\\nTuple sizes:\")\n",
    "print(f\"  ():              {sys.getsizeof(empty_tuple)}\")\n",
    "print(f\"  (1, 2, 3):       {sys.getsizeof(small_tuple)}\")\n",
    "print(f\"  Empty < filled:  {sys.getsizeof(empty_tuple) < sys.getsizeof(small_tuple)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000005",
   "metadata": {},
   "source": [
    "## Section 2: Comparing Container Type Sizes\n",
    "\n",
    "Different container types have different memory overhead. Tuples are lighter than lists, and sets have hash-table overhead similar to dicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Compare base sizes of empty containers\n",
    "containers: dict[str, object] = {\n",
    "    \"list()\":       [],\n",
    "    \"tuple()\":      (),\n",
    "    \"dict()\":       {},\n",
    "    \"set()\":        set(),\n",
    "    \"frozenset()\": frozenset(),\n",
    "    \"bytearray()\": bytearray(),\n",
    "}\n",
    "\n",
    "print(\"Empty container sizes (bytes):\")\n",
    "for name, obj in containers.items():\n",
    "    size: int = sys.getsizeof(obj)\n",
    "    print(f\"  {name:15s} {size:>4}\")\n",
    "\n",
    "print(f\"\\nTuples are lighter than lists: {sys.getsizeof(()) < sys.getsizeof([])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000007",
   "metadata": {},
   "source": [
    "## Section 3: `__slots__` -- Reducing Per-Instance Memory\n",
    "\n",
    "By default, each Python instance stores its attributes in a `__dict__` dictionary. Defining `__slots__` replaces the dict with a fixed-size structure, significantly reducing memory for classes with many instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "class Regular:\n",
    "    \"\"\"A regular class with a __dict__.\"\"\"\n",
    "\n",
    "    def __init__(self, x: int) -> None:\n",
    "        self.x: int = x\n",
    "\n",
    "\n",
    "class Slotted:\n",
    "    \"\"\"A class using __slots__ instead of __dict__.\"\"\"\n",
    "\n",
    "    __slots__ = (\"x\",)\n",
    "\n",
    "    def __init__(self, x: int) -> None:\n",
    "        self.x: int = x\n",
    "\n",
    "\n",
    "regular: Regular = Regular(1)\n",
    "slotted: Slotted = Slotted(1)\n",
    "\n",
    "regular_size: int = sys.getsizeof(regular)\n",
    "slotted_size: int = sys.getsizeof(slotted)\n",
    "\n",
    "print(f\"Regular instance size: {regular_size} bytes\")\n",
    "print(f\"Slotted instance size: {slotted_size} bytes\")\n",
    "print(f\"Slotted is smaller:    {slotted_size < regular_size}\")\n",
    "print(f\"Savings:               {regular_size - slotted_size} bytes per instance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "class RegularPoint:\n",
    "    def __init__(self, x: float, y: float, z: float) -> None:\n",
    "        self.x: float = x\n",
    "        self.y: float = y\n",
    "        self.z: float = z\n",
    "\n",
    "\n",
    "class SlottedPoint:\n",
    "    __slots__ = (\"x\", \"y\", \"z\")\n",
    "\n",
    "    def __init__(self, x: float, y: float, z: float) -> None:\n",
    "        self.x: float = x\n",
    "        self.y: float = y\n",
    "        self.z: float = z\n",
    "\n",
    "\n",
    "# Regular instances have a __dict__\n",
    "rp: RegularPoint = RegularPoint(1.0, 2.0, 3.0)\n",
    "print(f\"Regular has __dict__: {hasattr(rp, '__dict__')}\")\n",
    "print(f\"Regular __dict__: {rp.__dict__}\")\n",
    "print(f\"Regular __dict__ size: {sys.getsizeof(rp.__dict__)} bytes\")\n",
    "\n",
    "# Slotted instances do not\n",
    "sp: SlottedPoint = SlottedPoint(1.0, 2.0, 3.0)\n",
    "print(f\"\\nSlotted has __dict__: {hasattr(sp, '__dict__')}\")\n",
    "print(f\"Slotted has __slots__: {hasattr(sp, '__slots__')}\")\n",
    "\n",
    "# Memory comparison\n",
    "print(f\"\\nRegular size:  {sys.getsizeof(rp)} bytes\")\n",
    "print(f\"Slotted size:  {sys.getsizeof(sp)} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "class RegularItem:\n",
    "    def __init__(self, val: int) -> None:\n",
    "        self.val: int = val\n",
    "\n",
    "\n",
    "class SlottedItem:\n",
    "    __slots__ = (\"val\",)\n",
    "\n",
    "    def __init__(self, val: int) -> None:\n",
    "        self.val: int = val\n",
    "\n",
    "\n",
    "# At scale, the savings add up significantly\n",
    "n: int = 10_000\n",
    "\n",
    "regular_items: list[RegularItem] = [RegularItem(i) for i in range(n)]\n",
    "slotted_items: list[SlottedItem] = [SlottedItem(i) for i in range(n)]\n",
    "\n",
    "# Estimate total memory (instance size * count)\n",
    "regular_per: int = sys.getsizeof(regular_items[0])\n",
    "slotted_per: int = sys.getsizeof(slotted_items[0])\n",
    "\n",
    "regular_total: int = regular_per * n\n",
    "slotted_total: int = slotted_per * n\n",
    "\n",
    "print(f\"Per-instance: Regular={regular_per}B, Slotted={slotted_per}B\")\n",
    "print(f\"Total for {n:,} instances:\")\n",
    "print(f\"  Regular: {regular_total:>10,} bytes ({regular_total / 1024:.1f} KB)\")\n",
    "print(f\"  Slotted: {slotted_total:>10,} bytes ({slotted_total / 1024:.1f} KB)\")\n",
    "print(f\"  Savings: {regular_total - slotted_total:>10,} bytes ({(regular_total - slotted_total) / 1024:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000011",
   "metadata": {},
   "source": [
    "## Section 4: `tracemalloc` -- Tracing Memory Allocations\n",
    "\n",
    "The `tracemalloc` module tracks memory allocations made by Python. It lets you take snapshots, compare them, and find the source of memory usage down to the file and line number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracemalloc\n",
    "\n",
    "# Start tracing memory allocations\n",
    "tracemalloc.start()\n",
    "\n",
    "# Allocate some memory\n",
    "data: list[int] = [i for i in range(1000)]\n",
    "text: str = \"hello \" * 1000\n",
    "\n",
    "# Take a snapshot of current allocations\n",
    "snapshot: tracemalloc.Snapshot = tracemalloc.take_snapshot()\n",
    "\n",
    "# Get statistics grouped by line number\n",
    "stats: list[tracemalloc.StatisticDiff] = snapshot.statistics(\"lineno\")\n",
    "print(f\"Number of allocation sites: {len(stats)}\")\n",
    "print(f\"Has entries: {len(stats) > 0}\")\n",
    "\n",
    "# Show the top 5 memory consumers\n",
    "print(\"\\nTop 5 allocation sites:\")\n",
    "for stat in stats[:5]:\n",
    "    print(f\"  {stat}\")\n",
    "\n",
    "# Stop tracing\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracemalloc\n",
    "\n",
    "# tracemalloc can also group by filename\n",
    "tracemalloc.start()\n",
    "\n",
    "numbers: list[float] = [float(i) for i in range(5000)]\n",
    "\n",
    "snapshot: tracemalloc.Snapshot = tracemalloc.take_snapshot()\n",
    "\n",
    "# Group by filename instead of line number\n",
    "stats_by_file: list[tracemalloc.StatisticDiff] = snapshot.statistics(\"filename\")\n",
    "print(\"Top 3 allocations by filename:\")\n",
    "for stat in stats_by_file[:3]:\n",
    "    print(f\"  {stat}\")\n",
    "\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000014",
   "metadata": {},
   "source": [
    "## Section 5: `get_traced_memory` -- Current and Peak Usage\n",
    "\n",
    "`tracemalloc.get_traced_memory()` returns a tuple of `(current, peak)` bytes. This is useful for monitoring memory usage over time or finding the high-water mark of a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracemalloc\n",
    "\n",
    "tracemalloc.start()\n",
    "\n",
    "# Check initial memory\n",
    "current_before: int\n",
    "peak_before: int\n",
    "current_before, peak_before = tracemalloc.get_traced_memory()\n",
    "print(f\"Before allocation:\")\n",
    "print(f\"  Current: {current_before:>10,} bytes\")\n",
    "print(f\"  Peak:    {peak_before:>10,} bytes\")\n",
    "\n",
    "# Allocate a large data structure\n",
    "big_data: list[int] = list(range(100_000))\n",
    "\n",
    "current_after: int\n",
    "peak_after: int\n",
    "current_after, peak_after = tracemalloc.get_traced_memory()\n",
    "print(f\"\\nAfter allocation:\")\n",
    "print(f\"  Current: {current_after:>10,} bytes\")\n",
    "print(f\"  Peak:    {peak_after:>10,} bytes\")\n",
    "\n",
    "# Verify invariants\n",
    "print(f\"\\ncurrent >= 0: {current_after >= 0}\")\n",
    "print(f\"peak >= 0:    {peak_after >= 0}\")\n",
    "print(f\"peak >= current: {peak_after >= current_after}\")\n",
    "\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracemalloc\n",
    "\n",
    "\n",
    "def measure_peak_memory(func: object) -> tuple[int, int]:\n",
    "    \"\"\"Measure the peak memory usage of a callable.\"\"\"\n",
    "    tracemalloc.start()\n",
    "    func()  # type: ignore[operator]\n",
    "    current: int\n",
    "    peak: int\n",
    "    current, peak = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "    return current, peak\n",
    "\n",
    "\n",
    "def create_list() -> list[int]:\n",
    "    \"\"\"Create a list of integers.\"\"\"\n",
    "    return list(range(50_000))\n",
    "\n",
    "\n",
    "def create_generator_sum() -> int:\n",
    "    \"\"\"Sum integers using a generator (lower peak memory).\"\"\"\n",
    "    return sum(i for i in range(50_000))\n",
    "\n",
    "\n",
    "list_current, list_peak = measure_peak_memory(create_list)\n",
    "gen_current, gen_peak = measure_peak_memory(create_generator_sum)\n",
    "\n",
    "print(\"List approach:\")\n",
    "print(f\"  Current: {list_current:>10,} bytes\")\n",
    "print(f\"  Peak:    {list_peak:>10,} bytes\")\n",
    "\n",
    "print(\"\\nGenerator approach:\")\n",
    "print(f\"  Current: {gen_current:>10,} bytes\")\n",
    "print(f\"  Peak:    {gen_peak:>10,} bytes\")\n",
    "\n",
    "print(f\"\\nGenerator uses less peak memory: {gen_peak < list_peak}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000017",
   "metadata": {},
   "source": [
    "## Section 6: Comparing Snapshots\n",
    "\n",
    "You can take two snapshots at different points and compare them to see what was allocated in between. This is invaluable for detecting memory leaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracemalloc\n",
    "\n",
    "tracemalloc.start()\n",
    "\n",
    "# Take a baseline snapshot\n",
    "snapshot1: tracemalloc.Snapshot = tracemalloc.take_snapshot()\n",
    "\n",
    "# Allocate some memory\n",
    "new_data: list[str] = [f\"item_{i}\" for i in range(5000)]\n",
    "more_data: dict[int, str] = {i: f\"val_{i}\" for i in range(2000)}\n",
    "\n",
    "# Take a second snapshot\n",
    "snapshot2: tracemalloc.Snapshot = tracemalloc.take_snapshot()\n",
    "\n",
    "# Compare the two snapshots\n",
    "diff_stats: list[tracemalloc.StatisticDiff] = snapshot2.compare_to(snapshot1, \"lineno\")\n",
    "\n",
    "print(\"Top 5 memory increases between snapshots:\")\n",
    "for stat in diff_stats[:5]:\n",
    "    print(f\"  {stat}\")\n",
    "\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000019",
   "metadata": {},
   "source": [
    "## Section 7: Memory Optimization Strategies\n",
    "\n",
    "Practical techniques for reducing memory usage in Python programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Strategy 1: Use tuples instead of lists for immutable data\n",
    "list_data: list[int] = [1, 2, 3, 4, 5]\n",
    "tuple_data: tuple[int, ...] = (1, 2, 3, 4, 5)\n",
    "\n",
    "print(\"Tuples vs lists:\")\n",
    "print(f\"  list [1..5]:  {sys.getsizeof(list_data)} bytes\")\n",
    "print(f\"  tuple (1..5): {sys.getsizeof(tuple_data)} bytes\")\n",
    "print(f\"  Tuple smaller: {sys.getsizeof(tuple_data) < sys.getsizeof(list_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Strategy 2: Use generators to avoid materializing large sequences\n",
    "materialized: list[int] = [x * 2 for x in range(10_000)]\n",
    "lazy: range = range(10_000)\n",
    "\n",
    "print(\"Materialized list vs range object:\")\n",
    "print(f\"  list:  {sys.getsizeof(materialized):>10,} bytes\")\n",
    "print(f\"  range: {sys.getsizeof(lazy):>10,} bytes\")\n",
    "\n",
    "# Strategy 3: Use array module for homogeneous numeric data\n",
    "import array\n",
    "\n",
    "int_list: list[int] = list(range(1000))\n",
    "int_array: array.array[int] = array.array(\"l\", range(1000))\n",
    "\n",
    "print(f\"\\nlist of 1000 ints:  {sys.getsizeof(int_list):>10,} bytes\")\n",
    "print(f\"array of 1000 ints: {sys.getsizeof(int_array):>10,} bytes\")\n",
    "print(f\"array is smaller:   {sys.getsizeof(int_array) < sys.getsizeof(int_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1000022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Strategy 4: Use __slots__ for data-heavy classes (recap)\n",
    "# Strategy 5: Delete large objects when no longer needed\n",
    "\n",
    "\n",
    "def process_data() -> int:\n",
    "    \"\"\"Process data and clean up intermediate results.\"\"\"\n",
    "    # Large intermediate data\n",
    "    raw: list[int] = list(range(100_000))\n",
    "    result: int = sum(raw)\n",
    "\n",
    "    # Explicitly free the large list\n",
    "    del raw\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "total: int = process_data()\n",
    "print(f\"Result: {total:,}\")\n",
    "print(\"\\nMemory optimization strategies:\")\n",
    "print(\"  1. Use tuples for immutable sequences\")\n",
    "print(\"  2. Use generators / range for iteration\")\n",
    "print(\"  3. Use array.array for homogeneous numeric data\")\n",
    "print(\"  4. Use __slots__ on classes with many instances\")\n",
    "print(\"  5. del large objects when they are no longer needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000023",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### `sys.getsizeof()`\n",
    "- Returns the **shallow** size of an object in bytes\n",
    "- Does not account for referenced objects (e.g., list elements)\n",
    "- Different types have different base sizes; containers grow with their contents\n",
    "\n",
    "### `__slots__`\n",
    "- Replaces the per-instance `__dict__` with a fixed-size structure\n",
    "- Reduces memory per instance, significant when creating many objects\n",
    "- Instances cannot have attributes not listed in `__slots__`\n",
    "\n",
    "### `tracemalloc`\n",
    "- **`tracemalloc.start()`** / **`tracemalloc.stop()`**: Enable/disable allocation tracing\n",
    "- **`tracemalloc.take_snapshot()`**: Capture current allocations for analysis\n",
    "- **`snapshot.statistics(\"lineno\")`**: Group allocations by source line\n",
    "- **`snapshot.compare_to(other, key)`**: Diff two snapshots to find leaks\n",
    "- **`tracemalloc.get_traced_memory()`**: Returns `(current, peak)` bytes\n",
    "- `peak >= current` always holds; useful for finding high-water marks\n",
    "\n",
    "### Optimization Strategies\n",
    "- Prefer tuples over lists for immutable data\n",
    "- Use generators and `range` instead of materializing large sequences\n",
    "- Use `array.array` for large homogeneous numeric collections\n",
    "- Apply `__slots__` to classes instantiated many times\n",
    "- Explicitly `del` large intermediate objects"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}