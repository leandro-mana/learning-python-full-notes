{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# Chapter 27: ProcessPoolExecutor and Futures\n",
    "\n",
    "The `concurrent.futures` module provides a high-level interface for parallel execution.\n",
    "`ProcessPoolExecutor` manages a pool of worker processes and returns `Future` objects\n",
    "that represent pending results. It is simpler and more Pythonic than the lower-level\n",
    "`multiprocessing.Pool` API.\n",
    "\n",
    "## Topics Covered\n",
    "- **ProcessPoolExecutor**: High-level process pool interface\n",
    "- **Future**: Representing pending results\n",
    "- **map() vs submit()**: Two ways to distribute work\n",
    "- **as_completed()**: Processing results as they become available\n",
    "- **CPU-bound vs I/O-bound**: Choosing the right executor\n",
    "- **Practical**: Comparing ProcessPoolExecutor and ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5",
   "metadata": {},
   "source": [
    "## ProcessPoolExecutor Basics\n",
    "\n",
    "`ProcessPoolExecutor` is part of `concurrent.futures` and provides the same API as\n",
    "`ThreadPoolExecutor`. It uses processes instead of threads, making it ideal for\n",
    "**CPU-bound** workloads.\n",
    "\n",
    "Key features:\n",
    "- Context manager support (`with` statement)\n",
    "- `max_workers` defaults to the number of CPUs\n",
    "- Worker functions must be **picklable** (defined at module level)\n",
    "- Returns `Future` objects for asynchronous result handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "\n",
    "def square(x: int) -> int:\n",
    "    \"\"\"Compute the square of a number.\"\"\"\n",
    "    return x * x\n",
    "\n",
    "\n",
    "# Basic usage with executor.map()\n",
    "print(f\"CPU count: {os.cpu_count()}\")\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=2) as executor:\n",
    "    results: list[int] = list(executor.map(square, [1, 2, 3, 4, 5]))\n",
    "\n",
    "print(f\"Squares: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7",
   "metadata": {},
   "source": [
    "## executor.map(): Ordered Parallel Mapping\n",
    "\n",
    "`executor.map(func, *iterables)` applies a function to every item in the iterables,\n",
    "distributing work across the pool. It returns an **iterator** that yields results in\n",
    "the **same order** as the input.\n",
    "\n",
    "Key differences from `multiprocessing.Pool.map()`:\n",
    "- Returns a lazy iterator (not a list)\n",
    "- Supports a `timeout` parameter\n",
    "- Supports a `chunksize` parameter for efficiency with large iterables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "\n",
    "def process_item(x: int) -> tuple[int, int, int]:\n",
    "    \"\"\"Process an item and return (input, result, pid).\"\"\"\n",
    "    return (x, x * x, os.getpid())\n",
    "\n",
    "\n",
    "# map() preserves input order\n",
    "with ProcessPoolExecutor(max_workers=2) as executor:\n",
    "    results = list(executor.map(process_item, range(8)))\n",
    "\n",
    "main_pid: int = os.getpid()\n",
    "print(f\"Main PID: {main_pid}\")\n",
    "print(\"\\nResults (order preserved):\")\n",
    "for x, squared, pid in results:\n",
    "    print(f\"  {x}^2 = {squared} (worker PID: {pid})\")\n",
    "\n",
    "worker_pids: set[int] = {pid for _, _, pid in results}\n",
    "print(f\"\\nUnique worker PIDs: {worker_pids}\")\n",
    "print(f\"All workers differ from main: {all(pid != main_pid for _, _, pid in results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a7b8c9",
   "metadata": {},
   "source": [
    "## executor.submit() and Future Objects\n",
    "\n",
    "`executor.submit(func, *args, **kwargs)` submits a single callable for execution and\n",
    "returns a `Future` object immediately. The `Future` represents a computation that may\n",
    "not have completed yet.\n",
    "\n",
    "Key `Future` methods:\n",
    "- `result(timeout=None)` -- block until the result is ready, then return it\n",
    "- `done()` -- return `True` if the computation has completed\n",
    "- `cancelled()` -- return `True` if the task was cancelled\n",
    "- `exception(timeout=None)` -- return the exception, if any\n",
    "- `add_done_callback(fn)` -- register a callback to run when the future completes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import Future, ProcessPoolExecutor\n",
    "\n",
    "\n",
    "def square(x: int) -> int:\n",
    "    \"\"\"Compute the square of a number.\"\"\"\n",
    "    return x * x\n",
    "\n",
    "\n",
    "# submit() returns a Future\n",
    "with ProcessPoolExecutor(max_workers=1) as executor:\n",
    "    future: Future[int] = executor.submit(square, 7)\n",
    "\n",
    "    # Inspect the future\n",
    "    print(f\"Type: {type(future).__name__}\")\n",
    "    print(f\"Done: {future.done()}\")  # May or may not be done yet\n",
    "\n",
    "    # Get the result (blocks if not yet ready)\n",
    "    result: int = future.result()\n",
    "    print(f\"Result: {result}\")\n",
    "    print(f\"Done after result(): {future.done()}\")\n",
    "    print(f\"Exception: {future.exception()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import Future, ProcessPoolExecutor\n",
    "\n",
    "\n",
    "def cube(x: int) -> int:\n",
    "    \"\"\"Compute the cube of a number.\"\"\"\n",
    "    return x ** 3\n",
    "\n",
    "\n",
    "# Submit multiple tasks and collect futures\n",
    "with ProcessPoolExecutor(max_workers=2) as executor:\n",
    "    futures: dict[Future[int], int] = {\n",
    "        executor.submit(cube, n): n\n",
    "        for n in range(1, 7)\n",
    "    }\n",
    "\n",
    "    # Retrieve results from each future\n",
    "    print(\"Results from submit():\")\n",
    "    for future, input_val in futures.items():\n",
    "        result: int = future.result()\n",
    "        print(f\"  {input_val}^3 = {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0e1f2",
   "metadata": {},
   "source": [
    "## map() vs submit(): When to Use Each\n",
    "\n",
    "| Feature | `map()` | `submit()` |\n",
    "|---------|---------|:-----------|\n",
    "| Returns | Iterator of results | Individual `Future` objects |\n",
    "| Order | Results in input order | Results in completion order (with `as_completed`) |\n",
    "| Arguments | Single iterable per param | Full control of args/kwargs |\n",
    "| Use case | Batch processing same operation | Different tasks or custom handling |\n",
    "| Error handling | Exception raised during iteration | Exception stored in `Future` |\n",
    "\n",
    "**Rule of thumb**: Use `map()` for simple \"apply same function to many inputs\" tasks.\n",
    "Use `submit()` when you need more control over individual tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1f2a3",
   "metadata": {},
   "source": [
    "## as_completed(): Results in Completion Order\n",
    "\n",
    "`concurrent.futures.as_completed(futures)` yields futures as they **finish**, not in\n",
    "the order they were submitted. This is useful when you want to process results as\n",
    "soon as they are available, rather than waiting for all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from concurrent.futures import Future, ProcessPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "def variable_work(task_id: int) -> tuple[int, float]:\n",
    "    \"\"\"Simulate work with variable duration.\"\"\"\n",
    "    # Tasks with higher IDs finish faster\n",
    "    duration: float = 0.5 - (task_id * 0.1)\n",
    "    duration = max(duration, 0.05)\n",
    "    time.sleep(duration)\n",
    "    return (task_id, duration)\n",
    "\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=3) as executor:\n",
    "    futures: dict[Future[tuple[int, float]], int] = {\n",
    "        executor.submit(variable_work, i): i\n",
    "        for i in range(5)\n",
    "    }\n",
    "\n",
    "    print(\"Results in completion order:\")\n",
    "    for future in as_completed(futures):\n",
    "        task_id, duration = future.result()\n",
    "        print(f\"  Task {task_id} completed (took {duration:.2f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a3b4c5",
   "metadata": {},
   "source": [
    "## Error Handling with Futures\n",
    "\n",
    "When a worker function raises an exception, it is captured by the `Future` object and\n",
    "re-raised when you call `.result()` or `.exception()`. This makes error handling\n",
    "straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import Future, ProcessPoolExecutor\n",
    "\n",
    "\n",
    "def divide(a: float, b: float) -> float:\n",
    "    \"\"\"Divide a by b. Raises ZeroDivisionError if b is zero.\"\"\"\n",
    "    return a / b\n",
    "\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=2) as executor:\n",
    "    # Submit tasks, one of which will fail\n",
    "    tasks: list[tuple[float, float]] = [(10, 2), (20, 4), (30, 0), (40, 5)]\n",
    "    futures: list[tuple[Future[float], tuple[float, float]]] = [\n",
    "        (executor.submit(divide, a, b), (a, b))\n",
    "        for a, b in tasks\n",
    "    ]\n",
    "\n",
    "    for future, (a, b) in futures:\n",
    "        try:\n",
    "            result: float = future.result()\n",
    "            print(f\"  {a} / {b} = {result}\")\n",
    "        except ZeroDivisionError:\n",
    "            print(f\"  {a} / {b} = ERROR (division by zero)\")\n",
    "            # Inspect the exception stored in the Future\n",
    "            print(f\"    future.exception() = {future.exception()!r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5d6e7",
   "metadata": {},
   "source": [
    "## CPU-Bound vs I/O-Bound Workloads\n",
    "\n",
    "Choosing between `ProcessPoolExecutor` and `ThreadPoolExecutor` depends on the nature\n",
    "of your workload:\n",
    "\n",
    "| Workload | Bottleneck | Best Executor | Why |\n",
    "|----------|-----------|:--------------|:----|\n",
    "| **CPU-bound** | Computation | `ProcessPoolExecutor` | Bypasses GIL, true parallelism |\n",
    "| **I/O-bound** | Network, disk | `ThreadPoolExecutor` | Threads release GIL during I/O |\n",
    "| **Mixed** | Both | Depends | Profile first; consider async I/O |\n",
    "\n",
    "The GIL (Global Interpreter Lock) prevents multiple threads from executing Python bytecode\n",
    "simultaneously, but it is released during I/O operations. Processes each have their own GIL,\n",
    "so CPU-bound work runs truly in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "\n",
    "\n",
    "def cpu_heavy(n: int) -> int:\n",
    "    \"\"\"CPU-bound: compute sum of squares.\"\"\"\n",
    "    total: int = 0\n",
    "    for i in range(n):\n",
    "        total += i * i\n",
    "    return total\n",
    "\n",
    "\n",
    "workload: list[int] = [1_500_000] * 8\n",
    "\n",
    "# Sequential baseline\n",
    "start: float = time.perf_counter()\n",
    "_ = [cpu_heavy(n) for n in workload]\n",
    "seq_time: float = time.perf_counter() - start\n",
    "\n",
    "# Threads (limited by GIL for CPU-bound work)\n",
    "start = time.perf_counter()\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    _ = list(executor.map(cpu_heavy, workload))\n",
    "thread_time: float = time.perf_counter() - start\n",
    "\n",
    "# Processes (bypasses GIL)\n",
    "start = time.perf_counter()\n",
    "with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "    _ = list(executor.map(cpu_heavy, workload))\n",
    "process_time: float = time.perf_counter() - start\n",
    "\n",
    "print(\"CPU-bound workload comparison:\")\n",
    "print(f\"  Sequential:           {seq_time:.3f}s\")\n",
    "print(f\"  ThreadPoolExecutor:   {thread_time:.3f}s (speedup: {seq_time/thread_time:.2f}x)\")\n",
    "print(f\"  ProcessPoolExecutor:  {process_time:.3f}s (speedup: {seq_time/process_time:.2f}x)\")\n",
    "print(f\"\\nProcessPoolExecutor wins for CPU-bound tasks!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e7f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "\n",
    "\n",
    "def io_heavy(seconds: float) -> float:\n",
    "    \"\"\"I/O-bound: simulate waiting for a network response.\"\"\"\n",
    "    time.sleep(seconds)\n",
    "    return seconds\n",
    "\n",
    "\n",
    "io_workload: list[float] = [0.2] * 8\n",
    "\n",
    "# Sequential baseline\n",
    "start: float = time.perf_counter()\n",
    "_ = [io_heavy(s) for s in io_workload]\n",
    "seq_time: float = time.perf_counter() - start\n",
    "\n",
    "# Threads (efficient for I/O)\n",
    "start = time.perf_counter()\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    _ = list(executor.map(io_heavy, io_workload))\n",
    "thread_time: float = time.perf_counter() - start\n",
    "\n",
    "# Processes (more overhead for I/O)\n",
    "start = time.perf_counter()\n",
    "with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "    _ = list(executor.map(io_heavy, io_workload))\n",
    "process_time: float = time.perf_counter() - start\n",
    "\n",
    "print(\"I/O-bound workload comparison:\")\n",
    "print(f\"  Sequential:           {seq_time:.3f}s\")\n",
    "print(f\"  ThreadPoolExecutor:   {thread_time:.3f}s (speedup: {seq_time/thread_time:.2f}x)\")\n",
    "print(f\"  ProcessPoolExecutor:  {process_time:.3f}s (speedup: {seq_time/process_time:.2f}x)\")\n",
    "print(f\"\\nBoth work for I/O, but threads have less overhead!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f8a9b0",
   "metadata": {},
   "source": [
    "## Callbacks on Futures\n",
    "\n",
    "You can attach callbacks to `Future` objects using `add_done_callback()`. The callback\n",
    "function is called with the `Future` as its argument when the task completes. This is\n",
    "useful for logging, chaining tasks, or updating progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a9b0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import Future, ProcessPoolExecutor\n",
    "\n",
    "\n",
    "def compute_factorial(n: int) -> int:\n",
    "    \"\"\"Compute n! iteratively.\"\"\"\n",
    "    result: int = 1\n",
    "    for i in range(2, n + 1):\n",
    "        result *= i\n",
    "    return result\n",
    "\n",
    "\n",
    "def on_complete(future: Future[int]) -> None:\n",
    "    \"\"\"Callback when a factorial computation completes.\"\"\"\n",
    "    result: int = future.result()\n",
    "    print(f\"  Callback: computation finished, result = {result}\")\n",
    "\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=2) as executor:\n",
    "    print(\"Submitting tasks with callbacks:\")\n",
    "    for n in [5, 8, 10, 12]:\n",
    "        future: Future[int] = executor.submit(compute_factorial, n)\n",
    "        future.add_done_callback(on_complete)\n",
    "\n",
    "print(\"All tasks completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b0c1d2",
   "metadata": {},
   "source": [
    "## os.cpu_count() and Choosing max_workers\n",
    "\n",
    "`os.cpu_count()` returns the number of logical CPUs on the system. This is the default\n",
    "value for `max_workers` in `ProcessPoolExecutor`.\n",
    "\n",
    "Guidelines for choosing `max_workers`:\n",
    "- **CPU-bound**: Use `os.cpu_count()` or slightly less (leave room for other processes)\n",
    "- **I/O-bound**: Can use more workers than CPUs since they spend time waiting\n",
    "- **Memory-constrained**: Each process uses its own memory, so watch usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c1d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "\n",
    "def get_pid(_: int = 0) -> int:\n",
    "    \"\"\"Return the current process ID.\"\"\"\n",
    "    return os.getpid()\n",
    "\n",
    "\n",
    "# os.cpu_count() tells us how many CPUs are available\n",
    "cpus: int | None = os.cpu_count()\n",
    "print(f\"os.cpu_count(): {cpus}\")\n",
    "assert cpus is not None\n",
    "assert cpus >= 1\n",
    "\n",
    "# Default max_workers = cpu_count\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    # _max_workers is an implementation detail, shown for educational purposes\n",
    "    actual_workers: int | None = executor._max_workers\n",
    "    print(f\"Default max_workers: {actual_workers}\")\n",
    "\n",
    "# Practical: verify processes run on different PIDs\n",
    "with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "    pids: list[int] = list(executor.map(get_pid, range(8)))\n",
    "    unique: set[int] = set(pids)\n",
    "    print(f\"\\n8 tasks across 4 workers:\")\n",
    "    print(f\"  PIDs: {pids}\")\n",
    "    print(f\"  Unique PIDs: {unique}\")\n",
    "    print(f\"  All differ from main ({os.getpid()}): {all(p != os.getpid() for p in pids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d2e3f4",
   "metadata": {},
   "source": [
    "## Practical: Real-World Pattern -- Parallel Data Processing\n",
    "\n",
    "A common real-world pattern is to process a batch of items in parallel, collecting\n",
    "successes and failures separately. This example demonstrates using `submit()` with\n",
    "error handling for robust parallel processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e3f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import Future, ProcessPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "def process_record(record_id: int) -> dict[str, int | str]:\n",
    "    \"\"\"Simulate processing a data record. Some records fail.\"\"\"\n",
    "    if record_id % 5 == 0:\n",
    "        raise ValueError(f\"Record {record_id} is corrupted\")\n",
    "    return {\"id\": record_id, \"status\": \"processed\", \"value\": record_id * 10}\n",
    "\n",
    "\n",
    "record_ids: list[int] = list(range(1, 16))\n",
    "successes: list[dict[str, int | str]] = []\n",
    "failures: list[tuple[int, str]] = []\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=3) as executor:\n",
    "    # Submit all tasks\n",
    "    future_to_id: dict[Future[dict[str, int | str]], int] = {\n",
    "        executor.submit(process_record, rid): rid\n",
    "        for rid in record_ids\n",
    "    }\n",
    "\n",
    "    # Process results as they complete\n",
    "    for future in as_completed(future_to_id):\n",
    "        record_id: int = future_to_id[future]\n",
    "        try:\n",
    "            result: dict[str, int | str] = future.result()\n",
    "            successes.append(result)\n",
    "        except ValueError as e:\n",
    "            failures.append((record_id, str(e)))\n",
    "\n",
    "print(f\"Processed {len(successes)} records successfully:\")\n",
    "for s in sorted(successes, key=lambda x: x[\"id\"]):\n",
    "    print(f\"  Record {s['id']}: value={s['value']}\")\n",
    "\n",
    "print(f\"\\n{len(failures)} records failed:\")\n",
    "for record_id, error in sorted(failures):\n",
    "    print(f\"  Record {record_id}: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f4a5b6",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "| Concept | API | Purpose |\n",
    "|---------|-----|:--------|\n",
    "| **Executor** | `ProcessPoolExecutor(max_workers=n)` | High-level process pool |\n",
    "| **map()** | `executor.map(func, iterable)` | Parallel map, results in input order |\n",
    "| **submit()** | `executor.submit(func, *args)` | Submit single task, returns Future |\n",
    "| **Future** | `future.result()`, `.done()`, `.exception()` | Pending result handle |\n",
    "| **as_completed()** | `as_completed(futures)` | Yield futures in completion order |\n",
    "| **Callbacks** | `future.add_done_callback(fn)` | Run code when a future completes |\n",
    "| **cpu_count()** | `os.cpu_count()` | Number of logical CPUs |\n",
    "\n",
    "### Choosing the Right Executor\n",
    "\n",
    "| Scenario | Use |\n",
    "|----------|:----|\n",
    "| Heavy computation (math, parsing, compression) | `ProcessPoolExecutor` |\n",
    "| Network requests, file I/O, database queries | `ThreadPoolExecutor` |\n",
    "| Simple batch: same function, many inputs | `executor.map()` |\n",
    "| Complex: different tasks, error handling, callbacks | `executor.submit()` |\n",
    "\n",
    "### Best Practices\n",
    "- Always use executors as context managers to ensure proper cleanup\n",
    "- Define worker functions at module level (they must be picklable)\n",
    "- Use `as_completed()` when you want to process results as soon as they are ready\n",
    "- Handle exceptions from `.result()` -- they are re-raised from the worker\n",
    "- For CPU-bound tasks, `max_workers=os.cpu_count()` is a good starting point\n",
    "- Prefer `ProcessPoolExecutor` over `multiprocessing.Pool` for new code -- it has a cleaner API"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}