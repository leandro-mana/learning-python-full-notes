{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1010101",
   "metadata": {},
   "source": [
    "# Chapter 20: Profiling and Timing Python Code\n",
    "\n",
    "Before optimizing code, you must **measure** it. This notebook covers Python's built-in\n",
    "tools for timing code snippets, profiling function calls, and identifying performance\n",
    "bottlenecks.\n",
    "\n",
    "## Topics Covered\n",
    "- **timeit**: Precise micro-benchmarking of small code snippets\n",
    "- **cProfile**: Function-level profiling with call counts and timing\n",
    "- **pstats**: Analyzing and sorting profile results\n",
    "- **time.perf_counter()**: Manual high-resolution timing\n",
    "- **Decorator-based profiling**: Reusable profiling patterns\n",
    "- **Common performance traps**: String concatenation, repeated lookups, and more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2020202",
   "metadata": {},
   "source": [
    "## The timeit Module: Micro-Benchmarking\n",
    "\n",
    "`timeit` runs a code snippet many times and reports the total (or average) execution time.\n",
    "It automatically disables garbage collection during timing and uses the best available timer\n",
    "for your platform, making it ideal for comparing small code alternatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3030303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "# timeit.timeit() runs the statement `number` times and returns total seconds\n",
    "# Default number is 1_000_000\n",
    "\n",
    "# Compare list creation approaches\n",
    "time_literal = timeit.timeit(\"[1, 2, 3]\", number=1_000_000)\n",
    "time_constructor = timeit.timeit(\"list((1, 2, 3))\", number=1_000_000)\n",
    "\n",
    "print(\"Creating [1, 2, 3] one million times:\")\n",
    "print(f\"  List literal:      {time_literal:.4f}s\")\n",
    "print(f\"  list() constructor: {time_constructor:.4f}s\")\n",
    "print(f\"  Literal is {time_constructor / time_literal:.1f}x faster\")\n",
    "\n",
    "# Compare dict creation\n",
    "time_dict_literal = timeit.timeit('{\"a\": 1, \"b\": 2}', number=1_000_000)\n",
    "time_dict_constructor = timeit.timeit('dict(a=1, b=2)', number=1_000_000)\n",
    "\n",
    "print(f\"\\nCreating dict one million times:\")\n",
    "print(f\"  Dict literal: {time_dict_literal:.4f}s\")\n",
    "print(f\"  dict():       {time_dict_constructor:.4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4040404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "# timeit.repeat() runs multiple trials and returns a list of times\n",
    "# This helps identify variance in measurements\n",
    "\n",
    "results_comp = timeit.repeat(\n",
    "    \"[x**2 for x in range(100)]\",\n",
    "    repeat=5,\n",
    "    number=10_000,\n",
    ")\n",
    "\n",
    "results_map = timeit.repeat(\n",
    "    \"list(map(lambda x: x**2, range(100)))\",\n",
    "    repeat=5,\n",
    "    number=10_000,\n",
    ")\n",
    "\n",
    "print(\"Squaring 0-99, 10k iterations, 5 trials:\")\n",
    "print(f\"  List comprehension: {[f'{t:.4f}' for t in results_comp]}\")\n",
    "print(f\"  map() + lambda:     {[f'{t:.4f}' for t in results_map]}\")\n",
    "print(f\"\\n  Best comprehension: {min(results_comp):.4f}s\")\n",
    "print(f\"  Best map+lambda:    {min(results_map):.4f}s\")\n",
    "print(\"\\nNote: use min() of repeat results, not average (min reflects best case)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5050505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "# Using setup parameter for imports and initialization\n",
    "# The setup code runs once, then the statement is timed\n",
    "\n",
    "setup = \"from collections import deque; data = list(range(1000))\"\n",
    "\n",
    "time_list_pop = timeit.timeit(\n",
    "    \"data.pop(0)\",\n",
    "    setup=\"data = list(range(1000))\",\n",
    "    number=1_000,\n",
    ")\n",
    "\n",
    "time_deque_pop = timeit.timeit(\n",
    "    \"d.popleft()\",\n",
    "    setup=\"from collections import deque; d = deque(range(1000))\",\n",
    "    number=1_000,\n",
    ")\n",
    "\n",
    "print(\"Popping from the left, 1000 times:\")\n",
    "print(f\"  list.pop(0):    {time_list_pop:.6f}s\")\n",
    "print(f\"  deque.popleft(): {time_deque_pop:.6f}s\")\n",
    "print(f\"  deque is {time_list_pop / time_deque_pop:.1f}x faster\")\n",
    "\n",
    "# Timing a callable directly with timeit.timeit()\n",
    "def fibonacci(n: int) -> int:\n",
    "    \"\"\"Naive recursive fibonacci.\"\"\"\n",
    "    if n < 2:\n",
    "        return n\n",
    "    return fibonacci(n - 1) + fibonacci(n - 2)\n",
    "\n",
    "time_fib = timeit.timeit(lambda: fibonacci(20), number=100)\n",
    "print(f\"\\nfibonacci(20) x 100: {time_fib:.4f}s\")\n",
    "print(f\"  Average per call:  {time_fib / 100 * 1000:.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6060606",
   "metadata": {},
   "source": [
    "## cProfile: Function-Level Profiling\n",
    "\n",
    "`cProfile` is a deterministic profiler that records every function call, how many times it was\n",
    "called, and how long each call took. It reports both:\n",
    "- **tottime**: Time spent *inside* the function (excluding sub-calls)\n",
    "- **cumtime**: Cumulative time including all sub-calls\n",
    "\n",
    "This is the go-to tool for identifying which functions consume the most time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7070707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "\n",
    "\n",
    "def process_data(n: int) -> list[int]:\n",
    "    \"\"\"Simulate a multi-step data pipeline.\"\"\"\n",
    "    raw = generate_data(n)\n",
    "    filtered = filter_data(raw)\n",
    "    result = transform_data(filtered)\n",
    "    return result\n",
    "\n",
    "\n",
    "def generate_data(n: int) -> list[int]:\n",
    "    \"\"\"Generate a list of numbers.\"\"\"\n",
    "    return [i * 3 for i in range(n)]\n",
    "\n",
    "\n",
    "def filter_data(data: list[int]) -> list[int]:\n",
    "    \"\"\"Filter to even numbers only.\"\"\"\n",
    "    return [x for x in data if x % 2 == 0]\n",
    "\n",
    "\n",
    "def transform_data(data: list[int]) -> list[int]:\n",
    "    \"\"\"Apply an expensive transformation.\"\"\"\n",
    "    result: list[int] = []\n",
    "    for x in data:\n",
    "        result.append(slow_computation(x))\n",
    "    return result\n",
    "\n",
    "\n",
    "def slow_computation(x: int) -> int:\n",
    "    \"\"\"Simulate an expensive per-element computation.\"\"\"\n",
    "    total = 0\n",
    "    for i in range(100):\n",
    "        total += x * i\n",
    "    return total\n",
    "\n",
    "\n",
    "# Profile the pipeline\n",
    "print(\"Profiling process_data(5000):\")\n",
    "print(\"=\" * 70)\n",
    "cProfile.run(\"process_data(5000)\", sort=\"cumulative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8080808",
   "metadata": {},
   "source": [
    "## pstats: Analyzing Profile Results\n",
    "\n",
    "For more control over profile output, save the results to a `pstats.Stats` object.\n",
    "You can sort by different columns, filter by function name, and strip directory paths\n",
    "for cleaner output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9090909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "import io\n",
    "\n",
    "\n",
    "def compute_primes(limit: int) -> list[int]:\n",
    "    \"\"\"Find primes up to limit using trial division.\"\"\"\n",
    "    primes: list[int] = []\n",
    "    for num in range(2, limit):\n",
    "        if is_prime(num):\n",
    "            primes.append(num)\n",
    "    return primes\n",
    "\n",
    "\n",
    "def is_prime(n: int) -> bool:\n",
    "    \"\"\"Check if n is prime via trial division.\"\"\"\n",
    "    if n < 2:\n",
    "        return False\n",
    "    for i in range(2, int(n**0.5) + 1):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# Profile into a Stats object for analysis\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "result = compute_primes(5000)\n",
    "profiler.disable()\n",
    "\n",
    "print(f\"Found {len(result)} primes under 5000\")\n",
    "print()\n",
    "\n",
    "# Analyze with pstats\n",
    "stream = io.StringIO()\n",
    "stats = pstats.Stats(profiler, stream=stream)\n",
    "stats.strip_dirs()           # Remove directory paths for readability\n",
    "stats.sort_stats(\"tottime\")  # Sort by time spent in function\n",
    "stats.print_stats(10)        # Top 10 functions\n",
    "print(stream.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0101010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "import io\n",
    "\n",
    "\n",
    "def run_simulation(iterations: int) -> float:\n",
    "    \"\"\"Run a multi-step simulation.\"\"\"\n",
    "    total: float = 0.0\n",
    "    for i in range(iterations):\n",
    "        value = step_one(i)\n",
    "        value = step_two(value)\n",
    "        total += step_three(value)\n",
    "    return total\n",
    "\n",
    "\n",
    "def step_one(x: int) -> float:\n",
    "    \"\"\"First processing step.\"\"\"\n",
    "    return sum(i * 0.1 for i in range(x % 50))\n",
    "\n",
    "\n",
    "def step_two(x: float) -> float:\n",
    "    \"\"\"Second processing step (deliberately slow).\"\"\"\n",
    "    result = x\n",
    "    for _ in range(200):\n",
    "        result = (result + 1.0) * 0.999\n",
    "    return result\n",
    "\n",
    "\n",
    "def step_three(x: float) -> float:\n",
    "    \"\"\"Third processing step.\"\"\"\n",
    "    return x ** 0.5\n",
    "\n",
    "\n",
    "# Identifying bottlenecks: sort by cumtime vs tottime\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "run_simulation(500)\n",
    "profiler.disable()\n",
    "\n",
    "# Sort by cumulative time (includes sub-calls)\n",
    "stream = io.StringIO()\n",
    "stats = pstats.Stats(profiler, stream=stream)\n",
    "stats.strip_dirs()\n",
    "print(\"Sorted by CUMULATIVE time (cumtime):\")\n",
    "stats.sort_stats(\"cumulative\")\n",
    "stats.print_stats(8)\n",
    "print(stream.getvalue())\n",
    "\n",
    "# Sort by total time in function (excludes sub-calls)\n",
    "stream2 = io.StringIO()\n",
    "stats2 = pstats.Stats(profiler, stream=stream2)\n",
    "stats2.strip_dirs()\n",
    "print(\"\\nSorted by TOTAL time in function (tottime):\")\n",
    "stats2.sort_stats(\"tottime\")\n",
    "stats2.print_stats(8)\n",
    "print(stream2.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1111111",
   "metadata": {},
   "source": [
    "## time.perf_counter(): Manual High-Resolution Timing\n",
    "\n",
    "When you need to time a specific section of code (not just a function call), use\n",
    "`time.perf_counter()`. It provides the highest resolution clock available on your system\n",
    "and includes time spent sleeping. For measuring only CPU time, use `time.process_time()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2121212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# time.perf_counter() for wall-clock time\n",
    "start = time.perf_counter()\n",
    "total = sum(i * i for i in range(1_000_000))\n",
    "end = time.perf_counter()\n",
    "print(f\"Sum of squares (1M): {end - start:.4f}s\")\n",
    "\n",
    "# time.perf_counter_ns() for nanosecond precision\n",
    "start_ns = time.perf_counter_ns()\n",
    "result = sorted([5, 3, 1, 4, 2])\n",
    "end_ns = time.perf_counter_ns()\n",
    "print(f\"Sorting 5 elements: {end_ns - start_ns} ns\")\n",
    "\n",
    "# time.process_time() measures only CPU time (not sleep/IO)\n",
    "cpu_start = time.process_time()\n",
    "data = [x ** 2 for x in range(500_000)]\n",
    "cpu_end = time.process_time()\n",
    "print(f\"\\nCPU time for 500k squares: {cpu_end - cpu_start:.4f}s\")\n",
    "\n",
    "# Demonstrate the difference: perf_counter includes sleep, process_time does not\n",
    "wall_start = time.perf_counter()\n",
    "cpu_start = time.process_time()\n",
    "time.sleep(0.1)  # Sleep 100ms\n",
    "_ = sum(range(100_000))\n",
    "wall_end = time.perf_counter()\n",
    "cpu_end = time.process_time()\n",
    "\n",
    "print(f\"\\nWith 100ms sleep + computation:\")\n",
    "print(f\"  Wall clock (perf_counter): {wall_end - wall_start:.4f}s\")\n",
    "print(f\"  CPU time (process_time):   {cpu_end - cpu_start:.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3131313",
   "metadata": {},
   "source": [
    "## Profiling Patterns: Decorator-Based Profiling\n",
    "\n",
    "A profiling decorator makes it easy to measure any function without modifying its code.\n",
    "This is a reusable pattern you can drop into any project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4141414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "from typing import Any, Callable, TypeVar\n",
    "\n",
    "F = TypeVar(\"F\", bound=Callable[..., Any])\n",
    "\n",
    "\n",
    "def timer(func: F) -> F:\n",
    "    \"\"\"Decorator that prints execution time of the wrapped function.\"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args: Any, **kwargs: Any) -> Any:\n",
    "        start = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        elapsed = time.perf_counter() - start\n",
    "        print(f\"  {func.__name__}() took {elapsed:.4f}s\")\n",
    "        return result\n",
    "    return wrapper  # type: ignore[return-value]\n",
    "\n",
    "\n",
    "def call_counter(func: F) -> F:\n",
    "    \"\"\"Decorator that counts how many times a function is called.\"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args: Any, **kwargs: Any) -> Any:\n",
    "        wrapper.call_count += 1  # type: ignore[attr-defined]\n",
    "        return func(*args, **kwargs)\n",
    "    wrapper.call_count = 0  # type: ignore[attr-defined]\n",
    "    return wrapper  # type: ignore[return-value]\n",
    "\n",
    "\n",
    "# Using the timer decorator\n",
    "@timer\n",
    "def slow_sort(data: list[int]) -> list[int]:\n",
    "    \"\"\"Bubble sort - deliberately slow for demonstration.\"\"\"\n",
    "    arr = data.copy()\n",
    "    n = len(arr)\n",
    "    for i in range(n):\n",
    "        for j in range(0, n - i - 1):\n",
    "            if arr[j] > arr[j + 1]:\n",
    "                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n",
    "    return arr\n",
    "\n",
    "\n",
    "@timer\n",
    "def fast_sort(data: list[int]) -> list[int]:\n",
    "    \"\"\"Built-in sort (Timsort).\"\"\"\n",
    "    return sorted(data)\n",
    "\n",
    "\n",
    "import random\n",
    "test_data = [random.randint(0, 10_000) for _ in range(5_000)]\n",
    "\n",
    "print(\"Sorting 5,000 random integers:\")\n",
    "result1 = slow_sort(test_data)\n",
    "result2 = fast_sort(test_data)\n",
    "print(f\"  Results match: {result1 == result2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5151515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "from typing import Any, Callable\n",
    "\n",
    "\n",
    "def profile_stats(func: Callable[..., Any]) -> Callable[..., Any]:\n",
    "    \"\"\"Decorator that accumulates timing statistics across multiple calls.\"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args: Any, **kwargs: Any) -> Any:\n",
    "        start = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        elapsed = time.perf_counter() - start\n",
    "        wrapper._times.append(elapsed)  # type: ignore[attr-defined]\n",
    "        return result\n",
    "\n",
    "    wrapper._times: list[float] = []  # type: ignore[attr-defined]\n",
    "\n",
    "    def get_stats() -> dict[str, float]:\n",
    "        times = wrapper._times  # type: ignore[attr-defined]\n",
    "        if not times:\n",
    "            return {\"calls\": 0}\n",
    "        return {\n",
    "            \"calls\": len(times),\n",
    "            \"total\": sum(times),\n",
    "            \"avg\": sum(times) / len(times),\n",
    "            \"min\": min(times),\n",
    "            \"max\": max(times),\n",
    "        }\n",
    "\n",
    "    wrapper.get_stats = get_stats  # type: ignore[attr-defined]\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "@profile_stats\n",
    "def process_item(x: int) -> int:\n",
    "    \"\"\"Simulate variable-cost processing.\"\"\"\n",
    "    return sum(range(x))\n",
    "\n",
    "\n",
    "# Run the function many times with varying input sizes\n",
    "for i in range(100):\n",
    "    process_item(i * 100)\n",
    "\n",
    "# Inspect accumulated statistics\n",
    "stats = process_item.get_stats()  # type: ignore[attr-defined]\n",
    "print(\"Profile statistics for process_item():\")\n",
    "for key, value in stats.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.6f}s\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6161616",
   "metadata": {},
   "source": [
    "## Common Performance Traps\n",
    "\n",
    "Certain coding patterns are deceptively slow. Measuring them with `timeit` makes the\n",
    "cost obvious and helps you choose better alternatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7171717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "# Trap 1: String concatenation in a loop\n",
    "# Strings are immutable, so += creates a new string each time: O(n^2)\n",
    "\n",
    "def concat_with_plus(n: int) -> str:\n",
    "    \"\"\"Build a string using += (slow).\"\"\"\n",
    "    result = \"\"\n",
    "    for i in range(n):\n",
    "        result += str(i) + \" \"\n",
    "    return result\n",
    "\n",
    "\n",
    "def concat_with_join(n: int) -> str:\n",
    "    \"\"\"Build a string using join (fast).\"\"\"\n",
    "    return \" \".join(str(i) for i in range(n))\n",
    "\n",
    "\n",
    "def concat_with_list(n: int) -> str:\n",
    "    \"\"\"Build a string by appending to a list, then joining.\"\"\"\n",
    "    parts: list[str] = []\n",
    "    for i in range(n):\n",
    "        parts.append(str(i))\n",
    "    return \" \".join(parts)\n",
    "\n",
    "\n",
    "n = 10_000\n",
    "t_plus = timeit.timeit(lambda: concat_with_plus(n), number=10)\n",
    "t_join = timeit.timeit(lambda: concat_with_join(n), number=10)\n",
    "t_list = timeit.timeit(lambda: concat_with_list(n), number=10)\n",
    "\n",
    "print(f\"String concatenation ({n} items, 10 runs):\")\n",
    "print(f\"  += loop:        {t_plus:.4f}s\")\n",
    "print(f\"  join(genexpr):  {t_join:.4f}s\")\n",
    "print(f\"  list + join:    {t_list:.4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8181818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "# Trap 2: Repeated attribute/method lookups in tight loops\n",
    "# Each dot lookup (e.g., math.sqrt) is a dictionary lookup\n",
    "\n",
    "setup = \"import math; data = list(range(1, 10001))\"\n",
    "\n",
    "# Slow: repeated global + attribute lookup\n",
    "slow_code = \"\"\"\n",
    "result = []\n",
    "for x in data:\n",
    "    result.append(math.sqrt(x))\n",
    "\"\"\"\n",
    "\n",
    "# Fast: cache the method lookup and the append method\n",
    "fast_code = \"\"\"\n",
    "sqrt = math.sqrt\n",
    "result = []\n",
    "append = result.append\n",
    "for x in data:\n",
    "    append(sqrt(x))\n",
    "\"\"\"\n",
    "\n",
    "# Fastest: use a list comprehension (implicit optimization)\n",
    "fastest_code = \"result = [math.sqrt(x) for x in data]\"\n",
    "\n",
    "t_slow = timeit.timeit(slow_code, setup=setup, number=1000)\n",
    "t_fast = timeit.timeit(fast_code, setup=setup, number=1000)\n",
    "t_fastest = timeit.timeit(fastest_code, setup=setup, number=1000)\n",
    "\n",
    "print(\"sqrt() over 10k items, 1000 runs:\")\n",
    "print(f\"  Repeated lookups:   {t_slow:.4f}s\")\n",
    "print(f\"  Cached lookups:     {t_fast:.4f}s\")\n",
    "print(f\"  List comprehension: {t_fastest:.4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9191919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "# Trap 3: Checking membership in a list vs a set\n",
    "# list membership is O(n), set membership is O(1)\n",
    "\n",
    "setup_list = \"data = list(range(10000))\"\n",
    "setup_set = \"data = set(range(10000))\"\n",
    "\n",
    "# Worst case: item not found (must scan entire list)\n",
    "t_list = timeit.timeit(\"9999 in data\", setup=setup_list, number=100_000)\n",
    "t_set = timeit.timeit(\"9999 in data\", setup=setup_set, number=100_000)\n",
    "\n",
    "print(\"Membership test (item at end), 100k checks:\")\n",
    "print(f\"  list: {t_list:.4f}s\")\n",
    "print(f\"  set:  {t_set:.4f}s\")\n",
    "print(f\"  set is {t_list / t_set:.0f}x faster\")\n",
    "\n",
    "# Trap 4: Creating objects unnecessarily in loops\n",
    "t_create = timeit.timeit(\n",
    "    \"[tuple(range(10)) for _ in range(1000)]\",\n",
    "    number=1000,\n",
    ")\n",
    "t_reuse = timeit.timeit(\n",
    "    \"[t for _ in range(1000)]\",\n",
    "    setup=\"t = tuple(range(10))\",\n",
    "    number=1000,\n",
    ")\n",
    "\n",
    "print(f\"\\nCreating vs reusing a tuple, 1000x1000:\")\n",
    "print(f\"  Create each time: {t_create:.4f}s\")\n",
    "print(f\"  Reuse one object: {t_reuse:.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0202020",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "| Tool | Use Case | Key Function |\n",
    "|------|----------|-------------|\n",
    "| **timeit** | Micro-benchmark small snippets | `timeit.timeit()`, `timeit.repeat()` |\n",
    "| **cProfile** | Profile all function calls | `cProfile.run()`, `cProfile.Profile()` |\n",
    "| **pstats** | Analyze profile results | `Stats.sort_stats()`, `Stats.print_stats()` |\n",
    "| **time.perf_counter()** | Manual wall-clock timing | High-resolution, includes sleep |\n",
    "| **time.process_time()** | CPU-only timing | Excludes sleep and I/O wait |\n",
    "\n",
    "### Profiling Workflow\n",
    "1. **Measure first** -- never guess where bottlenecks are\n",
    "2. **Use `cProfile`** to find which functions take the most time\n",
    "3. **Sort by `cumtime`** to find the \"big picture\" bottlenecks\n",
    "4. **Sort by `tottime`** to find where CPU time is actually spent\n",
    "5. **Use `timeit`** to compare alternative implementations\n",
    "6. **Re-measure** after each change to verify improvement\n",
    "\n",
    "### Common Traps to Avoid\n",
    "- String concatenation with `+=` in loops (use `\"\".join()` instead)\n",
    "- Repeated attribute lookups in tight loops (cache with local variables)\n",
    "- Membership testing in `list` when `set` would suffice\n",
    "- Creating identical objects repeatedly instead of reusing them"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}