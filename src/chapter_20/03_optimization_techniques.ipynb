{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa110011",
   "metadata": {},
   "source": [
    "# Chapter 20: Optimization Techniques\n",
    "\n",
    "Once you have profiled your code and identified bottlenecks, this notebook covers the\n",
    "techniques available to make Python code faster and more memory-efficient. The golden rule:\n",
    "**profile first, optimize algorithmic complexity, then micro-optimize**.\n",
    "\n",
    "## Topics Covered\n",
    "- **`__slots__`**: Memory optimization for classes\n",
    "- **Algorithmic improvements**: O(n) vs O(n^2) with measurements\n",
    "- **`dis` module**: Bytecode disassembly\n",
    "- **Code object attributes**: `co_varnames`, `co_consts`, etc.\n",
    "- **Generators vs list comprehensions**: Memory trade-offs\n",
    "- **Local vs global variable access**: `LOAD_FAST` vs `LOAD_GLOBAL`\n",
    "- **`collections` and built-in optimizations**\n",
    "- **The GIL**: Threading vs multiprocessing\n",
    "- **`ctypes` overview**: Calling C from Python\n",
    "- **Optimization guidelines**: A practical workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb220022",
   "metadata": {},
   "source": [
    "## `__slots__` for Memory Optimization\n",
    "\n",
    "By default, Python stores instance attributes in a per-object `__dict__` dictionary. For\n",
    "classes with many instances, this is wasteful. Defining `__slots__` replaces `__dict__` with\n",
    "a fixed-size struct, reducing memory per instance significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc330033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "class PointDict:\n",
    "    \"\"\"Regular class with __dict__.\"\"\"\n",
    "    def __init__(self, x: float, y: float, z: float) -> None:\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "\n",
    "\n",
    "class PointSlots:\n",
    "    \"\"\"Slotted class - no __dict__.\"\"\"\n",
    "    __slots__ = (\"x\", \"y\", \"z\")\n",
    "\n",
    "    def __init__(self, x: float, y: float, z: float) -> None:\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "\n",
    "\n",
    "# Compare single-instance memory\n",
    "pd = PointDict(1.0, 2.0, 3.0)\n",
    "ps = PointSlots(1.0, 2.0, 3.0)\n",
    "\n",
    "print(\"Single instance memory:\")\n",
    "print(f\"  PointDict:  {sys.getsizeof(pd)} + __dict__: {sys.getsizeof(pd.__dict__)} bytes\")\n",
    "print(f\"  PointSlots: {sys.getsizeof(ps)} bytes (no __dict__)\")\n",
    "\n",
    "# Measure memory for many instances\n",
    "n = 100_000\n",
    "dict_objects = [PointDict(1.0, 2.0, 3.0) for _ in range(n)]\n",
    "slots_objects = [PointSlots(1.0, 2.0, 3.0) for _ in range(n)]\n",
    "\n",
    "# Approximate total memory (instance + __dict__ for dict version)\n",
    "dict_total = sum(sys.getsizeof(o) + sys.getsizeof(o.__dict__) for o in dict_objects[:100]) / 100\n",
    "slots_total = sum(sys.getsizeof(o) for o in slots_objects[:100]) / 100\n",
    "\n",
    "print(f\"\\nEstimated per-object cost ({n:,} instances):\")\n",
    "print(f\"  PointDict:  ~{dict_total:.0f} bytes/obj = ~{dict_total * n / 1024 / 1024:.1f} MB total\")\n",
    "print(f\"  PointSlots: ~{slots_total:.0f} bytes/obj = ~{slots_total * n / 1024 / 1024:.1f} MB total\")\n",
    "print(f\"  Savings: ~{(1 - slots_total / dict_total) * 100:.0f}%\")\n",
    "\n",
    "# __slots__ also prevents adding arbitrary attributes\n",
    "try:\n",
    "    ps.w = 4.0  # type: ignore[attr-defined]\n",
    "except AttributeError as e:\n",
    "    print(f\"\\nCannot add attributes to slotted class: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd440044",
   "metadata": {},
   "source": [
    "## Algorithmic Improvements: O(n) vs O(n^2)\n",
    "\n",
    "The single most impactful optimization is choosing a better algorithm. A constant-factor\n",
    "micro-optimization cannot save code that has the wrong Big-O complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee550055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def has_duplicates_quadratic(data: list[int]) -> bool:\n",
    "    \"\"\"O(n^2): Check every pair for duplicates.\"\"\"\n",
    "    n = len(data)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if data[i] == data[j]:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def has_duplicates_linear(data: list[int]) -> bool:\n",
    "    \"\"\"O(n): Use a set for constant-time lookup.\"\"\"\n",
    "    seen: set[int] = set()\n",
    "    for item in data:\n",
    "        if item in seen:\n",
    "            return True\n",
    "        seen.add(item)\n",
    "    return False\n",
    "\n",
    "\n",
    "def has_duplicates_pythonic(data: list[int]) -> bool:\n",
    "    \"\"\"O(n): Idiomatic Python -- compare len to set.\"\"\"\n",
    "    return len(data) != len(set(data))\n",
    "\n",
    "\n",
    "# Benchmark with increasing sizes\n",
    "print(f\"{'Size':>8} {'O(n^2)':>12} {'O(n) set':>12} {'Pythonic':>12}\")\n",
    "print(\"-\" * 48)\n",
    "\n",
    "for size in [1_000, 5_000, 10_000, 20_000]:\n",
    "    # No duplicates (worst case for quadratic)\n",
    "    data = list(range(size))\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    has_duplicates_quadratic(data)\n",
    "    t_quad = time.perf_counter() - start\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    has_duplicates_linear(data)\n",
    "    t_linear = time.perf_counter() - start\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    has_duplicates_pythonic(data)\n",
    "    t_pythonic = time.perf_counter() - start\n",
    "\n",
    "    print(f\"{size:>8,} {t_quad:>11.4f}s {t_linear:>11.6f}s {t_pythonic:>11.6f}s\")\n",
    "\n",
    "print(\"\\nNote how O(n^2) grows ~4x when n doubles, while O(n) grows ~2x.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff660066",
   "metadata": {},
   "source": [
    "## The `dis` Module: Bytecode Disassembly\n",
    "\n",
    "Python compiles source code to bytecode, which the CPython virtual machine then executes.\n",
    "The `dis` module lets you inspect this bytecode. This is useful for understanding *why*\n",
    "one approach is faster than another at the lowest level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa770077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dis\n",
    "\n",
    "\n",
    "def add_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Simple addition function.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def add_with_temp(a: int, b: int) -> int:\n",
    "    \"\"\"Addition with a temporary variable.\"\"\"\n",
    "    result = a + b\n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"Bytecode for add_numbers:\")\n",
    "dis.dis(add_numbers)\n",
    "\n",
    "print(\"\\nBytecode for add_with_temp:\")\n",
    "dis.dis(add_with_temp)\n",
    "\n",
    "print(\"\\nKey instructions:\")\n",
    "print(\"  LOAD_FAST    - Load a local variable (fast, indexed by position)\")\n",
    "print(\"  BINARY_OP    - Perform a binary operation (+, -, *, etc.)\")\n",
    "print(\"  STORE_FAST   - Store to a local variable\")\n",
    "print(\"  RETURN_VALUE - Return the top of the stack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb880088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dis\n",
    "\n",
    "# Compare: list comprehension vs manual loop\n",
    "def with_comprehension() -> list[int]:\n",
    "    return [x * 2 for x in range(10)]\n",
    "\n",
    "def with_loop() -> list[int]:\n",
    "    result: list[int] = []\n",
    "    for x in range(10):\n",
    "        result.append(x * 2)\n",
    "    return result\n",
    "\n",
    "print(\"List comprehension bytecode:\")\n",
    "dis.dis(with_comprehension)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\nManual loop bytecode:\")\n",
    "dis.dis(with_loop)\n",
    "\n",
    "print(\"\\nThe comprehension uses a specialized BUILD_LIST + LIST_APPEND\")\n",
    "print(\"path that avoids the overhead of LOAD_ATTR for .append().\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc990099",
   "metadata": {},
   "source": [
    "## Code Object Attributes\n",
    "\n",
    "Every function has a `__code__` object containing its compiled bytecode and metadata.\n",
    "Inspecting these attributes reveals how Python organizes function internals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd001100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_function(x: int, y: int, z: int = 10) -> int:\n",
    "    \"\"\"A function with locals, constants, and a default.\"\"\"\n",
    "    multiplier = 2\n",
    "    offset = 100\n",
    "    result = (x + y + z) * multiplier + offset\n",
    "    return result\n",
    "\n",
    "\n",
    "code = example_function.__code__\n",
    "\n",
    "print(\"Code object attributes:\")\n",
    "print(f\"  co_argcount:   {code.co_argcount}\")       # Number of positional args\n",
    "print(f\"  co_varnames:   {code.co_varnames}\")       # Local variable names (args first)\n",
    "print(f\"  co_consts:     {code.co_consts}\")         # Constant values used\n",
    "print(f\"  co_names:      {code.co_names}\")          # Names used (global lookups)\n",
    "print(f\"  co_nlocals:    {code.co_nlocals}\")        # Number of local variables\n",
    "print(f\"  co_stacksize:  {code.co_stacksize}\")      # Max stack depth needed\n",
    "print(f\"  co_filename:   {code.co_filename}\")       # Source file\n",
    "\n",
    "# Constants are pre-computed at compile time\n",
    "print(f\"\\nConstants include: docstring, default values, and literal numbers\")\n",
    "print(f\"Note: co_varnames includes args first, then locals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee111111",
   "metadata": {},
   "source": [
    "## Generator Expressions vs List Comprehensions: Memory\n",
    "\n",
    "A list comprehension builds the entire list in memory. A generator expression yields\n",
    "one item at a time, using near-constant memory regardless of data size. When you only\n",
    "need to iterate once, generators are the better choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff221122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# List comprehension: builds entire list in memory\n",
    "list_comp = [x * x for x in range(1_000_000)]\n",
    "\n",
    "# Generator expression: lazy, constant memory\n",
    "gen_expr = (x * x for x in range(1_000_000))\n",
    "\n",
    "print(\"Memory comparison (1M items):\")\n",
    "print(f\"  List comprehension: {sys.getsizeof(list_comp):>12,} bytes\")\n",
    "print(f\"  Generator expr:     {sys.getsizeof(gen_expr):>12,} bytes\")\n",
    "\n",
    "# Both produce the same result when consumed\n",
    "print(f\"\\n  sum(list_comp): {sum(list_comp)}\")\n",
    "print(f\"  sum(gen_expr):  {sum(gen_expr)}\")\n",
    "\n",
    "# Functions like sum(), min(), max(), any(), all() accept iterables\n",
    "# so you can feed them generators directly\n",
    "import timeit\n",
    "\n",
    "t_list = timeit.timeit(\"sum([x*x for x in range(10_000)])\", number=1000)\n",
    "t_gen = timeit.timeit(\"sum(x*x for x in range(10_000))\", number=1000)\n",
    "\n",
    "print(f\"\\nsum() with 10k items, 1000 runs:\")\n",
    "print(f\"  List comp: {t_list:.4f}s\")\n",
    "print(f\"  Generator: {t_gen:.4f}s\")\n",
    "print(\"  Generator avoids allocating and freeing a temporary list.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa331133",
   "metadata": {},
   "source": [
    "## Local Variable Access vs Global: LOAD_FAST vs LOAD_GLOBAL\n",
    "\n",
    "Local variables are stored in a fixed-size array and accessed by index (`LOAD_FAST`).\n",
    "Global and built-in lookups require dictionary lookups (`LOAD_GLOBAL`). In tight loops,\n",
    "this difference matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb441144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dis\n",
    "import timeit\n",
    "\n",
    "GLOBAL_MULTIPLIER: int = 3\n",
    "\n",
    "\n",
    "def use_global(data: list[int]) -> list[int]:\n",
    "    \"\"\"Access a global variable in a loop.\"\"\"\n",
    "    return [x * GLOBAL_MULTIPLIER for x in data]\n",
    "\n",
    "\n",
    "def use_local(data: list[int]) -> list[int]:\n",
    "    \"\"\"Cache the global as a local variable.\"\"\"\n",
    "    multiplier = GLOBAL_MULTIPLIER  # One LOAD_GLOBAL, then LOAD_FAST\n",
    "    return [x * multiplier for x in data]\n",
    "\n",
    "\n",
    "# Show the bytecode difference\n",
    "print(\"use_global bytecode:\")\n",
    "dis.dis(use_global)\n",
    "\n",
    "print(\"\\nuse_local bytecode:\")\n",
    "dis.dis(use_local)\n",
    "\n",
    "# Benchmark\n",
    "data = list(range(100_000))\n",
    "t_global = timeit.timeit(lambda: use_global(data), number=100)\n",
    "t_local = timeit.timeit(lambda: use_local(data), number=100)\n",
    "\n",
    "print(f\"\\n100k items, 100 runs:\")\n",
    "print(f\"  Global lookup:     {t_global:.4f}s\")\n",
    "print(f\"  Local (cached):    {t_local:.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc551155",
   "metadata": {},
   "source": [
    "## Collections and Built-in Optimizations\n",
    "\n",
    "Python's standard library is written in C and heavily optimized. Using built-in functions\n",
    "and `collections` types is almost always faster than reimplementing their logic in pure Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd661166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "from collections import Counter, defaultdict, deque\n",
    "\n",
    "# Built-in sum() vs manual loop\n",
    "setup = \"data = list(range(10_000))\"\n",
    "\n",
    "t_builtin = timeit.timeit(\"sum(data)\", setup=setup, number=10_000)\n",
    "t_manual = timeit.timeit(\n",
    "    \"total = 0\\nfor x in data:\\n    total += x\",\n",
    "    setup=setup,\n",
    "    number=10_000,\n",
    ")\n",
    "\n",
    "print(\"Summing 10k ints, 10k runs:\")\n",
    "print(f\"  Built-in sum():  {t_builtin:.4f}s\")\n",
    "print(f\"  Manual loop:     {t_manual:.4f}s\")\n",
    "print(f\"  Built-in is {t_manual / t_builtin:.1f}x faster\")\n",
    "\n",
    "# Counter vs manual counting\n",
    "words = [\"apple\", \"banana\", \"cherry\"] * 3000\n",
    "\n",
    "def manual_count(words: list[str]) -> dict[str, int]:\n",
    "    counts: dict[str, int] = {}\n",
    "    for w in words:\n",
    "        counts[w] = counts.get(w, 0) + 1\n",
    "    return counts\n",
    "\n",
    "t_counter = timeit.timeit(lambda: Counter(words), number=1_000)\n",
    "t_manual_c = timeit.timeit(lambda: manual_count(words), number=1_000)\n",
    "\n",
    "print(f\"\\nCounting 9k words, 1k runs:\")\n",
    "print(f\"  Counter():      {t_counter:.4f}s\")\n",
    "print(f\"  Manual dict:    {t_manual_c:.4f}s\")\n",
    "\n",
    "# deque.appendleft() vs list.insert(0, x)\n",
    "t_deque = timeit.timeit(\n",
    "    \"d.appendleft(1)\",\n",
    "    setup=\"from collections import deque; d = deque(range(10000))\",\n",
    "    number=100_000,\n",
    ")\n",
    "t_list_ins = timeit.timeit(\n",
    "    \"lst.insert(0, 1)\",\n",
    "    setup=\"lst = list(range(10000))\",\n",
    "    number=100_000,\n",
    ")\n",
    "\n",
    "print(f\"\\nPrepend 100k times to a 10k-item container:\")\n",
    "print(f\"  deque.appendleft(): {t_deque:.4f}s\")\n",
    "print(f\"  list.insert(0):     {t_list_ins:.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee771177",
   "metadata": {},
   "source": [
    "## The GIL: Global Interpreter Lock\n",
    "\n",
    "CPython has a **Global Interpreter Lock (GIL)** that allows only one thread to execute\n",
    "Python bytecode at a time. This means:\n",
    "\n",
    "- **Threading** is useful for I/O-bound work (network, disk) where threads spend most\n",
    "  time waiting, but **not** for CPU-bound work.\n",
    "- **Multiprocessing** spawns separate processes, each with its own GIL, enabling true\n",
    "  parallelism for CPU-bound tasks.\n",
    "\n",
    "> **Note**: Python 3.13 introduced an experimental free-threaded build (PEP 703) that\n",
    "> can disable the GIL. This is still experimental and not the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff881188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "def cpu_bound_work(n: int) -> int:\n",
    "    \"\"\"CPU-intensive computation.\"\"\"\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        total += i * i\n",
    "    return total\n",
    "\n",
    "\n",
    "WORK_SIZE = 5_000_000\n",
    "NUM_TASKS = 4\n",
    "\n",
    "# Sequential execution\n",
    "start = time.perf_counter()\n",
    "for _ in range(NUM_TASKS):\n",
    "    cpu_bound_work(WORK_SIZE)\n",
    "t_sequential = time.perf_counter() - start\n",
    "\n",
    "# Threaded execution (GIL limits parallelism for CPU work)\n",
    "start = time.perf_counter()\n",
    "threads = [threading.Thread(target=cpu_bound_work, args=(WORK_SIZE,)) for _ in range(NUM_TASKS)]\n",
    "for t in threads:\n",
    "    t.start()\n",
    "for t in threads:\n",
    "    t.join()\n",
    "t_threaded = time.perf_counter() - start\n",
    "\n",
    "# Multiprocessing execution (true parallelism)\n",
    "start = time.perf_counter()\n",
    "with multiprocessing.Pool(NUM_TASKS) as pool:\n",
    "    pool.map(cpu_bound_work, [WORK_SIZE] * NUM_TASKS)\n",
    "t_multiproc = time.perf_counter() - start\n",
    "\n",
    "print(f\"CPU-bound work: {NUM_TASKS} tasks x {WORK_SIZE:,} iterations\")\n",
    "print(f\"  Sequential:      {t_sequential:.3f}s\")\n",
    "print(f\"  Threading:       {t_threaded:.3f}s  (GIL prevents speedup)\")\n",
    "print(f\"  Multiprocessing: {t_multiproc:.3f}s  (true parallelism)\")\n",
    "print(f\"\\nThreading speedup:       {t_sequential / t_threaded:.2f}x\")\n",
    "print(f\"Multiprocessing speedup: {t_sequential / t_multiproc:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa991199",
   "metadata": {},
   "source": [
    "## ctypes Overview: Calling C Functions from Python\n",
    "\n",
    "`ctypes` allows Python to call functions in shared C libraries (`.so` on Linux, `.dylib`\n",
    "on macOS, `.dll` on Windows) without writing any C extension code. This is useful for\n",
    "performance-critical sections or interfacing with existing C libraries.\n",
    "\n",
    "This is a **conceptual overview** -- we will call functions from the C standard library\n",
    "to demonstrate the mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb002200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "import ctypes.util\n",
    "import sys\n",
    "\n",
    "# Load the C standard library\n",
    "if sys.platform == \"darwin\":\n",
    "    libc = ctypes.CDLL(\"libSystem.B.dylib\")\n",
    "elif sys.platform == \"linux\":\n",
    "    libc_path = ctypes.util.find_library(\"c\")\n",
    "    libc = ctypes.CDLL(libc_path)\n",
    "else:\n",
    "    libc = ctypes.CDLL(\"msvcrt\")  # Windows\n",
    "\n",
    "# Call C's abs() function\n",
    "libc.abs.restype = ctypes.c_int\n",
    "libc.abs.argtypes = [ctypes.c_int]\n",
    "\n",
    "result = libc.abs(-42)\n",
    "print(f\"C abs(-42) = {result}\")\n",
    "\n",
    "# Call C's strlen() on a byte string\n",
    "libc.strlen.restype = ctypes.c_size_t\n",
    "libc.strlen.argtypes = [ctypes.c_char_p]\n",
    "\n",
    "length = libc.strlen(b\"Hello, ctypes!\")\n",
    "print(f\"C strlen('Hello, ctypes!') = {length}\")\n",
    "\n",
    "# Conceptual: for real performance gains, you would:\n",
    "# 1. Write a C function that performs your hot loop\n",
    "# 2. Compile it into a shared library\n",
    "# 3. Load it with ctypes and call it from Python\n",
    "print(\"\\nctypes workflow:\")\n",
    "print(\"  1. Write C code -> compile to .so / .dylib / .dll\")\n",
    "print(\"  2. ctypes.CDLL('mylib.so')\")\n",
    "print(\"  3. Set .restype and .argtypes for type safety\")\n",
    "print(\"  4. Call functions directly from Python\")\n",
    "print(\"\\nAlternatives: cffi, Cython, pybind11, or the new C API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc113311",
   "metadata": {},
   "source": [
    "## Optimization Guidelines: A Practical Workflow\n",
    "\n",
    "Follow this order when optimizing Python code:\n",
    "\n",
    "1. **Write correct code first** -- premature optimization is the root of all evil\n",
    "2. **Profile** with `cProfile` to find actual bottlenecks (do not guess)\n",
    "3. **Fix algorithmic complexity** -- O(n) vs O(n^2) matters far more than micro-tuning\n",
    "4. **Use built-in functions and C-implemented types** (`sum`, `sorted`, `Counter`, `deque`)\n",
    "5. **Reduce memory pressure** -- `__slots__`, generators, avoid unnecessary copies\n",
    "6. **Micro-optimize hot loops** -- local variable caching, list comprehensions\n",
    "7. **Consider C extensions** -- `ctypes`, `Cython`, `pybind11` for truly hot code\n",
    "8. **Use multiprocessing** for CPU-bound parallelism (not threading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd224422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "# Putting it all together: optimizing a word frequency counter\n",
    "# Step by step, from naive to optimized\n",
    "\n",
    "sample_text = \"the quick brown fox jumps over the lazy dog \" * 10_000\n",
    "\n",
    "\n",
    "def v1_naive(text: str) -> dict[str, int]:\n",
    "    \"\"\"Version 1: Naive implementation.\"\"\"\n",
    "    words = text.split()\n",
    "    counts: dict[str, int] = {}\n",
    "    for word in words:\n",
    "        if word in counts:\n",
    "            counts[word] = counts[word] + 1\n",
    "        else:\n",
    "            counts[word] = 1\n",
    "    return counts\n",
    "\n",
    "\n",
    "def v2_get_default(text: str) -> dict[str, int]:\n",
    "    \"\"\"Version 2: Use dict.get() with default.\"\"\"\n",
    "    words = text.split()\n",
    "    counts: dict[str, int] = {}\n",
    "    for word in words:\n",
    "        counts[word] = counts.get(word, 0) + 1\n",
    "    return counts\n",
    "\n",
    "\n",
    "def v3_defaultdict(text: str) -> dict[str, int]:\n",
    "    \"\"\"Version 3: Use defaultdict(int).\"\"\"\n",
    "    from collections import defaultdict\n",
    "    words = text.split()\n",
    "    counts: defaultdict[str, int] = defaultdict(int)\n",
    "    for word in words:\n",
    "        counts[word] += 1\n",
    "    return dict(counts)\n",
    "\n",
    "\n",
    "def v4_counter(text: str) -> dict[str, int]:\n",
    "    \"\"\"Version 4: Use Counter (C-optimized).\"\"\"\n",
    "    from collections import Counter\n",
    "    return dict(Counter(text.split()))\n",
    "\n",
    "\n",
    "# Benchmark all versions\n",
    "versions = [\n",
    "    (\"v1: naive if/else\", v1_naive),\n",
    "    (\"v2: dict.get()\", v2_get_default),\n",
    "    (\"v3: defaultdict\", v3_defaultdict),\n",
    "    (\"v4: Counter\", v4_counter),\n",
    "]\n",
    "\n",
    "print(f\"Word frequency counting: {len(sample_text.split()):,} words\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "for name, func in versions:\n",
    "    t = timeit.timeit(lambda f=func: f(sample_text), number=50)\n",
    "    print(f\"  {name:<22s} {t:.4f}s (50 runs)\")\n",
    "\n",
    "# Verify all produce the same result\n",
    "results = [func(sample_text) for _, func in versions]\n",
    "print(f\"\\nAll versions agree: {all(r == results[0] for r in results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee335533",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Optimization Hierarchy (Most to Least Impact)\n",
    "\n",
    "| Priority | Technique | Typical Speedup |\n",
    "|----------|-----------|----------------|\n",
    "| 1 | **Algorithm choice** (O(n) vs O(n^2)) | 10x - 1000x+ |\n",
    "| 2 | **Use C-implemented built-ins** (sum, sorted, Counter) | 2x - 10x |\n",
    "| 3 | **Reduce memory** (__slots__, generators) | 30-50% memory savings |\n",
    "| 4 | **Micro-optimize** (local vars, comprehensions) | 5-30% |\n",
    "| 5 | **C extensions** (ctypes, Cython) | 10x - 100x for hot loops |\n",
    "| 6 | **Parallelism** (multiprocessing for CPU-bound) | Up to Nx on N cores |\n",
    "\n",
    "### Key Tools\n",
    "- **`dis.dis()`**: See exactly what bytecode Python generates\n",
    "- **`__code__` attributes**: Inspect function internals\n",
    "- **`sys.getsizeof()`**: Measure memory of individual objects\n",
    "- **`__slots__`**: Eliminate per-instance `__dict__` overhead\n",
    "- **`ctypes`**: Call C functions without writing C extensions\n",
    "\n",
    "### The Golden Rule\n",
    "**\"Make it work, make it right, make it fast -- in that order.\"**\n",
    "\n",
    "Always profile before optimizing. The bottleneck is almost never where you think it is."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}