{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Pathlib and OS Operations\n",
    "\n",
    "**Chapter 8 - Learning Python, 5th Edition**\n",
    "\n",
    "The `pathlib` module (Python 3.4+) provides an object-oriented interface for filesystem\n",
    "paths, replacing the older `os.path` string-based approach. Combined with `shutil` for\n",
    "high-level operations and `tempfile` for temporary storage, these modules form the\n",
    "foundation of modern Python filesystem programming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Section 1: `pathlib.Path` Basics\n",
    "\n",
    "`Path` objects represent filesystem paths as structured objects rather than raw strings.\n",
    "They provide attributes for accessing path components and methods for common operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path, PurePosixPath, PureWindowsPath\n",
    "\n",
    "# Constructing paths\n",
    "home: Path = Path.home()\n",
    "cwd: Path = Path.cwd()\n",
    "print(f\"Home directory: {home}\")\n",
    "print(f\"Current working directory: {cwd}\")\n",
    "\n",
    "# Path from string\n",
    "config_path: Path = Path(\"/etc/app/config.yaml\")\n",
    "print(f\"\\nPath from string: {config_path}\")\n",
    "print(f\"  type: {type(config_path).__name__}\")\n",
    "\n",
    "# Path components\n",
    "example: Path = Path(\"/home/user/projects/app/main.py\")\n",
    "print(f\"\\nPath: {example}\")\n",
    "print(f\"  .name:    {example.name}\")        # 'main.py'\n",
    "print(f\"  .stem:    {example.stem}\")        # 'main'\n",
    "print(f\"  .suffix:  {example.suffix}\")      # '.py'\n",
    "print(f\"  .parent:  {example.parent}\")      # /home/user/projects/app\n",
    "print(f\"  .anchor:  {example.anchor!r}\")    # '/'\n",
    "print(f\"  .parts:   {example.parts}\")       # ('/', 'home', 'user', ...)\n",
    "\n",
    "# Multiple suffixes (e.g., .tar.gz)\n",
    "archive: Path = Path(\"data/backup.tar.gz\")\n",
    "print(f\"\\nArchive: {archive}\")\n",
    "print(f\"  .suffix:   {archive.suffix}\")     # '.gz'\n",
    "print(f\"  .suffixes: {archive.suffixes}\")   # ['.tar', '.gz']\n",
    "print(f\"  .stem:     {archive.stem}\")       # 'backup.tar'\n",
    "\n",
    "# Parent chain\n",
    "print(f\"\\nParent chain of {example}:\")\n",
    "for parent in example.parents:\n",
    "    print(f\"  {parent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Section 2: Path Operations - Joining, Testing, and Resolving\n",
    "\n",
    "The `/` operator provides an intuitive way to join path components. Path objects\n",
    "also offer methods for testing existence and resolving symbolic links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "# Create a temporary directory for our experiments\n",
    "work_dir = Path(tempfile.mkdtemp(prefix=\"ch08_pathlib_\"))\n",
    "print(f\"Working directory: {work_dir}\")\n",
    "\n",
    "# Path joining with / operator (preferred over os.path.join)\n",
    "project: Path = work_dir / \"myproject\"\n",
    "src: Path = project / \"src\" / \"main.py\"\n",
    "print(f\"\\nJoined path: {src}\")\n",
    "\n",
    "# joinpath() method (equivalent to / operator)\n",
    "test_path: Path = project.joinpath(\"tests\", \"test_main.py\")\n",
    "print(f\"joinpath():  {test_path}\")\n",
    "\n",
    "# Create the directory structure\n",
    "project_src = project / \"src\"\n",
    "project_tests = project / \"tests\"\n",
    "project_src.mkdir(parents=True, exist_ok=True)\n",
    "project_tests.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create some files\n",
    "(project_src / \"main.py\").write_text(\"print('hello')\\n\", encoding=\"utf-8\")\n",
    "(project_src / \"utils.py\").write_text(\"# utilities\\n\", encoding=\"utf-8\")\n",
    "(project_tests / \"test_main.py\").write_text(\"# tests\\n\", encoding=\"utf-8\")\n",
    "(project / \"README.md\").write_text(\"# My Project\\n\", encoding=\"utf-8\")\n",
    "(project / \"setup.py\").write_text(\"# setup\\n\", encoding=\"utf-8\")\n",
    "\n",
    "# Existence and type testing\n",
    "print(f\"\\n{project_src} exists:     {project_src.exists()}\")\n",
    "print(f\"{project_src} is_dir:     {project_src.is_dir()}\")\n",
    "print(f\"{project_src} is_file:    {project_src.is_file()}\")\n",
    "\n",
    "main_py = project_src / \"main.py\"\n",
    "print(f\"\\n{main_py.name} exists:    {main_py.exists()}\")\n",
    "print(f\"{main_py.name} is_file:   {main_py.is_file()}\")\n",
    "print(f\"{main_py.name} is_dir:    {main_py.is_dir()}\")\n",
    "\n",
    "ghost = project / \"nonexistent.txt\"\n",
    "print(f\"\\n{ghost.name} exists: {ghost.exists()}\")\n",
    "\n",
    "# Resolving paths (absolute, no symlinks)\n",
    "relative: Path = Path(\".\") / \"some\" / \"relative\" / \"path\"\n",
    "print(f\"\\nRelative path:  {relative}\")\n",
    "print(f\"Resolved:       {relative.resolve()}\")\n",
    "print(f\"Is absolute:    {relative.is_absolute()}\")\n",
    "print(f\"work_dir absolute: {work_dir.is_absolute()}\")\n",
    "\n",
    "# with_name() and with_suffix() create modified copies\n",
    "original: Path = Path(\"data/report_v1.txt\")\n",
    "renamed: Path = original.with_name(\"report_v2.txt\")\n",
    "different_ext: Path = original.with_suffix(\".csv\")\n",
    "print(f\"\\nOriginal:      {original}\")\n",
    "print(f\"with_name():   {renamed}\")\n",
    "print(f\"with_suffix(): {different_ext}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Section 3: Directory Operations\n",
    "\n",
    "Path objects provide methods for creating, listing, and searching directories.\n",
    "`iterdir()` lists immediate contents, while `glob()` and `rglob()` perform\n",
    "pattern matching at one or all directory levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mkdir() - create directories\n",
    "nested: Path = work_dir / \"a\" / \"b\" / \"c\"\n",
    "\n",
    "# parents=True creates intermediate directories (like mkdir -p)\n",
    "# exist_ok=True suppresses FileExistsError\n",
    "nested.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Created nested directory: {nested}\")\n",
    "\n",
    "# Without parents=True, intermediate dirs must exist\n",
    "try:\n",
    "    (work_dir / \"x\" / \"y\" / \"z\").mkdir()\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Without parents=True: {e}\")\n",
    "\n",
    "# iterdir() - list directory contents\n",
    "print(f\"\\nContents of {project.name}/src/:\")\n",
    "for item in sorted(project_src.iterdir()):\n",
    "    kind = \"dir\" if item.is_dir() else \"file\"\n",
    "    print(f\"  [{kind:4s}] {item.name}\")\n",
    "\n",
    "# Separate files and directories\n",
    "print(f\"\\nContents of {project.name}/:\")\n",
    "dirs: list[Path] = []\n",
    "files: list[Path] = []\n",
    "for item in sorted(project.iterdir()):\n",
    "    (dirs if item.is_dir() else files).append(item)\n",
    "\n",
    "for d in dirs:\n",
    "    print(f\"  [dir ] {d.name}/\")\n",
    "for f in files:\n",
    "    print(f\"  [file] {f.name}\")\n",
    "\n",
    "# glob() - pattern matching in one directory level\n",
    "print(f\"\\nPython files in src/: {[p.name for p in project_src.glob('*.py')]}\")\n",
    "print(f\"Markdown files:       {[p.name for p in project.glob('*.md')]}\")\n",
    "\n",
    "# rglob() - recursive pattern matching (all subdirectories)\n",
    "print(f\"\\nAll .py files (recursive):\")\n",
    "for py_file in sorted(project.rglob(\"*.py\")):\n",
    "    # Show path relative to project root\n",
    "    print(f\"  {py_file.relative_to(project)}\")\n",
    "\n",
    "# glob with ** for explicit recursive matching\n",
    "all_files: list[Path] = sorted(project.glob(\"**/*\"))\n",
    "print(f\"\\nAll items (glob **/*):\")\n",
    "for item in all_files:\n",
    "    rel = item.relative_to(project)\n",
    "    prefix = \"dir \" if item.is_dir() else \"file\"\n",
    "    print(f\"  [{prefix}] {rel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Section 4: File Metadata\n",
    "\n",
    "The `stat()` method returns file metadata including size, timestamps, and permissions.\n",
    "Path objects also provide convenience properties for common queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import stat as stat_module\n",
    "\n",
    "# Write a file with some content for metadata inspection\n",
    "meta_file: Path = work_dir / \"metadata_demo.txt\"\n",
    "meta_file.write_text(\"Sample content for metadata demonstration.\\n\" * 10,\n",
    "                     encoding=\"utf-8\")\n",
    "\n",
    "# stat() returns an os.stat_result object\n",
    "file_stat = meta_file.stat()\n",
    "print(f\"File: {meta_file.name}\")\n",
    "print(f\"  Size:          {file_stat.st_size} bytes\")\n",
    "print(f\"  Mode (octal):  {oct(file_stat.st_mode)}\")\n",
    "print(f\"  Is regular:    {stat_module.S_ISREG(file_stat.st_mode)}\")\n",
    "\n",
    "# Timestamps (as Unix epoch floats)\n",
    "created = datetime.fromtimestamp(file_stat.st_ctime)\n",
    "modified = datetime.fromtimestamp(file_stat.st_mtime)\n",
    "accessed = datetime.fromtimestamp(file_stat.st_atime)\n",
    "print(f\"  Created:       {created:%Y-%m-%d %H:%M:%S}\")\n",
    "print(f\"  Modified:      {modified:%Y-%m-%d %H:%M:%S}\")\n",
    "print(f\"  Accessed:      {accessed:%Y-%m-%d %H:%M:%S}\")\n",
    "\n",
    "# Practical: summarize directory contents\n",
    "def directory_summary(path: Path) -> dict[str, int | float]:\n",
    "    \"\"\"Summarize file counts and total size of a directory.\"\"\"\n",
    "    total_size: int = 0\n",
    "    file_count: int = 0\n",
    "    dir_count: int = 0\n",
    "\n",
    "    for item in path.rglob(\"*\"):\n",
    "        if item.is_file():\n",
    "            file_count += 1\n",
    "            total_size += item.stat().st_size\n",
    "        elif item.is_dir():\n",
    "            dir_count += 1\n",
    "\n",
    "    return {\n",
    "        \"files\": file_count,\n",
    "        \"directories\": dir_count,\n",
    "        \"total_size_bytes\": total_size,\n",
    "        \"total_size_kb\": round(total_size / 1024, 2),\n",
    "    }\n",
    "\n",
    "\n",
    "summary = directory_summary(project)\n",
    "print(f\"\\nProject summary:\")\n",
    "for key, value in summary.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# File size by extension\n",
    "from collections import defaultdict\n",
    "\n",
    "size_by_ext: dict[str, int] = defaultdict(int)\n",
    "count_by_ext: dict[str, int] = defaultdict(int)\n",
    "\n",
    "for f in project.rglob(\"*\"):\n",
    "    if f.is_file():\n",
    "        ext = f.suffix or \"(no ext)\"\n",
    "        size_by_ext[ext] += f.stat().st_size\n",
    "        count_by_ext[ext] += 1\n",
    "\n",
    "print(f\"\\nFiles by extension:\")\n",
    "for ext in sorted(count_by_ext):\n",
    "    print(f\"  {ext:10s}: {count_by_ext[ext]} files, {size_by_ext[ext]} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Section 5: The `tempfile` Module\n",
    "\n",
    "The `tempfile` module creates temporary files and directories that are automatically\n",
    "cleaned up. This is essential for testing, intermediate processing, and any situation\n",
    "where you need scratch space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "# NamedTemporaryFile - auto-deleted when closed (or when context exits)\n",
    "with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".txt\", prefix=\"data_\",\n",
    "                                  delete=False, encoding=\"utf-8\") as tmp:\n",
    "    tmp.write(\"Temporary data for processing.\\n\")\n",
    "    tmp_path = Path(tmp.name)\n",
    "    print(f\"NamedTemporaryFile: {tmp_path}\")\n",
    "    print(f\"  name:   {tmp_path.name}\")\n",
    "    print(f\"  suffix: {tmp_path.suffix}\")\n",
    "    print(f\"  exists: {tmp_path.exists()}\")\n",
    "\n",
    "# File persists because delete=False; clean it up manually\n",
    "print(f\"  exists after close: {tmp_path.exists()}\")\n",
    "tmp_path.unlink()\n",
    "print(f\"  exists after unlink: {tmp_path.exists()}\")\n",
    "\n",
    "# TemporaryDirectory - auto-deleted when context exits\n",
    "with tempfile.TemporaryDirectory(prefix=\"scratch_\") as tmp_dir_str:\n",
    "    tmp_dir = Path(tmp_dir_str)\n",
    "    print(f\"\\nTemporaryDirectory: {tmp_dir}\")\n",
    "\n",
    "    # Create files inside the temp directory\n",
    "    for i in range(3):\n",
    "        (tmp_dir / f\"file_{i}.txt\").write_text(f\"content {i}\\n\",\n",
    "                                                encoding=\"utf-8\")\n",
    "\n",
    "    contents = list(tmp_dir.iterdir())\n",
    "    print(f\"  Contents: {[p.name for p in sorted(contents)]}\")\n",
    "    print(f\"  exists: {tmp_dir.exists()}\")\n",
    "\n",
    "# Directory and all contents are gone after the with block\n",
    "print(f\"  exists after context: {tmp_dir.exists()}\")\n",
    "\n",
    "# mkdtemp() for manual management (when you need control over lifetime)\n",
    "manual_tmp: str = tempfile.mkdtemp(prefix=\"manual_\")\n",
    "manual_path = Path(manual_tmp)\n",
    "print(f\"\\nmkdtemp: {manual_path}\")\n",
    "print(f\"  exists: {manual_path.exists()}\")\n",
    "\n",
    "# Must clean up manually\n",
    "import shutil\n",
    "shutil.rmtree(manual_path)\n",
    "print(f\"  exists after rmtree: {manual_path.exists()}\")\n",
    "\n",
    "# SpooledTemporaryFile - stays in memory until max_size exceeded\n",
    "with tempfile.SpooledTemporaryFile(max_size=1024, mode=\"w+\",\n",
    "                                    encoding=\"utf-8\") as spool:\n",
    "    spool.write(\"Small data stays in memory.\\n\")\n",
    "    spool.seek(0)\n",
    "    content = spool.read()\n",
    "    print(f\"\\nSpooledTemporaryFile content: {content.rstrip()!r}\")\n",
    "    print(f\"  Rolled to disk: {spool._rolled}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Section 6: `shutil` - High-Level File Operations\n",
    "\n",
    "The `shutil` module provides high-level operations like copying, moving, and\n",
    "removing directory trees. It handles the details that `Path` methods do not cover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Create a fresh workspace\n",
    "shutil_dir = Path(tempfile.mkdtemp(prefix=\"ch08_shutil_\"))\n",
    "\n",
    "# Create source files\n",
    "src_dir = shutil_dir / \"source\"\n",
    "src_dir.mkdir()\n",
    "(src_dir / \"data.txt\").write_text(\"Important data.\\n\", encoding=\"utf-8\")\n",
    "(src_dir / \"config.ini\").write_text(\"[settings]\\nkey=value\\n\", encoding=\"utf-8\")\n",
    "sub = src_dir / \"subdir\"\n",
    "sub.mkdir()\n",
    "(sub / \"nested.txt\").write_text(\"Nested file.\\n\", encoding=\"utf-8\")\n",
    "\n",
    "# --- shutil.copy() - copy file (preserves permissions) ---\n",
    "dst_file = shutil_dir / \"data_copy.txt\"\n",
    "shutil.copy(src_dir / \"data.txt\", dst_file)\n",
    "print(f\"copy(): {dst_file.name} exists={dst_file.exists()}\")\n",
    "\n",
    "# --- shutil.copy2() - copy file + metadata (timestamps) ---\n",
    "dst_file2 = shutil_dir / \"data_copy2.txt\"\n",
    "shutil.copy2(src_dir / \"data.txt\", dst_file2)\n",
    "orig_stat = (src_dir / \"data.txt\").stat()\n",
    "copy_stat = dst_file2.stat()\n",
    "print(f\"copy2(): preserved mtime={orig_stat.st_mtime == copy_stat.st_mtime}\")\n",
    "\n",
    "# --- shutil.copytree() - copy entire directory tree ---\n",
    "tree_copy = shutil_dir / \"source_backup\"\n",
    "shutil.copytree(src_dir, tree_copy)\n",
    "print(f\"\\ncopytree() result:\")\n",
    "for item in sorted(tree_copy.rglob(\"*\")):\n",
    "    rel = item.relative_to(tree_copy)\n",
    "    prefix = \"dir \" if item.is_dir() else \"file\"\n",
    "    print(f\"  [{prefix}] {rel}\")\n",
    "\n",
    "# --- shutil.move() - move/rename files or directories ---\n",
    "moved_file = shutil_dir / \"moved_data.txt\"\n",
    "shutil.move(str(dst_file), str(moved_file))\n",
    "print(f\"\\nmove(): original exists={dst_file.exists()}, moved exists={moved_file.exists()}\")\n",
    "\n",
    "# --- shutil.rmtree() - remove entire directory tree ---\n",
    "print(f\"\\nBefore rmtree: {tree_copy.name}/ exists={tree_copy.exists()}\")\n",
    "shutil.rmtree(tree_copy)\n",
    "print(f\"After rmtree:  {tree_copy.name}/ exists={tree_copy.exists()}\")\n",
    "\n",
    "# --- shutil.disk_usage() - check disk space ---\n",
    "usage = shutil.disk_usage(shutil_dir)\n",
    "print(f\"\\nDisk usage for {shutil_dir}:\")\n",
    "print(f\"  Total: {usage.total / (1024**3):.1f} GB\")\n",
    "print(f\"  Used:  {usage.used / (1024**3):.1f} GB\")\n",
    "print(f\"  Free:  {usage.free / (1024**3):.1f} GB\")\n",
    "\n",
    "# Cleanup\n",
    "shutil.rmtree(shutil_dir)\n",
    "print(f\"\\nCleaned up {shutil_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Section 7: Practical Pattern - Project File Scanner\n",
    "\n",
    "Combining `pathlib` operations into a reusable utility that scans a project\n",
    "directory, filters by patterns, and reports statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FileInfo:\n",
    "    \"\"\"Metadata about a single file.\"\"\"\n",
    "    path: Path\n",
    "    size: int\n",
    "    modified: datetime\n",
    "    extension: str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ScanResult:\n",
    "    \"\"\"Results of scanning a directory.\"\"\"\n",
    "    root: Path\n",
    "    files: list[FileInfo] = field(default_factory=list)\n",
    "    skipped_dirs: list[Path] = field(default_factory=list)\n",
    "\n",
    "    @property\n",
    "    def total_size(self) -> int:\n",
    "        return sum(f.size for f in self.files)\n",
    "\n",
    "    @property\n",
    "    def file_count(self) -> int:\n",
    "        return len(self.files)\n",
    "\n",
    "    def by_extension(self) -> dict[str, list[FileInfo]]:\n",
    "        \"\"\"Group files by extension.\"\"\"\n",
    "        result: dict[str, list[FileInfo]] = {}\n",
    "        for f in self.files:\n",
    "            result.setdefault(f.extension, []).append(f)\n",
    "        return result\n",
    "\n",
    "    def largest(self, n: int = 5) -> list[FileInfo]:\n",
    "        \"\"\"Return the n largest files.\"\"\"\n",
    "        return sorted(self.files, key=lambda f: f.size, reverse=True)[:n]\n",
    "\n",
    "\n",
    "def scan_directory(\n",
    "    root: Path,\n",
    "    patterns: list[str] | None = None,\n",
    "    exclude_dirs: set[str] | None = None,\n",
    ") -> ScanResult:\n",
    "    \"\"\"Scan a directory tree, optionally filtering by glob patterns.\"\"\"\n",
    "    if exclude_dirs is None:\n",
    "        exclude_dirs = {\".git\", \"__pycache__\", \".venv\", \"node_modules\"}\n",
    "    if patterns is None:\n",
    "        patterns = [\"*\"]\n",
    "\n",
    "    result = ScanResult(root=root)\n",
    "\n",
    "    for pattern in patterns:\n",
    "        for path in root.rglob(pattern):\n",
    "            # Skip excluded directories\n",
    "            if any(excl in path.parts for excl in exclude_dirs):\n",
    "                continue\n",
    "            if path.is_file():\n",
    "                stat = path.stat()\n",
    "                result.files.append(FileInfo(\n",
    "                    path=path,\n",
    "                    size=stat.st_size,\n",
    "                    modified=datetime.fromtimestamp(stat.st_mtime),\n",
    "                    extension=path.suffix or \"(none)\",\n",
    "                ))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Demo: scan a temporary project\n",
    "demo_dir = Path(tempfile.mkdtemp(prefix=\"ch08_scanner_\"))\n",
    "for subdir in [\"src\", \"tests\", \"docs\", \"__pycache__\"]:\n",
    "    (demo_dir / subdir).mkdir()\n",
    "\n",
    "(demo_dir / \"src\" / \"app.py\").write_text(\"# App code\\n\" * 50, encoding=\"utf-8\")\n",
    "(demo_dir / \"src\" / \"models.py\").write_text(\"# Models\\n\" * 30, encoding=\"utf-8\")\n",
    "(demo_dir / \"src\" / \"utils.py\").write_text(\"# Utils\\n\", encoding=\"utf-8\")\n",
    "(demo_dir / \"tests\" / \"test_app.py\").write_text(\"# Tests\\n\" * 20, encoding=\"utf-8\")\n",
    "(demo_dir / \"docs\" / \"guide.md\").write_text(\"# Guide\\n\" * 15, encoding=\"utf-8\")\n",
    "(demo_dir / \"README.md\").write_text(\"# README\\n\", encoding=\"utf-8\")\n",
    "(demo_dir / \"__pycache__\" / \"app.cpython-312.pyc\").write_bytes(b\"\\x00\" * 100)\n",
    "\n",
    "scan = scan_directory(demo_dir, patterns=[\"*.py\", \"*.md\"])\n",
    "\n",
    "print(f\"Scan results for {demo_dir.name}/\")\n",
    "print(f\"  Total files: {scan.file_count}\")\n",
    "print(f\"  Total size:  {scan.total_size} bytes\")\n",
    "\n",
    "print(f\"\\nBy extension:\")\n",
    "for ext, files in sorted(scan.by_extension().items()):\n",
    "    total = sum(f.size for f in files)\n",
    "    print(f\"  {ext}: {len(files)} files, {total} bytes\")\n",
    "\n",
    "print(f\"\\nLargest files:\")\n",
    "for fi in scan.largest(3):\n",
    "    rel = fi.path.relative_to(demo_dir)\n",
    "    print(f\"  {rel}: {fi.size} bytes (modified {fi.modified:%H:%M:%S})\")\n",
    "\n",
    "# Note: __pycache__ files excluded by default\n",
    "print(f\"\\n__pycache__ excluded: no .pyc files in results\")\n",
    "\n",
    "# Cleanup\n",
    "shutil.rmtree(demo_dir)\n",
    "shutil.rmtree(work_dir)\n",
    "print(f\"Cleaned up temporary directories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### `pathlib.Path`\n",
    "- Use `/` operator for joining: `Path('a') / 'b' / 'c'`\n",
    "- Access components: `.name`, `.stem`, `.suffix`, `.parent`, `.parts`\n",
    "- Test: `.exists()`, `.is_file()`, `.is_dir()`\n",
    "- Modify: `.with_name()`, `.with_suffix()`\n",
    "- Read/write shortcuts: `.read_text()`, `.write_text()`, `.read_bytes()`\n",
    "\n",
    "### Directory Operations\n",
    "- `.mkdir(parents=True, exist_ok=True)` for safe creation\n",
    "- `.iterdir()` for listing, `.glob()` / `.rglob()` for pattern matching\n",
    "- `.relative_to()` for computing relative paths\n",
    "\n",
    "### `tempfile`\n",
    "- `TemporaryDirectory()` for auto-cleaned scratch space\n",
    "- `NamedTemporaryFile()` for temporary files with names\n",
    "- Always prefer context managers for automatic cleanup\n",
    "\n",
    "### `shutil`\n",
    "- `copy()` / `copy2()` for file copying (with or without metadata)\n",
    "- `copytree()` / `rmtree()` for directory trees\n",
    "- `move()` for cross-filesystem moves\n",
    "\n",
    "### Best Practices\n",
    "1. Prefer `pathlib.Path` over `os.path` for new code\n",
    "2. Use `tempfile` for scratch files and directories\n",
    "3. Always handle `FileNotFoundError` and `PermissionError`\n",
    "4. Use `rglob()` with exclusion sets to skip irrelevant directories\n",
    "5. Use `shutil.rmtree()` with caution - it deletes recursively with no undo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}