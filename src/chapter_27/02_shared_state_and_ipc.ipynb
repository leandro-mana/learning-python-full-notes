{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# Chapter 27: Shared State and Inter-Process Communication\n",
    "\n",
    "Since each process has its own memory space, sharing data between processes requires\n",
    "explicit mechanisms. The `multiprocessing` module provides several IPC (Inter-Process\n",
    "Communication) primitives: `Queue`, `Pipe`, `Value`, `Array`, `Manager`, and\n",
    "synchronization tools like `Lock`.\n",
    "\n",
    "## Topics Covered\n",
    "- **Queue**: Thread/process-safe FIFO queue\n",
    "- **Pipe**: Bidirectional communication channel\n",
    "- **Value**: Shared single value in shared memory\n",
    "- **Array**: Shared array in shared memory\n",
    "- **Lock**: Synchronize access to shared resources\n",
    "- **Manager**: Proxy-based shared objects (dicts, lists, etc.)\n",
    "- **Practical**: Producer-consumer pattern with Queue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5",
   "metadata": {},
   "source": [
    "## Queue: Safe Inter-Process Communication\n",
    "\n",
    "`multiprocessing.Queue` is a process-safe FIFO queue built on top of pipes and locks.\n",
    "It is the most common way to pass data between processes.\n",
    "\n",
    "Key methods:\n",
    "- `put(item)` -- add an item (blocks if the queue is full)\n",
    "- `get()` -- remove and return an item (blocks if empty)\n",
    "- `empty()` -- approximate check if the queue is empty\n",
    "- `qsize()` -- approximate number of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "# Basic Queue usage (within a single process for demonstration)\n",
    "q: multiprocessing.Queue = multiprocessing.Queue()\n",
    "\n",
    "# Put items into the queue\n",
    "q.put(\"hello\")\n",
    "q.put(\"world\")\n",
    "q.put(42)\n",
    "\n",
    "# Get items in FIFO order\n",
    "print(f\"First:  {q.get()}\")\n",
    "print(f\"Second: {q.get()}\")\n",
    "print(f\"Third:  {q.get()}\")\n",
    "print(f\"Empty:  {q.empty()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "\n",
    "def queue_worker(q: multiprocessing.Queue, values: list[int]) -> None:\n",
    "    \"\"\"Put computed results into a queue.\"\"\"\n",
    "    pid: int = os.getpid()\n",
    "    for v in values:\n",
    "        q.put((pid, v, v * v))\n",
    "\n",
    "\n",
    "# Use a Queue to collect results from multiple worker processes\n",
    "result_queue: multiprocessing.Queue = multiprocessing.Queue()\n",
    "\n",
    "p1 = multiprocessing.Process(target=queue_worker, args=(result_queue, [1, 2, 3]))\n",
    "p2 = multiprocessing.Process(target=queue_worker, args=(result_queue, [4, 5, 6]))\n",
    "\n",
    "p1.start()\n",
    "p2.start()\n",
    "p1.join()\n",
    "p2.join()\n",
    "\n",
    "# Read all results\n",
    "print(\"Results from workers:\")\n",
    "while not result_queue.empty():\n",
    "    pid, value, squared = result_queue.get()\n",
    "    print(f\"  PID {pid}: {value}^2 = {squared}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6a7b8",
   "metadata": {},
   "source": [
    "## Pipe: Bidirectional Communication\n",
    "\n",
    "`multiprocessing.Pipe()` creates a pair of connected `Connection` objects. By default,\n",
    "the pipe is bidirectional -- each end can both `send()` and `recv()`.\n",
    "\n",
    "Pipes are faster than queues for simple two-process communication, but they are not\n",
    "safe for use by more than two processes simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "# Bidirectional pipe (within a single process for clarity)\n",
    "parent_conn, child_conn = multiprocessing.Pipe()\n",
    "\n",
    "# Send from parent end, receive at child end\n",
    "parent_conn.send(\"ping\")\n",
    "print(f\"Child received: {child_conn.recv()}\")\n",
    "\n",
    "# Send from child end, receive at parent end\n",
    "child_conn.send(\"pong\")\n",
    "print(f\"Parent received: {parent_conn.recv()}\")\n",
    "\n",
    "# Pipes can send any picklable object\n",
    "parent_conn.send({\"type\": \"data\", \"values\": [1, 2, 3]})\n",
    "msg: dict = child_conn.recv()\n",
    "print(f\"Dict received: {msg}\")\n",
    "\n",
    "parent_conn.close()\n",
    "child_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from multiprocessing.connection import Connection\n",
    "\n",
    "\n",
    "def pipe_child(conn: Connection) -> None:\n",
    "    \"\"\"Child process that communicates via a Pipe.\"\"\"\n",
    "    msg: str = conn.recv()\n",
    "    conn.send(f\"echo: {msg}\")\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "# Two-process communication with Pipe\n",
    "parent_conn, child_conn = multiprocessing.Pipe()\n",
    "\n",
    "p = multiprocessing.Process(target=pipe_child, args=(child_conn,))\n",
    "p.start()\n",
    "\n",
    "# Parent sends a message and waits for the reply\n",
    "parent_conn.send(\"hello from parent\")\n",
    "reply: str = parent_conn.recv()\n",
    "print(f\"Parent got reply: {reply}\")\n",
    "\n",
    "p.join()\n",
    "parent_conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c9d0e1",
   "metadata": {},
   "source": [
    "## Value and Array: Shared Memory\n",
    "\n",
    "`multiprocessing.Value` and `multiprocessing.Array` create shared memory objects that\n",
    "can be accessed by multiple processes. They use ctypes type codes:\n",
    "\n",
    "| Type code | C type | Python type |\n",
    "|-----------|--------|:------------|\n",
    "| `'i'` | `int` | `int` |\n",
    "| `'d'` | `double` | `float` |\n",
    "| `'f'` | `float` | `float` |\n",
    "| `'c'` | `char` | `bytes` |\n",
    "\n",
    "These objects live in **shared memory** (not copied), so changes are visible to all processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "# Value: a single shared value\n",
    "counter = multiprocessing.Value(\"i\", 0)  # 'i' = signed int, initial value = 0\n",
    "print(f\"Initial value: {counter.value}\")\n",
    "\n",
    "counter.value = 42\n",
    "print(f\"After assignment: {counter.value}\")\n",
    "\n",
    "# Value with a float\n",
    "temperature = multiprocessing.Value(\"d\", 98.6)  # 'd' = double\n",
    "print(f\"Temperature: {temperature.value}\")\n",
    "\n",
    "# Array: shared array of fixed type\n",
    "arr = multiprocessing.Array(\"d\", [1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "print(f\"\\nArray contents: {list(arr)}\")\n",
    "\n",
    "arr[0] = 10.0\n",
    "arr[4] = 50.0\n",
    "print(f\"After modification: {list(arr)}\")\n",
    "print(f\"Array length: {len(arr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "\n",
    "def increment_counter(\n",
    "    counter: multiprocessing.Value,\n",
    "    times: int,\n",
    ") -> None:\n",
    "    \"\"\"Increment a shared counter multiple times.\"\"\"\n",
    "    for _ in range(times):\n",
    "        with counter.get_lock():  # Acquire the built-in lock\n",
    "            counter.value += 1\n",
    "\n",
    "\n",
    "# Shared counter accessed by multiple processes\n",
    "shared_counter = multiprocessing.Value(\"i\", 0)\n",
    "\n",
    "processes: list[multiprocessing.Process] = [\n",
    "    multiprocessing.Process(target=increment_counter, args=(shared_counter, 1000))\n",
    "    for _ in range(4)\n",
    "]\n",
    "\n",
    "for p in processes:\n",
    "    p.start()\n",
    "for p in processes:\n",
    "    p.join()\n",
    "\n",
    "# With proper locking, result should be exactly 4000\n",
    "print(f\"Final counter value: {shared_counter.value}\")\n",
    "print(f\"Expected: {4 * 1000}\")\n",
    "print(f\"Correct: {shared_counter.value == 4000}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2a3b4",
   "metadata": {},
   "source": [
    "## Lock: Synchronizing Shared Access\n",
    "\n",
    "`multiprocessing.Lock` prevents multiple processes from accessing a shared resource\n",
    "simultaneously. It works exactly like `threading.Lock` but across processes.\n",
    "\n",
    "- `lock.acquire()` / `lock.release()` -- manual lock management\n",
    "- `with lock:` -- context manager (preferred) for automatic release\n",
    "\n",
    "Without a lock, concurrent modifications to shared state can produce incorrect results\n",
    "due to **race conditions**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "\n",
    "def unsafe_increment(\n",
    "    counter: multiprocessing.Value,\n",
    "    times: int,\n",
    ") -> None:\n",
    "    \"\"\"Increment WITHOUT a lock -- prone to race conditions.\"\"\"\n",
    "    for _ in range(times):\n",
    "        counter.value += 1  # NOT atomic!\n",
    "\n",
    "\n",
    "def safe_increment(\n",
    "    counter: multiprocessing.Value,\n",
    "    lock: multiprocessing.Lock,\n",
    "    times: int,\n",
    ") -> None:\n",
    "    \"\"\"Increment WITH a lock -- safe from race conditions.\"\"\"\n",
    "    for _ in range(times):\n",
    "        with lock:\n",
    "            counter.value += 1\n",
    "\n",
    "\n",
    "# Unsafe version (may produce incorrect results)\n",
    "unsafe_counter = multiprocessing.Value(\"i\", 0)\n",
    "procs = [\n",
    "    multiprocessing.Process(target=unsafe_increment, args=(unsafe_counter, 10000))\n",
    "    for _ in range(4)\n",
    "]\n",
    "for p in procs:\n",
    "    p.start()\n",
    "for p in procs:\n",
    "    p.join()\n",
    "print(f\"Unsafe counter: {unsafe_counter.value} (expected 40000)\")\n",
    "\n",
    "# Safe version with explicit Lock\n",
    "safe_counter = multiprocessing.Value(\"i\", 0)\n",
    "lock = multiprocessing.Lock()\n",
    "procs = [\n",
    "    multiprocessing.Process(target=safe_increment, args=(safe_counter, lock, 10000))\n",
    "    for _ in range(4)\n",
    "]\n",
    "for p in procs:\n",
    "    p.start()\n",
    "for p in procs:\n",
    "    p.join()\n",
    "print(f\"Safe counter:   {safe_counter.value} (expected 40000)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4c5d6",
   "metadata": {},
   "source": [
    "## Manager: Proxy-Based Shared Objects\n",
    "\n",
    "`multiprocessing.Manager()` creates a server process that hosts shared Python objects.\n",
    "Other processes access these objects through **proxies**. This is more flexible than\n",
    "`Value`/`Array` because it supports standard Python types:\n",
    "\n",
    "- `manager.list()` -- shared list\n",
    "- `manager.dict()` -- shared dictionary\n",
    "- `manager.Value()` -- shared value\n",
    "- `manager.Queue()` -- shared queue\n",
    "- `manager.Lock()` -- shared lock\n",
    "\n",
    "The tradeoff: Managers are **slower** than `Value`/`Array` because they use inter-process\n",
    "communication (proxies) under the hood, but they are more convenient for complex data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c5d6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from multiprocessing.managers import DictProxy, ListProxy\n",
    "\n",
    "\n",
    "def add_results(\n",
    "    shared_dict: DictProxy,\n",
    "    shared_list: ListProxy,\n",
    "    key: str,\n",
    "    values: list[int],\n",
    ") -> None:\n",
    "    \"\"\"Add results to shared dict and list.\"\"\"\n",
    "    total: int = sum(values)\n",
    "    shared_dict[key] = total\n",
    "    shared_list.append(f\"{key}={total}\")\n",
    "\n",
    "\n",
    "with multiprocessing.Manager() as manager:\n",
    "    # Create shared objects through the manager\n",
    "    shared_dict = manager.dict()\n",
    "    shared_list = manager.list()\n",
    "\n",
    "    # Launch processes that modify shared objects\n",
    "    processes = [\n",
    "        multiprocessing.Process(\n",
    "            target=add_results,\n",
    "            args=(shared_dict, shared_list, f\"task_{i}\", list(range(i * 10))),\n",
    "        )\n",
    "        for i in range(1, 5)\n",
    "    ]\n",
    "    for p in processes:\n",
    "        p.start()\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    print(\"Shared dict:\")\n",
    "    for key, value in sorted(shared_dict.items()):\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "    print(f\"\\nShared list: {list(shared_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d6e7f8",
   "metadata": {},
   "source": [
    "## Choosing the Right IPC Mechanism\n",
    "\n",
    "| Mechanism | Use Case | Speed | Flexibility |\n",
    "|-----------|----------|:------|:------------|\n",
    "| **Queue** | Multiple producers/consumers, message passing | Medium | High |\n",
    "| **Pipe** | Two-process communication, request/response | Fast | Low |\n",
    "| **Value** | Single shared number (int, float) | Fast | Low |\n",
    "| **Array** | Shared fixed-size array of numbers | Fast | Low |\n",
    "| **Manager** | Shared dicts, lists, complex objects | Slow | High |\n",
    "| **Lock** | Protect shared resources from race conditions | -- | -- |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7f8a9",
   "metadata": {},
   "source": [
    "## Practical: Producer-Consumer with Queue\n",
    "\n",
    "The **producer-consumer** pattern is a classic concurrency design pattern. Producers\n",
    "generate data and place it on a queue; consumers take data from the queue and process it.\n",
    "A special **sentinel** value (e.g., `None`) signals consumers to stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "def producer(\n",
    "    queue: multiprocessing.Queue,\n",
    "    items: list[int],\n",
    "    name: str,\n",
    ") -> None:\n",
    "    \"\"\"Produce items and put them on the queue.\"\"\"\n",
    "    for item in items:\n",
    "        queue.put((name, item))\n",
    "        time.sleep(0.05)  # Simulate work\n",
    "    print(f\"  Producer {name} (PID {os.getpid()}) finished\")\n",
    "\n",
    "\n",
    "def consumer(\n",
    "    queue: multiprocessing.Queue,\n",
    "    result_queue: multiprocessing.Queue,\n",
    "    name: str,\n",
    ") -> None:\n",
    "    \"\"\"Consume items from the queue until sentinel is received.\"\"\"\n",
    "    processed: int = 0\n",
    "    while True:\n",
    "        item = queue.get()\n",
    "        if item is None:  # Sentinel value\n",
    "            break\n",
    "        producer_name, value = item\n",
    "        result_queue.put((name, producer_name, value, value * value))\n",
    "        processed += 1\n",
    "    print(f\"  Consumer {name} (PID {os.getpid()}) processed {processed} items\")\n",
    "\n",
    "\n",
    "# Set up the queues\n",
    "work_queue: multiprocessing.Queue = multiprocessing.Queue()\n",
    "result_queue: multiprocessing.Queue = multiprocessing.Queue()\n",
    "\n",
    "# Start 2 producers and 2 consumers\n",
    "producers = [\n",
    "    multiprocessing.Process(target=producer, args=(work_queue, [1, 2, 3, 4], \"P1\")),\n",
    "    multiprocessing.Process(target=producer, args=(work_queue, [5, 6, 7, 8], \"P2\")),\n",
    "]\n",
    "consumers = [\n",
    "    multiprocessing.Process(target=consumer, args=(work_queue, result_queue, \"C1\")),\n",
    "    multiprocessing.Process(target=consumer, args=(work_queue, result_queue, \"C2\")),\n",
    "]\n",
    "\n",
    "for p in producers + consumers:\n",
    "    p.start()\n",
    "\n",
    "# Wait for producers to finish\n",
    "for p in producers:\n",
    "    p.join()\n",
    "\n",
    "# Send sentinel values (one per consumer)\n",
    "for _ in consumers:\n",
    "    work_queue.put(None)\n",
    "\n",
    "# Wait for consumers to finish\n",
    "for c in consumers:\n",
    "    c.join()\n",
    "\n",
    "# Collect results\n",
    "print(\"\\nResults:\")\n",
    "while not result_queue.empty():\n",
    "    consumer_name, producer_name, value, squared = result_queue.get()\n",
    "    print(f\"  {consumer_name} processed {producer_name}'s item: {value}^2 = {squared}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a9b0c1",
   "metadata": {},
   "source": [
    "## Shared Array with Worker Processes\n",
    "\n",
    "When multiple processes need to write results into a shared data structure, `Array`\n",
    "combined with index-based partitioning avoids the need for locks entirely. Each process\n",
    "writes to its own slice of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0c1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "\n",
    "def fill_array_slice(\n",
    "    shared_arr: multiprocessing.Array,\n",
    "    start: int,\n",
    "    end: int,\n",
    "    multiplier: float,\n",
    ") -> None:\n",
    "    \"\"\"Fill a slice of a shared array with computed values.\"\"\"\n",
    "    for i in range(start, end):\n",
    "        shared_arr[i] = float(i) * multiplier\n",
    "\n",
    "\n",
    "# Create a shared array of 12 doubles\n",
    "size: int = 12\n",
    "shared: multiprocessing.Array = multiprocessing.Array(\"d\", size)\n",
    "\n",
    "# Each process handles a different slice (no lock needed)\n",
    "chunk: int = size // 3\n",
    "procs = [\n",
    "    multiprocessing.Process(target=fill_array_slice, args=(shared, 0, chunk, 1.0)),\n",
    "    multiprocessing.Process(target=fill_array_slice, args=(shared, chunk, 2 * chunk, 2.0)),\n",
    "    multiprocessing.Process(target=fill_array_slice, args=(shared, 2 * chunk, size, 3.0)),\n",
    "]\n",
    "\n",
    "for p in procs:\n",
    "    p.start()\n",
    "for p in procs:\n",
    "    p.join()\n",
    "\n",
    "print(\"Shared array contents:\")\n",
    "for i, val in enumerate(shared):\n",
    "    print(f\"  [{i}] = {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c1d2e3",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "| Concept | API | Purpose |\n",
    "|---------|-----|:--------|\n",
    "| **Queue** | `multiprocessing.Queue` | FIFO message passing between processes |\n",
    "| **Pipe** | `multiprocessing.Pipe()` | Fast two-process bidirectional channel |\n",
    "| **Value** | `multiprocessing.Value('i', 0)` | Single shared int/float in shared memory |\n",
    "| **Array** | `multiprocessing.Array('d', [...])` | Fixed-size shared array in shared memory |\n",
    "| **Lock** | `multiprocessing.Lock()` | Prevent race conditions on shared state |\n",
    "| **Manager** | `multiprocessing.Manager()` | Proxy-based shared dicts, lists, etc. |\n",
    "\n",
    "### Best Practices\n",
    "- Use `Queue` for general-purpose message passing between any number of processes\n",
    "- Use `Pipe` for fast, simple two-process communication\n",
    "- Use `Value` and `Array` for high-performance shared memory with numeric data\n",
    "- Always use locks when multiple processes write to the same `Value` or `Array`\n",
    "- Use `Manager` when you need to share complex Python objects (dicts, lists)\n",
    "- Prefer partitioning work (each process writes its own slice) over shared locks\n",
    "- Use sentinel values to signal consumers when all work is done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}