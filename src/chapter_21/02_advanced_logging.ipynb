{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 21: Advanced Logging\n",
    "\n",
    "Building on logging fundamentals, this notebook covers the advanced features of Python's\n",
    "logging module: logger hierarchies, multiple handlers, custom filters, rotating file\n",
    "handlers, structured logging, configuration via dictionaries, and best practices for\n",
    "logging in libraries vs applications.\n",
    "\n",
    "## Topics Covered\n",
    "- **Logger hierarchy**: Parent-child relationships and propagation\n",
    "- **Multiple handlers**: Console + file on a single logger\n",
    "- **Filters**: Filtering log records by custom criteria\n",
    "- **Rotating handlers**: `RotatingFileHandler` and `TimedRotatingFileHandler`\n",
    "- **Structured logging**: JSON-formatted log output\n",
    "- **dictConfig and fileConfig**: Declarative configuration\n",
    "- **Libraries vs applications**: Different logging strategies\n",
    "- **LoggerAdapter**: Adding context with extra fields"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logger Hierarchy: Parent-Child Relationships\n",
    "\n",
    "Logger names form a hierarchy using dot-separated names, just like Python packages.\n",
    "The logger `myapp.db.connection` is a child of `myapp.db`, which is a child of `myapp`,\n",
    "which is a child of the **root** logger.\n",
    "\n",
    "When a logger processes a record, it passes the record to its own handlers, then\n",
    "(if `propagate=True`, which is the default) passes it up to the parent logger. This\n",
    "continues all the way to the root."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "# Clean slate\n",
    "for name in [\"webapp\", \"webapp.auth\", \"webapp.auth.oauth\"]:\n",
    "    lg = logging.getLogger(name)\n",
    "    lg.handlers.clear()\n",
    "    lg.setLevel(logging.NOTSET)\n",
    "    lg.propagate = True\n",
    "\n",
    "# Build a three-level hierarchy\n",
    "parent = logging.getLogger(\"webapp\")\n",
    "child = logging.getLogger(\"webapp.auth\")\n",
    "grandchild = logging.getLogger(\"webapp.auth.oauth\")\n",
    "\n",
    "# Verify the hierarchy\n",
    "print(f\"child.parent: {child.parent}\")\n",
    "print(f\"grandchild.parent: {grandchild.parent}\")\n",
    "print(f\"parent.parent: {parent.parent}\")\n",
    "\n",
    "# Set level only on the parent -- children inherit it\n",
    "parent.setLevel(logging.WARNING)\n",
    "\n",
    "print(f\"\\nparent effective level:     {logging.getLevelName(parent.getEffectiveLevel())}\")\n",
    "print(f\"child effective level:      {logging.getLevelName(child.getEffectiveLevel())}\")\n",
    "print(f\"grandchild effective level: {logging.getLevelName(grandchild.getEffectiveLevel())}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "# Demonstrate propagation: records bubble up to parent handlers\n",
    "parent = logging.getLogger(\"webapp\")\n",
    "parent.setLevel(logging.DEBUG)\n",
    "parent.handlers.clear()\n",
    "\n",
    "child = logging.getLogger(\"webapp.auth\")\n",
    "child.handlers.clear()\n",
    "\n",
    "# Add a handler ONLY to the parent\n",
    "parent_handler = logging.StreamHandler(sys.stdout)\n",
    "parent_handler.setFormatter(logging.Formatter(\"[%(name)s] %(levelname)s: %(message)s\"))\n",
    "parent.addHandler(parent_handler)\n",
    "parent.propagate = False  # Stop at parent, don't go to root\n",
    "\n",
    "# Child has no handler, but propagation sends records to parent's handler\n",
    "print(\"--- Child logs propagate to parent handler ---\")\n",
    "child.warning(\"Login attempt failed for user 'admin'\")\n",
    "child.info(\"Session created for user 'alice'\")\n",
    "\n",
    "# Disable propagation on child\n",
    "print(\"\\n--- After child.propagate = False ---\")\n",
    "child.propagate = False\n",
    "child.warning(\"This will NOT appear (no handler, no propagation)\")\n",
    "\n",
    "# Give child its own handler\n",
    "child_handler = logging.StreamHandler(sys.stdout)\n",
    "child_handler.setFormatter(logging.Formatter(\"  AUTH >> %(levelname)s: %(message)s\"))\n",
    "child.addHandler(child_handler)\n",
    "\n",
    "print(\"\\n--- Child with its own handler, propagation off ---\")\n",
    "child.warning(\"Appears only through child's handler\")\n",
    "\n",
    "# Re-enable propagation: message appears in BOTH handlers\n",
    "child.propagate = True\n",
    "print(\"\\n--- Child with own handler + propagation on ---\")\n",
    "child.error(\"Appears in BOTH child and parent handlers\")\n",
    "\n",
    "# Clean up\n",
    "parent.removeHandler(parent_handler)\n",
    "child.removeHandler(child_handler)\n",
    "child.propagate = True\n",
    "parent.propagate = True"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Handlers Per Logger\n",
    "\n",
    "A common pattern is to attach multiple handlers to a single logger, each with a different\n",
    "level and destination. For example: verbose `DEBUG` output to a file, and only `WARNING`+\n",
    "to the console."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import logging\n",
    "import sys\n",
    "import io\n",
    "\n",
    "logger = logging.getLogger(\"myapp.multi\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.handlers.clear()\n",
    "logger.propagate = False\n",
    "\n",
    "# Handler 1: Console -- only WARNING and above\n",
    "console_handler = logging.StreamHandler(sys.stdout)\n",
    "console_handler.setLevel(logging.WARNING)\n",
    "console_handler.setFormatter(logging.Formatter(\n",
    "    \"CONSOLE | %(levelname)-8s | %(message)s\"\n",
    "))\n",
    "\n",
    "# Handler 2: Simulated file (StringIO) -- all levels from DEBUG\n",
    "file_buffer = io.StringIO()\n",
    "file_handler = logging.StreamHandler(file_buffer)\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "file_handler.setFormatter(logging.Formatter(\n",
    "    \"%(asctime)s | %(levelname)-8s | %(name)s | %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    "))\n",
    "\n",
    "logger.addHandler(console_handler)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Emit messages at various levels\n",
    "print(\"=== Console output (WARNING+) ===\")\n",
    "logger.debug(\"Connecting to database\")\n",
    "logger.info(\"Query executed in 45ms\")\n",
    "logger.warning(\"Slow query detected: 2300ms\")\n",
    "logger.error(\"Connection pool exhausted\")\n",
    "\n",
    "# Show what the \"file\" captured (all levels)\n",
    "print(\"\\n=== File output (DEBUG+) ===\")\n",
    "print(file_buffer.getvalue())\n",
    "\n",
    "# Clean up\n",
    "logger.removeHandler(console_handler)\n",
    "logger.removeHandler(file_handler)\n",
    "logger.propagate = True"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters: Custom Log Record Filtering\n",
    "\n",
    "Filters provide fine-grained control over which records a logger or handler processes.\n",
    "A filter can be:\n",
    "- A `logging.Filter` instance (filters by logger name prefix)\n",
    "- Any object with a `filter(record)` method that returns `True`/`False`\n",
    "- A callable that takes a `LogRecord` and returns `True`/`False`"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "\n",
    "class SensitiveDataFilter(logging.Filter):\n",
    "    \"\"\"Filter that redacts sensitive fields from log messages.\"\"\"\n",
    "\n",
    "    SENSITIVE_KEYWORDS: list[str] = [\"password\", \"token\", \"secret\", \"api_key\"]\n",
    "\n",
    "    def filter(self, record: logging.LogRecord) -> bool:\n",
    "        \"\"\"Redact sensitive data but allow the record through.\"\"\"\n",
    "        message: str = record.getMessage()\n",
    "        for keyword in self.SENSITIVE_KEYWORDS:\n",
    "            if keyword in message.lower():\n",
    "                record.msg = f\"[REDACTED - contains '{keyword}']\"\n",
    "                record.args = None\n",
    "                break\n",
    "        return True  # Always allow through (but redacted)\n",
    "\n",
    "\n",
    "class LevelRangeFilter(logging.Filter):\n",
    "    \"\"\"Only allow records within a specific level range.\"\"\"\n",
    "\n",
    "    def __init__(self, low: int = logging.DEBUG, high: int = logging.CRITICAL) -> None:\n",
    "        super().__init__()\n",
    "        self.low = low\n",
    "        self.high = high\n",
    "\n",
    "    def filter(self, record: logging.LogRecord) -> bool:\n",
    "        return self.low <= record.levelno <= self.high\n",
    "\n",
    "\n",
    "# Setup logger\n",
    "logger = logging.getLogger(\"myapp.filters\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.handlers.clear()\n",
    "logger.propagate = False\n",
    "\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setFormatter(logging.Formatter(\"%(levelname)-8s: %(message)s\"))\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# Add the sensitive data filter\n",
    "sensitive_filter = SensitiveDataFilter()\n",
    "handler.addFilter(sensitive_filter)\n",
    "\n",
    "print(\"--- With SensitiveDataFilter ---\")\n",
    "logger.info(\"User alice logged in successfully\")\n",
    "logger.info(\"Authenticating with password=s3cret123\")\n",
    "logger.info(\"Setting API_KEY=abc-def-ghi\")\n",
    "logger.warning(\"Token expired for user bob\")\n",
    "\n",
    "# Add a level range filter: only DEBUG and INFO\n",
    "handler.removeFilter(sensitive_filter)\n",
    "range_filter = LevelRangeFilter(low=logging.DEBUG, high=logging.INFO)\n",
    "handler.addFilter(range_filter)\n",
    "\n",
    "print(\"\\n--- With LevelRangeFilter (DEBUG-INFO only) ---\")\n",
    "logger.debug(\"This DEBUG message passes\")\n",
    "logger.info(\"This INFO message passes\")\n",
    "logger.warning(\"This WARNING will be filtered out\")\n",
    "logger.error(\"This ERROR will be filtered out\")\n",
    "\n",
    "# Clean up\n",
    "handler.removeFilter(range_filter)\n",
    "logger.removeHandler(handler)\n",
    "logger.propagate = True"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RotatingFileHandler and TimedRotatingFileHandler\n",
    "\n",
    "For long-running applications, log files can grow very large. The `logging.handlers`\n",
    "module provides rotating handlers that automatically manage file sizes:\n",
    "\n",
    "- **`RotatingFileHandler`**: Rotates when the file reaches a size limit\n",
    "  - `maxBytes`: Maximum size per file\n",
    "  - `backupCount`: Number of rotated backup files to keep\n",
    "  \n",
    "- **`TimedRotatingFileHandler`**: Rotates based on time intervals\n",
    "  - `when`: `'S'` (seconds), `'M'` (minutes), `'H'` (hours), `'D'` (days), `'midnight'`\n",
    "  - `interval`: Number of time units between rotations\n",
    "  - `backupCount`: Number of backup files to keep"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from logging.handlers import RotatingFileHandler, TimedRotatingFileHandler\n",
    "import logging\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Create a temporary directory for demo log files\n",
    "log_dir: str = tempfile.mkdtemp(prefix=\"logging_demo_\")\n",
    "log_file: str = os.path.join(log_dir, \"app.log\")\n",
    "\n",
    "# RotatingFileHandler: rotate after 1KB, keep 3 backups\n",
    "rotating_handler = RotatingFileHandler(\n",
    "    filename=log_file,\n",
    "    maxBytes=1024,       # Rotate after 1KB\n",
    "    backupCount=3,       # Keep app.log.1, app.log.2, app.log.3\n",
    ")\n",
    "rotating_handler.setFormatter(logging.Formatter(\n",
    "    \"%(asctime)s [%(levelname)s] %(message)s\"\n",
    "))\n",
    "\n",
    "logger = logging.getLogger(\"myapp.rotating\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.handlers.clear()\n",
    "logger.propagate = False\n",
    "logger.addHandler(rotating_handler)\n",
    "\n",
    "# Write enough messages to trigger rotation\n",
    "for i in range(50):\n",
    "    logger.info(\"Log entry number %d: some application event data here\", i)\n",
    "\n",
    "# Close the handler so files are flushed\n",
    "rotating_handler.close()\n",
    "logger.removeHandler(rotating_handler)\n",
    "\n",
    "# Show the rotated files\n",
    "print(f\"Log directory: {log_dir}\")\n",
    "print(f\"\\nFiles created:\")\n",
    "for filename in sorted(os.listdir(log_dir)):\n",
    "    filepath = os.path.join(log_dir, filename)\n",
    "    size = os.path.getsize(filepath)\n",
    "    print(f\"  {filename}: {size} bytes\")\n",
    "\n",
    "# Show content of the most recent log file\n",
    "print(f\"\\nLast 3 lines of app.log:\")\n",
    "with open(log_file) as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[-3:]:\n",
    "        print(f\"  {line.rstrip()}\")\n",
    "\n",
    "# TimedRotatingFileHandler (conceptual -- just show configuration)\n",
    "print(\"\\nTimedRotatingFileHandler configuration example:\")\n",
    "print(\"  when='midnight' -- rotate at midnight each day\")\n",
    "print(\"  interval=1      -- every 1 unit of 'when'\")\n",
    "print(\"  backupCount=7   -- keep one week of logs\")\n",
    "\n",
    "# Clean up temp directory\n",
    "import shutil\n",
    "shutil.rmtree(log_dir)\n",
    "logger.propagate = True"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Logging: JSON-Formatted Output\n",
    "\n",
    "Plain-text logs are human-readable but hard to parse programmatically. **Structured logging**\n",
    "outputs records in a machine-readable format like JSON, making it easy to index, search,\n",
    "and analyze logs with tools like Elasticsearch, Splunk, or CloudWatch."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import json\n",
    "import logging\n",
    "import sys\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "\n",
    "class JSONFormatter(logging.Formatter):\n",
    "    \"\"\"Formats log records as JSON lines.\"\"\"\n",
    "\n",
    "    def format(self, record: logging.LogRecord) -> str:\n",
    "        \"\"\"Convert a LogRecord to a JSON string.\"\"\"\n",
    "        log_data: dict[str, object] = {\n",
    "            \"timestamp\": datetime.fromtimestamp(\n",
    "                record.created, tz=timezone.utc\n",
    "            ).isoformat(),\n",
    "            \"level\": record.levelname,\n",
    "            \"logger\": record.name,\n",
    "            \"message\": record.getMessage(),\n",
    "            \"module\": record.module,\n",
    "            \"function\": record.funcName,\n",
    "            \"line\": record.lineno,\n",
    "        }\n",
    "\n",
    "        # Include exception info if present\n",
    "        if record.exc_info and record.exc_info[0] is not None:\n",
    "            log_data[\"exception\"] = self.formatException(record.exc_info)\n",
    "\n",
    "        # Include any extra fields\n",
    "        if hasattr(record, \"request_id\"):\n",
    "            log_data[\"request_id\"] = record.request_id  # type: ignore[attr-defined]\n",
    "        if hasattr(record, \"user_id\"):\n",
    "            log_data[\"user_id\"] = record.user_id  # type: ignore[attr-defined]\n",
    "\n",
    "        return json.dumps(log_data, default=str)\n",
    "\n",
    "\n",
    "# Set up logger with JSON formatter\n",
    "logger = logging.getLogger(\"myapp.json\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.handlers.clear()\n",
    "logger.propagate = False\n",
    "\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setFormatter(JSONFormatter())\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# Regular log messages become JSON\n",
    "logger.info(\"Application started\")\n",
    "logger.warning(\"Cache miss ratio above threshold: 45%%\")\n",
    "\n",
    "# Log with extra fields\n",
    "logger.info(\n",
    "    \"User authenticated\",\n",
    "    extra={\"request_id\": \"req-abc-123\", \"user_id\": 42}\n",
    ")\n",
    "\n",
    "# Log with exception\n",
    "try:\n",
    "    result: float = 1 / 0\n",
    "except ZeroDivisionError:\n",
    "    logger.error(\"Calculation failed\", exc_info=True)\n",
    "\n",
    "# Clean up\n",
    "logger.removeHandler(handler)\n",
    "logger.propagate = True"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dictConfig: Declarative Logging Configuration\n",
    "\n",
    "`logging.config.dictConfig()` lets you configure the entire logging system from a\n",
    "dictionary. This is the **recommended** approach for complex setups because:\n",
    "\n",
    "- Configuration can be stored in YAML/JSON/TOML files\n",
    "- Easy to change without modifying code\n",
    "- All loggers, handlers, formatters, and filters defined in one place\n",
    "\n",
    "`logging.config.fileConfig()` is the older file-based approach using INI format."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import logging\n",
    "import logging.config\n",
    "import sys\n",
    "\n",
    "# Define the entire logging configuration as a dictionary\n",
    "LOGGING_CONFIG: dict = {\n",
    "    \"version\": 1,                     # Required, always 1\n",
    "    \"disable_existing_loggers\": False, # Don't disable loggers created before config\n",
    "\n",
    "    \"formatters\": {\n",
    "        \"standard\": {\n",
    "            \"format\": \"%(asctime)s [%(levelname)-8s] %(name)s: %(message)s\",\n",
    "            \"datefmt\": \"%H:%M:%S\",\n",
    "        },\n",
    "        \"brief\": {\n",
    "            \"format\": \"%(levelname)s: %(message)s\",\n",
    "        },\n",
    "    },\n",
    "\n",
    "    \"handlers\": {\n",
    "        \"console\": {\n",
    "            \"class\": \"logging.StreamHandler\",\n",
    "            \"level\": \"INFO\",\n",
    "            \"formatter\": \"brief\",\n",
    "            \"stream\": \"ext://sys.stdout\",\n",
    "        },\n",
    "        \"detailed_console\": {\n",
    "            \"class\": \"logging.StreamHandler\",\n",
    "            \"level\": \"DEBUG\",\n",
    "            \"formatter\": \"standard\",\n",
    "            \"stream\": \"ext://sys.stdout\",\n",
    "        },\n",
    "    },\n",
    "\n",
    "    \"loggers\": {\n",
    "        \"myapp\": {\n",
    "            \"level\": \"DEBUG\",\n",
    "            \"handlers\": [\"detailed_console\"],\n",
    "            \"propagate\": False,\n",
    "        },\n",
    "        \"myapp.db\": {\n",
    "            \"level\": \"WARNING\",       # Only warnings+ from the db module\n",
    "            \"handlers\": [\"console\"],\n",
    "            \"propagate\": False,\n",
    "        },\n",
    "    },\n",
    "\n",
    "    \"root\": {\n",
    "        \"level\": \"WARNING\",\n",
    "        \"handlers\": [\"console\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Apply the configuration\n",
    "logging.config.dictConfig(LOGGING_CONFIG)\n",
    "\n",
    "# Test the configured loggers\n",
    "app_logger = logging.getLogger(\"myapp\")\n",
    "db_logger = logging.getLogger(\"myapp.db\")\n",
    "\n",
    "print(\"--- myapp logger (detailed format, DEBUG+) ---\")\n",
    "app_logger.debug(\"Initializing application\")\n",
    "app_logger.info(\"Configuration loaded\")\n",
    "\n",
    "print(\"\\n--- myapp.db logger (brief format, WARNING+) ---\")\n",
    "db_logger.info(\"Executing SELECT query\")       # Filtered out\n",
    "db_logger.warning(\"Query took 5.2 seconds\")\n",
    "db_logger.error(\"Connection lost to primary DB\")\n",
    "\n",
    "# Clean up\n",
    "for name in [\"myapp\", \"myapp.db\"]:\n",
    "    lg = logging.getLogger(name)\n",
    "    lg.handlers.clear()\n",
    "    lg.setLevel(logging.NOTSET)\n",
    "    lg.propagate = True\n",
    "root = logging.getLogger()\n",
    "root.handlers.clear()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging in Libraries vs Applications\n",
    "\n",
    "Libraries and applications have different logging responsibilities:\n",
    "\n",
    "**Libraries** should:\n",
    "- Create loggers using `getLogger(__name__)`\n",
    "- Add a `NullHandler` to suppress \"No handlers could be found\" warnings\n",
    "- **Never** configure handlers, formatters, or levels\n",
    "- Let the application decide how to handle log output\n",
    "\n",
    "**Applications** should:\n",
    "- Configure the root logger or specific loggers with handlers and formatters\n",
    "- Use `dictConfig()` or `basicConfig()` at the entry point\n",
    "- Set appropriate levels for different components"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "\n",
    "# === Library code (what a library author writes) ===\n",
    "# File: mylib/__init__.py\n",
    "lib_logger = logging.getLogger(\"mylib\")\n",
    "lib_logger.addHandler(logging.NullHandler())  # Prevent \"no handler\" warning\n",
    "\n",
    "\n",
    "def library_function(data: str) -> str:\n",
    "    \"\"\"A function in a third-party library.\"\"\"\n",
    "    lib_logger.debug(\"Processing data: %s\", data[:50])\n",
    "    if not data:\n",
    "        lib_logger.warning(\"Empty data received\")\n",
    "        return \"\"\n",
    "    lib_logger.info(\"Data processed successfully, length=%d\", len(data))\n",
    "    return data.upper()\n",
    "\n",
    "\n",
    "# === Without application configuration, library logs are silently discarded ===\n",
    "print(\"--- Without app configuration (NullHandler absorbs logs) ---\")\n",
    "result = library_function(\"hello world\")\n",
    "print(f\"Result: {result}\")\n",
    "print(\"(No log output -- NullHandler absorbed everything)\")\n",
    "\n",
    "# === Application code: configure logging to see library output ===\n",
    "print(\"\\n--- With app configuration ---\")\n",
    "app_handler = logging.StreamHandler(sys.stdout)\n",
    "app_handler.setFormatter(logging.Formatter(\"[%(name)s] %(levelname)s: %(message)s\"))\n",
    "\n",
    "# Configure the library's logger from the application side\n",
    "lib_logger.addHandler(app_handler)\n",
    "lib_logger.setLevel(logging.DEBUG)\n",
    "\n",
    "result = library_function(\"hello world\")\n",
    "print(f\"Result: {result}\")\n",
    "\n",
    "# Clean up\n",
    "lib_logger.removeHandler(app_handler)\n",
    "lib_logger.setLevel(logging.NOTSET)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoggerAdapter: Adding Context with Extra Fields\n",
    "\n",
    "`LoggerAdapter` wraps a logger and injects extra context into every log record.\n",
    "This is useful for adding request IDs, user IDs, or other contextual information\n",
    "without passing them to every log call."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "\n",
    "# Set up a logger with a format that includes 'extra' fields\n",
    "logger = logging.getLogger(\"myapp.adapter\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.handlers.clear()\n",
    "logger.propagate = False\n",
    "\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setFormatter(logging.Formatter(\n",
    "    \"%(asctime)s [%(levelname)s] request_id=%(request_id)s user=%(user)s: %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\"\n",
    "))\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# Create a LoggerAdapter that injects request context\n",
    "request_context: dict[str, str] = {\n",
    "    \"request_id\": \"req-7f3a-b2c1\",\n",
    "    \"user\": \"alice\",\n",
    "}\n",
    "adapter = logging.LoggerAdapter(logger, extra=request_context)\n",
    "\n",
    "# Every log call through the adapter automatically includes the context\n",
    "adapter.info(\"Handling GET /api/users\")\n",
    "adapter.debug(\"Querying database for user list\")\n",
    "adapter.info(\"Returning 25 users\")\n",
    "\n",
    "# A different request gets a different adapter\n",
    "print()\n",
    "another_context: dict[str, str] = {\n",
    "    \"request_id\": \"req-9d4e-f8a2\",\n",
    "    \"user\": \"bob\",\n",
    "}\n",
    "another_adapter = logging.LoggerAdapter(logger, extra=another_context)\n",
    "another_adapter.warning(\"Rate limit approaching for user\")\n",
    "another_adapter.error(\"Permission denied for /admin endpoint\")\n",
    "\n",
    "# Clean up\n",
    "logger.removeHandler(handler)\n",
    "logger.propagate = True"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "\n",
    "class RequestAdapter(logging.LoggerAdapter):\n",
    "    \"\"\"Custom LoggerAdapter that prefixes messages with request context.\"\"\"\n",
    "\n",
    "    def process(\n",
    "        self, msg: str, kwargs: dict\n",
    "    ) -> tuple[str, dict]:\n",
    "        \"\"\"Prepend request context to every log message.\"\"\"\n",
    "        request_id: str = self.extra.get(\"request_id\", \"unknown\")  # type: ignore[union-attr]\n",
    "        client_ip: str = self.extra.get(\"client_ip\", \"unknown\")  # type: ignore[union-attr]\n",
    "        return f\"[{request_id}] [{client_ip}] {msg}\", kwargs\n",
    "\n",
    "\n",
    "# Set up logger with a simple format (context is in the message itself)\n",
    "logger = logging.getLogger(\"myapp.custom_adapter\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.handlers.clear()\n",
    "logger.propagate = False\n",
    "\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setFormatter(logging.Formatter(\"%(levelname)-8s %(message)s\"))\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# Simulate handling two concurrent requests\n",
    "req1 = RequestAdapter(logger, {\"request_id\": \"a1b2c3\", \"client_ip\": \"192.168.1.10\"})\n",
    "req2 = RequestAdapter(logger, {\"request_id\": \"d4e5f6\", \"client_ip\": \"10.0.0.5\"})\n",
    "\n",
    "req1.info(\"Received GET /api/products\")\n",
    "req2.info(\"Received POST /api/orders\")\n",
    "req1.debug(\"Fetching products from cache\")\n",
    "req2.warning(\"Order validation failed: missing field 'quantity'\")\n",
    "req1.info(\"Returning 150 products\")\n",
    "req2.error(\"Order creation failed\")\n",
    "\n",
    "# Clean up\n",
    "logger.removeHandler(handler)\n",
    "logger.propagate = True"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "| Concept | Tool | Purpose |\n",
    "|---------|------|--------|\n",
    "| **Logger hierarchy** | Dot-separated names | Parent-child log propagation |\n",
    "| **Multiple handlers** | `addHandler()` | Send logs to console + file simultaneously |\n",
    "| **Filters** | `logging.Filter`, callables | Fine-grained record filtering and modification |\n",
    "| **Rotating handlers** | `RotatingFileHandler` | Automatic log file rotation by size or time |\n",
    "| **Structured logging** | Custom `Formatter` | JSON output for machine parsing |\n",
    "| **dictConfig** | `logging.config.dictConfig()` | Declarative logging configuration |\n",
    "| **NullHandler** | `logging.NullHandler()` | Silent default handler for libraries |\n",
    "| **LoggerAdapter** | `logging.LoggerAdapter` | Inject context into every log message |\n",
    "\n",
    "### Best Practices\n",
    "- Use `propagate=False` on loggers with their own handlers to avoid duplicate output\n",
    "- Libraries should only add `NullHandler`; applications configure everything else\n",
    "- Use `dictConfig()` for complex setups -- store config in external files\n",
    "- Use `RotatingFileHandler` in production to prevent disk exhaustion\n",
    "- Use structured (JSON) logging when logs will be parsed by aggregation tools\n",
    "- Use `LoggerAdapter` or the `extra` parameter to add request/session context\n",
    "- Set `disable_existing_loggers: False` in `dictConfig` to avoid silencing third-party loggers"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}