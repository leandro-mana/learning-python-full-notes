{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# File Operations\n",
    "\n",
    "**Chapter 8 - Learning Python, 5th Edition**\n",
    "\n",
    "Python provides a comprehensive set of built-in functions and methods for file I/O.\n",
    "Understanding file modes, encoding, context managers, and the distinction between\n",
    "text and binary modes is essential for reading and writing data reliably across platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Section 1: The `open()` Function and File Modes\n",
    "\n",
    "The built-in `open()` function is the gateway to all file I/O. Its `mode` parameter\n",
    "controls how the file is opened:\n",
    "\n",
    "| Mode | Description |\n",
    "|------|-------------|\n",
    "| `'r'` | Read (default) - file must exist |\n",
    "| `'w'` | Write - creates or truncates |\n",
    "| `'a'` | Append - creates or appends |\n",
    "| `'x'` | Exclusive create - fails if file exists |\n",
    "| `'b'` | Binary mode (combine: `'rb'`, `'wb'`) |\n",
    "| `'t'` | Text mode (default, combine: `'rt'`, `'wt'`) |\n",
    "| `'+'` | Read and write (combine: `'r+'`, `'w+'`) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Create a temporary directory for all our examples\n",
    "work_dir = Path(tempfile.mkdtemp(prefix=\"ch08_files_\"))\n",
    "print(f\"Working directory: {work_dir}\")\n",
    "\n",
    "# --- 'w' mode: write (creates or truncates) ---\n",
    "sample_file = work_dir / \"sample.txt\"\n",
    "f = open(sample_file, \"w\")\n",
    "f.write(\"Hello, World!\\n\")\n",
    "f.write(\"Python file I/O is straightforward.\\n\")\n",
    "f.close()  # Must close manually without context manager\n",
    "print(f\"Created {sample_file.name}, size: {sample_file.stat().st_size} bytes\")\n",
    "\n",
    "# --- 'r' mode: read (default) ---\n",
    "f = open(sample_file, \"r\")\n",
    "content = f.read()\n",
    "f.close()\n",
    "print(f\"\\nRead content:\\n{content}\")\n",
    "\n",
    "# --- 'a' mode: append ---\n",
    "f = open(sample_file, \"a\")\n",
    "f.write(\"This line was appended.\\n\")\n",
    "f.close()\n",
    "\n",
    "# --- 'x' mode: exclusive create (fails if file exists) ---\n",
    "new_file = work_dir / \"exclusive.txt\"\n",
    "f = open(new_file, \"x\")\n",
    "f.write(\"Created exclusively.\\n\")\n",
    "f.close()\n",
    "\n",
    "try:\n",
    "    f = open(new_file, \"x\")\n",
    "except FileExistsError as e:\n",
    "    print(f\"'x' mode prevents overwrite: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Section 2: Context Managers (`with` Statement)\n",
    "\n",
    "Always use `with` for file operations. The context manager guarantees the file is\n",
    "closed even if an exception occurs, preventing resource leaks and data corruption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The with statement handles open/close automatically\n",
    "log_file = work_dir / \"app.log\"\n",
    "\n",
    "with open(log_file, \"w\") as f:\n",
    "    f.write(\"2024-01-15 10:00:00 INFO  Application started\\n\")\n",
    "    f.write(\"2024-01-15 10:00:01 DEBUG Loading configuration\\n\")\n",
    "    f.write(\"2024-01-15 10:00:02 WARN  Deprecated API used\\n\")\n",
    "    f.write(\"2024-01-15 10:00:03 ERROR Connection timeout\\n\")\n",
    "    f.write(\"2024-01-15 10:00:05 INFO  Retrying connection\\n\")\n",
    "    # File is automatically closed when exiting the with block\n",
    "\n",
    "print(f\"File closed after with block: {f.closed}\")\n",
    "\n",
    "# Even exceptions don't prevent cleanup\n",
    "error_file = work_dir / \"error_test.txt\"\n",
    "try:\n",
    "    with open(error_file, \"w\") as f:\n",
    "        f.write(\"some data\\n\")\n",
    "        raise ValueError(\"Simulated error during write\")\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "print(f\"File closed despite exception: {f.closed}\")\n",
    "\n",
    "# Multiple files in one with statement\n",
    "source = work_dir / \"source.txt\"\n",
    "dest = work_dir / \"dest.txt\"\n",
    "\n",
    "with open(source, \"w\") as f:\n",
    "    f.write(\"Line 1\\nLine 2\\nLine 3\\n\")\n",
    "\n",
    "with open(source, \"r\") as src, open(dest, \"w\") as dst:\n",
    "    for line in src:\n",
    "        dst.write(line.upper())\n",
    "\n",
    "with open(dest, \"r\") as f:\n",
    "    print(f\"\\nUppercased copy:\\n{f.read()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Section 3: Reading Methods\n",
    "\n",
    "Python offers several ways to read file content, each suited to different use cases:\n",
    "\n",
    "- `read()` - entire file as a single string\n",
    "- `read(n)` - up to `n` characters (text) or bytes (binary)\n",
    "- `readline()` - one line at a time\n",
    "- `readlines()` - all lines as a list\n",
    "- **Iteration** - memory-efficient line-by-line processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a multi-line file for demonstration\n",
    "data_file = work_dir / \"data.txt\"\n",
    "with open(data_file, \"w\") as f:\n",
    "    for i in range(1, 6):\n",
    "        f.write(f\"Line {i}: data point {i * 10}\\n\")\n",
    "\n",
    "# read() - entire file as string\n",
    "with open(data_file, \"r\") as f:\n",
    "    full_content: str = f.read()\n",
    "print(f\"read() returns {type(full_content).__name__}, length={len(full_content)}\")\n",
    "print(f\"Content:\\n{full_content}\")\n",
    "\n",
    "# read(n) - partial read\n",
    "with open(data_file, \"r\") as f:\n",
    "    first_20: str = f.read(20)\n",
    "    next_20: str = f.read(20)\n",
    "print(f\"First 20 chars: {first_20!r}\")\n",
    "print(f\"Next 20 chars:  {next_20!r}\")\n",
    "\n",
    "# readline() - one line at a time\n",
    "print(\"\\nreadline() calls:\")\n",
    "with open(data_file, \"r\") as f:\n",
    "    line1: str = f.readline()\n",
    "    line2: str = f.readline()\n",
    "    print(f\"  Line 1: {line1!r}\")\n",
    "    print(f\"  Line 2: {line2!r}\")\n",
    "\n",
    "# readlines() - all lines as a list\n",
    "with open(data_file, \"r\") as f:\n",
    "    all_lines: list[str] = f.readlines()\n",
    "print(f\"\\nreadlines() returns {len(all_lines)} lines:\")\n",
    "for line in all_lines:\n",
    "    print(f\"  {line!r}\")\n",
    "\n",
    "# Iteration - preferred for large files (memory efficient)\n",
    "print(\"\\nIteration (recommended):\")\n",
    "with open(data_file, \"r\") as f:\n",
    "    for line_num, line in enumerate(f, start=1):\n",
    "        print(f\"  [{line_num}] {line.rstrip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Section 4: Writing Methods\n",
    "\n",
    "- `write(s)` - write a string, returns number of characters written\n",
    "- `writelines(lines)` - write an iterable of strings (no newlines added)\n",
    "- `print(..., file=f)` - redirect print output to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write() returns the number of characters written\n",
    "output_file = work_dir / \"output.txt\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    chars_written: int = f.write(\"Hello, World!\\n\")\n",
    "    print(f\"write() returned: {chars_written} characters\")\n",
    "\n",
    "    chars_written = f.write(\"Second line.\\n\")\n",
    "    print(f\"write() returned: {chars_written} characters\")\n",
    "\n",
    "# writelines() - writes an iterable of strings (no automatic newlines!)\n",
    "lines_file = work_dir / \"lines.txt\"\n",
    "lines: list[str] = [\n",
    "    \"alpha\\n\",\n",
    "    \"bravo\\n\",\n",
    "    \"charlie\\n\",\n",
    "    \"delta\\n\",\n",
    "]\n",
    "\n",
    "with open(lines_file, \"w\") as f:\n",
    "    f.writelines(lines)\n",
    "\n",
    "with open(lines_file, \"r\") as f:\n",
    "    print(f\"\\nwritelines() result:\\n{f.read()}\")\n",
    "\n",
    "# Using print() with file= parameter\n",
    "report_file = work_dir / \"report.txt\"\n",
    "with open(report_file, \"w\") as f:\n",
    "    print(\"=\" * 40, file=f)\n",
    "    print(\"Monthly Report\", file=f)\n",
    "    print(\"=\" * 40, file=f)\n",
    "    for month, revenue in [(\"Jan\", 1200), (\"Feb\", 1350), (\"Mar\", 980)]:\n",
    "        print(f\"  {month}: ${revenue:,}\", file=f)\n",
    "    print(f\"\\n  Total: ${1200 + 1350 + 980:,}\", file=f)\n",
    "\n",
    "with open(report_file, \"r\") as f:\n",
    "    print(f\"print(file=f) result:\\n{f.read()}\")\n",
    "\n",
    "# Writing with a generator (memory efficient for large data)\n",
    "gen_file = work_dir / \"generated.txt\"\n",
    "with open(gen_file, \"w\") as f:\n",
    "    f.writelines(f\"item_{i:04d}\\n\" for i in range(5))\n",
    "\n",
    "with open(gen_file, \"r\") as f:\n",
    "    print(f\"Generator writelines:\\n{f.read()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Section 5: Text vs Binary Mode\n",
    "\n",
    "Text mode (`'t'`, the default) handles encoding/decoding and normalizes line endings.\n",
    "Binary mode (`'b'`) reads and writes raw bytes without any transformation.\n",
    "\n",
    "- **Text mode**: `str` objects, automatic newline translation (`\\n` <-> OS-specific)\n",
    "- **Binary mode**: `bytes` objects, no translation, required for non-text data (images, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text mode: works with str\n",
    "text_file = work_dir / \"text_mode.txt\"\n",
    "with open(text_file, \"w\") as f:  # 'w' is shorthand for 'wt'\n",
    "    f.write(\"Text mode uses str objects.\\n\")\n",
    "    f.write(\"Newlines are translated automatically.\\n\")\n",
    "\n",
    "with open(text_file, \"r\") as f:\n",
    "    text_data: str = f.read()\n",
    "    print(f\"Text mode type: {type(text_data).__name__}\")\n",
    "    print(f\"Content: {text_data!r}\")\n",
    "\n",
    "# Binary mode: works with bytes\n",
    "bin_file = work_dir / \"binary_mode.bin\"\n",
    "with open(bin_file, \"wb\") as f:\n",
    "    f.write(b\"\\x89PNG\\r\\n\\x1a\\n\")  # PNG file header bytes\n",
    "    f.write(b\"\\x00\\x01\\x02\\x03\\x04\")\n",
    "    f.write(bytes([0xFF, 0xFE, 0xFD]))\n",
    "\n",
    "with open(bin_file, \"rb\") as f:\n",
    "    bin_data: bytes = f.read()\n",
    "    print(f\"\\nBinary mode type: {type(bin_data).__name__}\")\n",
    "    print(f\"Raw bytes: {bin_data!r}\")\n",
    "    print(f\"Hex: {bin_data.hex(' ')}\")\n",
    "    print(f\"Length: {len(bin_data)} bytes\")\n",
    "\n",
    "# Mixing modes raises TypeError\n",
    "try:\n",
    "    with open(bin_file, \"wb\") as f:\n",
    "        f.write(\"text string\")  # Cannot write str in binary mode\n",
    "except TypeError as e:\n",
    "    print(f\"\\nTypeError: {e}\")\n",
    "\n",
    "# Reading a text file in binary mode shows raw bytes\n",
    "with open(text_file, \"rb\") as f:\n",
    "    raw: bytes = f.read()\n",
    "    print(f\"\\nText file read as binary: {raw!r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Section 6: File Encoding\n",
    "\n",
    "Text files must be decoded from bytes to strings. The `encoding` parameter tells\n",
    "Python which codec to use. Always specify encoding explicitly for portability.\n",
    "\n",
    "Common encodings:\n",
    "- `'utf-8'` - Universal, supports all Unicode (recommended default)\n",
    "- `'ascii'` - 7-bit, English only\n",
    "- `'latin-1'` (ISO 8859-1) - Western European, maps bytes 0-255 directly\n",
    "- `'utf-16'` - Fixed 2-byte encoding with BOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Check the platform default encoding\n",
    "print(f\"Platform default encoding: {sys.getdefaultencoding()}\")\n",
    "\n",
    "# Write UTF-8 text with international characters\n",
    "utf8_file = work_dir / \"utf8.txt\"\n",
    "with open(utf8_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"English: Hello, World!\\n\")\n",
    "    f.write(\"French: Bonjour le monde!\\n\")\n",
    "    f.write(\"Japanese: \\u3053\\u3093\\u306b\\u3061\\u306f\\u4e16\\u754c\\n\")\n",
    "    f.write(\"Emoji: \\U0001F40D Python\\n\")\n",
    "\n",
    "with open(utf8_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    print(f\"UTF-8 content:\\n{f.read()}\")\n",
    "\n",
    "# Show byte-level differences between encodings\n",
    "test_string = \"caf\\u00e9\"  # cafe with accent\n",
    "print(f\"String: {test_string!r}\")\n",
    "\n",
    "for enc in [\"utf-8\", \"latin-1\", \"ascii\"]:\n",
    "    try:\n",
    "        encoded: bytes = test_string.encode(enc)\n",
    "        print(f\"  {enc:10s}: {encoded!r} ({len(encoded)} bytes)\")\n",
    "    except UnicodeEncodeError as e:\n",
    "        print(f\"  {enc:10s}: FAILED - {e}\")\n",
    "\n",
    "# The errors parameter controls how encoding/decoding failures are handled\n",
    "problem_bytes = b\"caf\\xe9\"  # Latin-1 encoded\n",
    "\n",
    "for errors_mode in [\"strict\", \"replace\", \"ignore\", \"backslashreplace\"]:\n",
    "    try:\n",
    "        decoded = problem_bytes.decode(\"utf-8\", errors=errors_mode)\n",
    "        print(f\"\\nerrors={errors_mode!r:20s} -> {decoded!r}\")\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"\\nerrors={errors_mode!r:20s} -> UnicodeDecodeError: {e}\")\n",
    "\n",
    "# Practical pattern: read with fallback encoding\n",
    "def read_text_file(path: Path, encodings: list[str] | None = None) -> str:\n",
    "    \"\"\"Try multiple encodings until one works.\"\"\"\n",
    "    if encodings is None:\n",
    "        encodings = [\"utf-8\", \"latin-1\", \"cp1252\"]\n",
    "    for enc in encodings:\n",
    "        try:\n",
    "            with open(path, \"r\", encoding=enc) as f:\n",
    "                return f.read()\n",
    "        except (UnicodeDecodeError, LookupError):\n",
    "            continue\n",
    "    raise ValueError(f\"Could not decode {path} with any of {encodings}\")\n",
    "\n",
    "# Test with a Latin-1 encoded file\n",
    "latin_file = work_dir / \"latin1.txt\"\n",
    "with open(latin_file, \"wb\") as f:\n",
    "    f.write(b\"caf\\xe9\\n\")\n",
    "\n",
    "result = read_text_file(latin_file)\n",
    "print(f\"\\nFallback reader result: {result!r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Section 7: File Position with `seek()` and `tell()`\n",
    "\n",
    "Every open file has a position cursor. `tell()` returns the current position,\n",
    "and `seek(offset, whence)` moves it.\n",
    "\n",
    "In **text mode**, positions are opaque values returned by `tell()` (only `seek(0)` is\n",
    "guaranteed portable). In **binary mode**, positions are byte offsets.\n",
    "\n",
    "| `whence` | Meaning |\n",
    "|----------|---------|\n",
    "| `0` | Start of file (default) |\n",
    "| `1` | Current position (binary only) |\n",
    "| `2` | End of file (binary only) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seek() and tell() in binary mode (full control)\n",
    "seek_file = work_dir / \"seek_demo.bin\"\n",
    "with open(seek_file, \"wb\") as f:\n",
    "    f.write(b\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\")\n",
    "\n",
    "with open(seek_file, \"rb\") as f:\n",
    "    print(f\"Initial position: {f.tell()}\")\n",
    "\n",
    "    # Read first 5 bytes\n",
    "    data = f.read(5)\n",
    "    print(f\"Read 5 bytes: {data!r}, position now: {f.tell()}\")\n",
    "\n",
    "    # Seek to absolute position\n",
    "    f.seek(10)\n",
    "    print(f\"After seek(10): position={f.tell()}, next={f.read(3)!r}\")\n",
    "\n",
    "    # Seek relative to current position (whence=1)\n",
    "    f.seek(2, 1)\n",
    "    print(f\"After seek(2, 1): position={f.tell()}, next={f.read(3)!r}\")\n",
    "\n",
    "    # Seek from end (whence=2)\n",
    "    f.seek(-5, 2)\n",
    "    print(f\"After seek(-5, 2): position={f.tell()}, rest={f.read()!r}\")\n",
    "\n",
    "    # Rewind to start\n",
    "    f.seek(0)\n",
    "    print(f\"After seek(0): position={f.tell()}, full={f.read()!r}\")\n",
    "\n",
    "# seek() and tell() in text mode (limited)\n",
    "text_seek = work_dir / \"seek_text.txt\"\n",
    "with open(text_seek, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"Line 1\\nLine 2\\nLine 3\\n\")\n",
    "\n",
    "with open(text_seek, \"r\", encoding=\"utf-8\") as f:\n",
    "    pos_0 = f.tell()\n",
    "    line1 = f.readline()\n",
    "    pos_after_line1 = f.tell()\n",
    "    line2 = f.readline()\n",
    "\n",
    "    print(f\"\\nText mode positions:\")\n",
    "    print(f\"  Start: {pos_0}\")\n",
    "    print(f\"  After line 1 ({line1.rstrip()!r}): {pos_after_line1}\")\n",
    "\n",
    "    # In text mode, only seek(0) and seek(tell_value) are safe\n",
    "    f.seek(pos_after_line1)\n",
    "    re_read = f.readline()\n",
    "    print(f\"  Re-read from saved position: {re_read.rstrip()!r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Section 8: Practical Pattern - Line-Oriented Processing\n",
    "\n",
    "A common real-world pattern: process a file line by line, filtering, transforming,\n",
    "or aggregating data. This approach is memory-efficient for large files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class LogEntry:\n",
    "    \"\"\"Parsed log entry.\"\"\"\n",
    "    timestamp: str\n",
    "    level: str\n",
    "    message: str\n",
    "\n",
    "\n",
    "def parse_log_line(line: str) -> LogEntry | None:\n",
    "    \"\"\"Parse a log line into a LogEntry, or None if malformed.\"\"\"\n",
    "    parts = line.strip().split(maxsplit=3)\n",
    "    if len(parts) < 4:\n",
    "        return None\n",
    "    timestamp = f\"{parts[0]} {parts[1]}\"\n",
    "    level = parts[2]\n",
    "    message = parts[3]\n",
    "    return LogEntry(timestamp=timestamp, level=level, message=message)\n",
    "\n",
    "\n",
    "def analyze_log(path: Path) -> dict[str, int]:\n",
    "    \"\"\"Analyze a log file and return counts by level.\"\"\"\n",
    "    level_counts: Counter[str] = Counter()\n",
    "    error_messages: list[str] = []\n",
    "\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            entry = parse_log_line(line)\n",
    "            if entry is None:\n",
    "                continue\n",
    "            level_counts[entry.level] += 1\n",
    "            if entry.level == \"ERROR\":\n",
    "                error_messages.append(entry.message)\n",
    "\n",
    "    return dict(level_counts), error_messages\n",
    "\n",
    "\n",
    "# Use the log file we created earlier\n",
    "counts, errors = analyze_log(log_file)\n",
    "print(f\"Log level counts: {counts}\")\n",
    "print(f\"Error messages: {errors}\")\n",
    "\n",
    "# Practical: filter log to a new file\n",
    "error_log = work_dir / \"errors_only.log\"\n",
    "lines_written: int = 0\n",
    "\n",
    "with open(log_file, \"r\", encoding=\"utf-8\") as src, \\\n",
    "     open(error_log, \"w\", encoding=\"utf-8\") as dst:\n",
    "    for line in src:\n",
    "        entry = parse_log_line(line)\n",
    "        if entry and entry.level in (\"ERROR\", \"WARN\"):\n",
    "            dst.write(line)\n",
    "            lines_written += 1\n",
    "\n",
    "print(f\"\\nFiltered {lines_written} warning/error lines to {error_log.name}\")\n",
    "with open(error_log, \"r\") as f:\n",
    "    print(f.read())\n",
    "\n",
    "# Cleanup temporary directory\n",
    "import shutil\n",
    "shutil.rmtree(work_dir)\n",
    "print(f\"Cleaned up {work_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### File Modes\n",
    "- `'r'` read, `'w'` write (truncate), `'a'` append, `'x'` exclusive create\n",
    "- `'b'` binary, `'t'` text (default), `'+'` read-write\n",
    "\n",
    "### Reading\n",
    "- `read()` for small files, iteration for large files\n",
    "- `readline()` for one line, `readlines()` for all lines as list\n",
    "\n",
    "### Writing\n",
    "- `write()` returns character count, `writelines()` takes an iterable\n",
    "- `print(..., file=f)` for formatted output\n",
    "\n",
    "### Best Practices\n",
    "1. **Always** use `with` statements for file handling\n",
    "2. **Always** specify `encoding='utf-8'` explicitly\n",
    "3. Use iteration (not `read()`) for large files\n",
    "4. Use `'x'` mode when you need to prevent accidental overwrites\n",
    "5. Use binary mode for non-text data (images, archives, protocols)\n",
    "6. Use `seek()`/`tell()` in binary mode for random access; avoid in text mode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}