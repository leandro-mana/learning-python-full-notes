{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 13: Practical Text Processing\n",
    "\n",
    "**Chapter 13 - Learning Python**\n",
    "\n",
    "This notebook bridges the gap between regex theory and real-world usage.\n",
    "We cover email validation, compiled patterns, data extraction from structured\n",
    "text, efficient iteration with `finditer`, when to prefer string methods over\n",
    "regex, and common pitfalls to avoid.\n",
    "\n",
    "## Key Concepts\n",
    "- **Email validation**: building a practical (not RFC-complete) email pattern\n",
    "- **`re.split`**: splitting strings on complex delimiters\n",
    "- **`re.compile`**: pre-compiling patterns for reuse and readability\n",
    "- **Data extraction**: parsing logs, CSVs, and structured text\n",
    "- **`re.finditer`**: memory-efficient iteration over matches\n",
    "- **String methods vs regex**: choosing the right tool\n",
    "- **Common pitfalls**: catastrophic backtracking and over-engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Email Validation\n",
    "\n",
    "Email validation with regex is a classic exercise. A fully RFC 5322-compliant\n",
    "pattern is extraordinarily complex. In practice, a reasonable approximation\n",
    "covers the vast majority of valid addresses."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import re\n",
    "\n",
    "# A practical email validation pattern\n",
    "# Matches: local part @ domain . tld\n",
    "# Local part: letters, digits, dots, underscores, hyphens, plus\n",
    "# Domain: letters, digits, hyphens, with at least one dot\n",
    "# TLD: 2 or more letters\n",
    "EMAIL_PATTERN = re.compile(\n",
    "    r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\"\n",
    ")\n",
    "\n",
    "\n",
    "def is_valid_email(email: str) -> bool:\n",
    "    \"\"\"Check if a string looks like a valid email address.\"\"\"\n",
    "    return bool(EMAIL_PATTERN.match(email))\n",
    "\n",
    "\n",
    "test_emails = [\n",
    "    \"user@example.com\",         # valid\n",
    "    \"alice.bob+tag@work.org\",   # valid (dots, plus in local)\n",
    "    \"name@sub.domain.co.uk\",    # valid (subdomain)\n",
    "    \"@missing-local.com\",       # invalid (no local part)\n",
    "    \"no-at-sign.com\",           # invalid (no @)\n",
    "    \"user@.com\",                # invalid (dot after @)\n",
    "    \"user@domain\",              # invalid (no TLD)\n",
    "    \"user@domain.a\",            # invalid (TLD too short)\n",
    "]\n",
    "\n",
    "print(\"Email validation results:\")\n",
    "for email in test_emails:\n",
    "    status = \"valid\" if is_valid_email(email) else \"INVALID\"\n",
    "    print(f\"  {email:35s} -> {status}\")\n",
    "\n",
    "print(\"\\nNote: For production use, consider the 'email-validator' package.\")\n",
    "print(\"Regex can never fully validate emails per RFC 5322.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `re.split` -- Splitting on Complex Patterns\n",
    "\n",
    "`str.split()` works on literal delimiters. `re.split()` lets you split on\n",
    "patterns, handling multiple or variable delimiters in one call."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import re\n",
    "\n",
    "# Problem: split on commas, semicolons, or pipes (with optional whitespace)\n",
    "data = \"apple, banana; cherry | date,  elderberry;fig\"\n",
    "\n",
    "# str.split can only handle one delimiter\n",
    "print(f\"str.split(','):  {data.split(',')}\")\n",
    "\n",
    "# re.split handles multiple delimiters at once\n",
    "items = re.split(r\"[,;|]\\s*\", data)\n",
    "print(f\"re.split:        {items}\")\n",
    "\n",
    "# Split on one or more whitespace characters (like str.split() but explicit)\n",
    "messy = \"  hello   world\\tfoo\\n\\nbar  \"\n",
    "clean = re.split(r\"\\s+\", messy.strip())\n",
    "print(f\"\\nWhitespace split: {clean}\")\n",
    "\n",
    "# Capturing groups in the split pattern KEEP the delimiters\n",
    "equation = \"3+4-5*2/1\"\n",
    "parts = re.split(r\"([+\\-*/])\", equation)\n",
    "print(f\"\\nSplit with captured delimiters: {parts}\")\n",
    "\n",
    "# maxsplit parameter: limit the number of splits\n",
    "log_line = \"ERROR:2024-01-15:disk:full:critical\"\n",
    "level, date, rest = re.split(r\":\", log_line, maxsplit=2)\n",
    "print(f\"\\nmaxsplit=2: level={level!r}, date={date!r}, rest={rest!r}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiled Patterns with `re.compile`\n",
    "\n",
    "`re.compile(pattern)` returns a reusable `Pattern` object. Benefits:\n",
    "- **Performance**: the pattern is compiled once and reused across many calls\n",
    "- **Readability**: the pattern gets a descriptive variable name\n",
    "- **Organization**: group related flags and patterns together\n",
    "\n",
    "The compiled object has the same methods: `.match()`, `.search()`, `.findall()`,\n",
    "`.sub()`, `.split()`, etc."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import re\n",
    "\n",
    "# Compile a pattern once, use it many times\n",
    "WORD_PATTERN = re.compile(r\"\\b[A-Z][a-z]+\\b\")\n",
    "IP_PATTERN = re.compile(\n",
    "    r\"\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b\"\n",
    ")\n",
    "\n",
    "# Use the compiled pattern's methods directly\n",
    "texts = [\n",
    "    \"Alice met Bob in Paris\",\n",
    "    \"the quick brown fox jumped\",\n",
    "    \"Charlie went to New York and London\",\n",
    "]\n",
    "\n",
    "print(\"Capitalized words (compiled pattern):\")\n",
    "for text in texts:\n",
    "    matches = WORD_PATTERN.findall(text)\n",
    "    print(f\"  {text!r} -> {matches}\")\n",
    "\n",
    "# IP address matching\n",
    "log = \"\"\"Connection from 192.168.1.1 accepted\n",
    "Failed login from 10.0.0.5\n",
    "Timeout on 172.16.0.100\"\"\"\n",
    "\n",
    "print(f\"\\nIP addresses found: {IP_PATTERN.findall(log)}\")\n",
    "\n",
    "# Compiled patterns with flags\n",
    "COMMENT_PATTERN = re.compile(\n",
    "    r\"#.*$\",          # '#' followed by anything to end of line\n",
    "    re.MULTILINE,     # $ matches at each line end\n",
    ")\n",
    "\n",
    "code = \"\"\"x = 42  # the answer\n",
    "y = x + 1  # increment\n",
    "print(y)  # output\"\"\"\n",
    "\n",
    "stripped = COMMENT_PATTERN.sub(\"\", code)\n",
    "print(f\"\\nCode without comments:\")\n",
    "print(stripped)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Data from Structured Text\n",
    "\n",
    "Regex excels at parsing semi-structured text like log files, configuration\n",
    "files, and simple data formats."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import re\n",
    "from typing import NamedTuple\n",
    "\n",
    "\n",
    "class LogEntry(NamedTuple):\n",
    "    timestamp: str\n",
    "    level: str\n",
    "    module: str\n",
    "    message: str\n",
    "\n",
    "\n",
    "LOG_PATTERN = re.compile(\n",
    "    r\"\\[(?P<timestamp>[\\d-]+ [\\d:]+)\\]\\s+\"\n",
    "    r\"(?P<level>DEBUG|INFO|WARNING|ERROR|CRITICAL)\\s+\"\n",
    "    r\"(?P<module>[\\w.]+):\\s+\"\n",
    "    r\"(?P<message>.+)\"\n",
    ")\n",
    "\n",
    "\n",
    "def parse_log(log_text: str) -> list[LogEntry]:\n",
    "    \"\"\"Parse structured log lines into LogEntry objects.\"\"\"\n",
    "    entries: list[LogEntry] = []\n",
    "    for m in LOG_PATTERN.finditer(log_text):\n",
    "        entries.append(LogEntry(**m.groupdict()))\n",
    "    return entries\n",
    "\n",
    "\n",
    "sample_log = \"\"\"[2024-01-15 10:23:45] INFO server.main: Server started on port 8080\n",
    "[2024-01-15 10:23:46] DEBUG server.auth: Loading auth configuration\n",
    "[2024-01-15 10:24:01] WARNING server.db: Connection pool 80% full\n",
    "[2024-01-15 10:24:15] ERROR server.handler: Request timeout after 30s\n",
    "[2024-01-15 10:24:16] INFO server.handler: Retrying request\"\"\"\n",
    "\n",
    "entries = parse_log(sample_log)\n",
    "print(f\"Parsed {len(entries)} log entries:\\n\")\n",
    "for entry in entries:\n",
    "    print(f\"  [{entry.level:8s}] {entry.timestamp} | {entry.module}: {entry.message}\")\n",
    "\n",
    "# Filter: show only warnings and errors\n",
    "issues = [e for e in entries if e.level in (\"WARNING\", \"ERROR\", \"CRITICAL\")]\n",
    "print(f\"\\nIssues found: {len(issues)}\")\n",
    "for e in issues:\n",
    "    print(f\"  {e.level}: {e.message}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `re.finditer` -- Memory-Efficient Iteration\n",
    "\n",
    "`re.findall` builds a list of all matches in memory. `re.finditer` returns\n",
    "an **iterator** of `Match` objects, yielding one match at a time. This is\n",
    "more memory-efficient for large texts and gives access to the full `Match`\n",
    "object (position, groups, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import re\n",
    "\n",
    "text = \"\"\"Scores: Alice=95, Bob=87, Charlie=92, Diana=88, Eve=96\"\"\"\n",
    "\n",
    "# findall returns strings (or tuples) -- loses position information\n",
    "names_scores = re.findall(r\"(\\w+)=(\\d+)\", text)\n",
    "print(f\"findall: {names_scores}\")\n",
    "\n",
    "# finditer returns Match objects -- preserves full match information\n",
    "print(\"\\nfinditer (with positions):\")\n",
    "for m in re.finditer(r\"(?P<name>\\w+)=(?P<score>\\d+)\", text):\n",
    "    print(f\"  {m.group('name'):10s} score={m.group('score'):>3s}  \"\n",
    "          f\"at position {m.start()}-{m.end()}\")\n",
    "\n",
    "# finditer is an iterator -- it doesn't build the full list in memory\n",
    "# This matters when processing large files\n",
    "large_text = \"word \" * 10000  # simulate a large document\n",
    "pattern = re.compile(r\"\\bword\\b\")\n",
    "\n",
    "# Count matches without building a list\n",
    "count = sum(1 for _ in pattern.finditer(large_text))\n",
    "print(f\"\\nMatches in large text (via finditer): {count}\")\n",
    "\n",
    "# Compare: findall creates a list of 10000 strings in memory\n",
    "# finditer yields one match at a time"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Methods vs Regex: When to Use Which\n",
    "\n",
    "Regex is powerful but not always the best tool. Python's built-in string\n",
    "methods are faster and more readable for simple operations.\n",
    "\n",
    "**Use string methods when:**\n",
    "- Searching for a literal substring\n",
    "- Splitting on a fixed delimiter\n",
    "- Simple prefix/suffix checks\n",
    "- Case conversion or stripping whitespace\n",
    "\n",
    "**Use regex when:**\n",
    "- The pattern is variable or complex\n",
    "- You need capturing groups\n",
    "- Multiple delimiters or flexible whitespace\n",
    "- Validation against a structured format"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import re\n",
    "import timeit\n",
    "\n",
    "text = \"Hello, World! Hello, Python!\"\n",
    "\n",
    "# --- Task 1: Check if string contains a substring ---\n",
    "# String method (preferred -- simpler, faster)\n",
    "has_python_str = \"Python\" in text\n",
    "# Regex (overkill for this)\n",
    "has_python_re = bool(re.search(r\"Python\", text))\n",
    "print(f\"Contains 'Python' (str): {has_python_str}\")\n",
    "print(f\"Contains 'Python' (re):  {has_python_re}\")\n",
    "\n",
    "# --- Task 2: Check prefix ---\n",
    "# String method (preferred)\n",
    "starts_hello_str = text.startswith(\"Hello\")\n",
    "# Regex (unnecessary complexity)\n",
    "starts_hello_re = bool(re.match(r\"Hello\", text))\n",
    "print(f\"\\nStarts with 'Hello' (str): {starts_hello_str}\")\n",
    "print(f\"Starts with 'Hello' (re):  {starts_hello_re}\")\n",
    "\n",
    "# --- Task 3: Replace fixed string ---\n",
    "# String method (preferred)\n",
    "replaced_str = text.replace(\"Hello\", \"Hi\")\n",
    "# Regex\n",
    "replaced_re = re.sub(r\"Hello\", \"Hi\", text)\n",
    "print(f\"\\nReplace (str): {replaced_str}\")\n",
    "print(f\"Replace (re):  {replaced_re}\")\n",
    "\n",
    "# --- Task 4: Complex pattern -- regex is appropriate ---\n",
    "# Extract version numbers like 'v1.2.3' or 'v10.0.1'\n",
    "changelog = \"Released v1.2.3, hotfix v1.2.4, major v2.0.0\"\n",
    "# No clean way to do this with string methods!\n",
    "versions = re.findall(r\"v\\d+\\.\\d+\\.\\d+\", changelog)\n",
    "print(f\"\\nVersions (regex is the right tool): {versions}\")\n",
    "\n",
    "# --- Performance comparison ---\n",
    "sample = \"abc\" * 1000 + \"target\" + \"xyz\" * 1000\n",
    "t_str = timeit.timeit(lambda: \"target\" in sample, number=10000)\n",
    "t_re = timeit.timeit(lambda: re.search(r\"target\", sample), number=10000)\n",
    "print(f\"\\nPerformance (10k iterations):\")\n",
    "print(f\"  'in' operator: {t_str:.4f}s\")\n",
    "print(f\"  re.search:     {t_re:.4f}s\")\n",
    "print(f\"  String method is ~{t_re / t_str:.1f}x faster for literal search\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Pitfalls\n",
    "\n",
    "### 1. Catastrophic Backtracking\n",
    "Certain patterns with nested quantifiers can cause the regex engine to\n",
    "explore an exponential number of paths, effectively hanging your program.\n",
    "\n",
    "### 2. Over-Engineering with Regex\n",
    "Not every text problem needs regex. Using regex for tasks that string\n",
    "methods handle cleanly makes code harder to read and maintain.\n",
    "\n",
    "### 3. Forgetting Raw Strings\n",
    "Without `r\"...\"`, backslash sequences are interpreted by Python before\n",
    "reaching the regex engine."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import re\n",
    "import time\n",
    "\n",
    "# --- Pitfall 1: Catastrophic backtracking ---\n",
    "# BAD pattern: nested quantifiers on overlapping character classes\n",
    "# Pattern: (a+)+ matching against 'aaaaaaaaaaab'\n",
    "# The engine tries exponentially many ways to divide 'a's among groups\n",
    "\n",
    "print(\"Catastrophic backtracking demonstration:\")\n",
    "print(\"  BAD pattern: r'(a+)+b' with input 'aaa...ab' (no match case)\")\n",
    "\n",
    "# Safe: short input\n",
    "safe_input = \"a\" * 10 + \"b\"\n",
    "start = time.time()\n",
    "re.match(r\"(a+)+b\", safe_input)\n",
    "print(f\"  10 a's + 'b' (match):   {time.time() - start:.6f}s\")\n",
    "\n",
    "# Dangerous: input that does NOT match causes backtracking\n",
    "danger_input = \"a\" * 20 + \"c\"  # no 'b', so engine backtracks\n",
    "start = time.time()\n",
    "re.match(r\"(a+)+b\", danger_input)\n",
    "elapsed = time.time() - start\n",
    "print(f\"  20 a's + 'c' (no match): {elapsed:.6f}s\")\n",
    "\n",
    "# The fix: use atomic patterns or possessive quantifiers\n",
    "# In Python, rewrite to avoid nested quantifiers\n",
    "start = time.time()\n",
    "re.match(r\"a+b\", danger_input)  # Fixed: no nested quantifier\n",
    "print(f\"  Fixed pattern (a+b):     {time.time() - start:.6f}s\")\n",
    "\n",
    "print(\"\\n--- Pitfall 2: Over-engineering ---\")\n",
    "# DON'T use regex for simple checks\n",
    "filename = \"report.pdf\"\n",
    "\n",
    "# Overcomplicated regex\n",
    "is_pdf_regex = bool(re.search(r\"\\.pdf$\", filename))\n",
    "# Clean string method\n",
    "is_pdf_simple = filename.endswith(\".pdf\")\n",
    "print(f\"  regex way:  {is_pdf_regex}\")\n",
    "print(f\"  simple way: {is_pdf_simple}  (prefer this!)\")\n",
    "\n",
    "print(\"\\n--- Pitfall 3: Forgetting raw strings ---\")\n",
    "# \\b in a normal string is a backspace character\n",
    "bad_pattern = \"\\bword\\b\"       # \\b = backspace!\n",
    "good_pattern = r\"\\bword\\b\"     # \\b = word boundary\n",
    "text = \"a word here\"\n",
    "print(f\"  Without r'': {re.search(bad_pattern, text)}\")\n",
    "print(f\"  With r'':    {re.search(good_pattern, text).group()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Practical Patterns\n",
    "- **Email validation**: `r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\"`\n",
    "- For production, use dedicated validation libraries rather than regex alone\n",
    "\n",
    "### `re.split` and `re.compile`\n",
    "- `re.split(pattern, string)` handles multiple/variable delimiters\n",
    "- `re.compile(pattern)` creates a reusable `Pattern` object for performance and readability\n",
    "\n",
    "### Data Extraction\n",
    "- Named groups + `finditer` + `NamedTuple` is a clean pattern for parsing structured text\n",
    "- `re.finditer` is memory-efficient: yields `Match` objects one at a time\n",
    "\n",
    "### When NOT to Use Regex\n",
    "- Literal substring search: use `in`, `.find()`, `.index()`\n",
    "- Fixed-string replacement: use `.replace()`\n",
    "- Prefix/suffix checks: use `.startswith()`, `.endswith()`\n",
    "- Simple splitting: use `.split()`\n",
    "\n",
    "### Pitfalls to Avoid\n",
    "1. **Catastrophic backtracking**: avoid nested quantifiers like `(a+)+`\n",
    "2. **Over-engineering**: don't use regex when string methods suffice\n",
    "3. **Forgetting raw strings**: always use `r\"...\"` for regex patterns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}