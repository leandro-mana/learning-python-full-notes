{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 12: The functools Module\n",
    "\n",
    "The `functools` module provides higher-order functions and operations on callable objects.\n",
    "It is one of Python's most important standard library modules for functional programming,\n",
    "offering tools for partial application, memoization, reduction, and more.\n",
    "\n",
    "## Key Concepts\n",
    "- **`partial`**: Pre-fill function arguments to create specialized versions\n",
    "- **`lru_cache` / `cache`**: Automatic memoization of function results\n",
    "- **`reduce`**: Cumulative application of a function over a sequence\n",
    "- **`total_ordering`**: Auto-generate comparison methods\n",
    "- **`wraps`**: Preserve function metadata in decorators\n",
    "- **`singledispatch`**: Generic functions with type-based dispatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: functools.partial\n",
    "\n",
    "`partial` creates a new function with some arguments pre-filled. This is useful for\n",
    "adapting functions to interfaces that expect fewer arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "# partial pre-fills function arguments\n",
    "# Example: create a binary string parser from int()\n",
    "base2_log = functools.partial(int, base=2)\n",
    "print(f\"binary '1010' = {base2_log('1010')}\")   # 10\n",
    "print(f\"binary '1111' = {base2_log('1111')}\")   # 15\n",
    "print(f\"binary '11001' = {base2_log('11001')}\") # 25\n",
    "\n",
    "# Create a hex parser too\n",
    "hex_to_int = functools.partial(int, base=16)\n",
    "print(f\"\\nhex 'ff' = {hex_to_int('ff')}\")\n",
    "print(f\"hex '1a' = {hex_to_int('1a')}\")\n",
    "\n",
    "# partial with positional arguments\n",
    "def power(base: float, exponent: float) -> float:\n",
    "    return base ** exponent\n",
    "\n",
    "square = functools.partial(power, exponent=2)\n",
    "cube = functools.partial(power, exponent=3)\n",
    "\n",
    "print(f\"\\nsquare(5) = {square(5)}\")\n",
    "print(f\"cube(3) = {cube(3)}\")\n",
    "\n",
    "# Inspect partial objects\n",
    "print(f\"\\npartial func: {square.func.__name__}\")\n",
    "print(f\"partial keywords: {square.keywords}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Memoization with lru_cache and cache\n",
    "\n",
    "Memoization stores the results of expensive function calls and returns the cached result\n",
    "when the same inputs occur again. `lru_cache` provides an LRU (Least Recently Used) cache,\n",
    "while `cache` (Python 3.9+) provides an unbounded cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "# lru_cache: memoize with bounded cache\n",
    "call_count: int = 0\n",
    "\n",
    "@functools.lru_cache(maxsize=None)  # maxsize=None means unbounded\n",
    "def fibonacci(n: int) -> int:\n",
    "    \"\"\"Compute the nth Fibonacci number with memoization.\"\"\"\n",
    "    global call_count\n",
    "    call_count += 1\n",
    "    if n < 2:\n",
    "        return n\n",
    "    return fibonacci(n - 1) + fibonacci(n - 2)\n",
    "\n",
    "result = fibonacci(10)\n",
    "print(f\"fibonacci(10) = {result}\")\n",
    "print(f\"Function was called {call_count} times (11 unique values, each computed once)\")\n",
    "\n",
    "# Cache info shows hits, misses, and size\n",
    "print(f\"Cache info: {fibonacci.cache_info()}\")\n",
    "\n",
    "# Second call is free -- all values are cached\n",
    "call_count = 0\n",
    "result = fibonacci(10)\n",
    "print(f\"\\nSecond call: fibonacci(10) = {result}\")\n",
    "print(f\"Function was called {call_count} times (all cache hits)\")\n",
    "print(f\"Cache info: {fibonacci.cache_info()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "# functools.cache (Python 3.9+): simpler unbounded cache\n",
    "# Equivalent to lru_cache(maxsize=None) but cleaner syntax\n",
    "@functools.cache\n",
    "def expensive_computation(x: int, y: int) -> int:\n",
    "    \"\"\"Simulate an expensive computation.\"\"\"\n",
    "    print(f\"  Computing {x} + {y}...\")\n",
    "    return x + y\n",
    "\n",
    "print(\"First calls (cache misses):\")\n",
    "print(f\"Result: {expensive_computation(1, 2)}\")\n",
    "print(f\"Result: {expensive_computation(3, 4)}\")\n",
    "\n",
    "print(\"\\nSecond calls (cache hits -- no 'Computing...' output):\")\n",
    "print(f\"Result: {expensive_computation(1, 2)}\")\n",
    "print(f\"Result: {expensive_computation(3, 4)}\")\n",
    "\n",
    "# Bounded cache example: only keep the last 2 results\n",
    "@functools.lru_cache(maxsize=2)\n",
    "def bounded_compute(x: int) -> int:\n",
    "    print(f\"  Computing for {x}...\")\n",
    "    return x * 10\n",
    "\n",
    "print(\"\\n--- Bounded LRU cache (maxsize=2) ---\")\n",
    "bounded_compute(1)  # miss\n",
    "bounded_compute(2)  # miss\n",
    "bounded_compute(1)  # hit\n",
    "bounded_compute(3)  # miss, evicts 2\n",
    "bounded_compute(2)  # miss again (was evicted)\n",
    "print(f\"Cache info: {bounded_compute.cache_info()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: functools.reduce\n",
    "\n",
    "`reduce` applies a two-argument function cumulatively to the items of a sequence,\n",
    "reducing it to a single value. It is the functional equivalent of a loop that accumulates a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import operator\n",
    "\n",
    "# reduce applies a function cumulatively: f(f(f(a, b), c), d)\n",
    "# Product of all numbers (1 * 2 * 3 * 4 * 5 = 120)\n",
    "product = functools.reduce(operator.mul, [1, 2, 3, 4, 5])\n",
    "print(f\"Product of [1,2,3,4,5] = {product}\")\n",
    "\n",
    "# Sum without using built-in sum()\n",
    "total = functools.reduce(operator.add, [10, 20, 30, 40])\n",
    "print(f\"Sum of [10,20,30,40] = {total}\")\n",
    "\n",
    "# With an initial value\n",
    "total_with_init = functools.reduce(operator.add, [1, 2, 3], 100)\n",
    "print(f\"Sum of [1,2,3] starting from 100 = {total_with_init}\")\n",
    "\n",
    "# Find the maximum value\n",
    "largest = functools.reduce(lambda a, b: a if a > b else b, [3, 1, 4, 1, 5, 9, 2, 6])\n",
    "print(f\"\\nLargest value: {largest}\")\n",
    "\n",
    "# Flatten a list of lists\n",
    "nested = [[1, 2], [3, 4], [5, 6]]\n",
    "flat = functools.reduce(operator.add, nested)\n",
    "print(f\"Flattened {nested} = {flat}\")\n",
    "\n",
    "# Build a dictionary from pairs\n",
    "pairs = [(\"a\", 1), (\"b\", 2), (\"c\", 3)]\n",
    "result = functools.reduce(lambda d, pair: {**d, pair[0]: pair[1]}, pairs, {})\n",
    "print(f\"Dict from pairs: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: functools.total_ordering\n",
    "\n",
    "`total_ordering` is a class decorator that automatically fills in missing comparison methods.\n",
    "You only need to define `__eq__` and one of `__lt__`, `__le__`, `__gt__`, or `__ge__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "@functools.total_ordering\n",
    "class Score:\n",
    "    \"\"\"A score with all comparison operators auto-generated.\"\"\"\n",
    "\n",
    "    def __init__(self, value: int) -> None:\n",
    "        self.value = value\n",
    "\n",
    "    def __eq__(self, other: object) -> bool:\n",
    "        if not isinstance(other, Score):\n",
    "            return NotImplemented\n",
    "        return self.value == other.value\n",
    "\n",
    "    def __lt__(self, other: \"Score\") -> bool:\n",
    "        return self.value < other.value\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Score({self.value})\"\n",
    "\n",
    "# Only __eq__ and __lt__ are defined, but all comparisons work\n",
    "s5 = Score(5)\n",
    "s10 = Score(10)\n",
    "s5b = Score(5)\n",
    "\n",
    "print(f\"{s5} < {s10}:  {s5 < s10}\")\n",
    "print(f\"{s10} > {s5}:  {s10 > s5}\")    # auto-generated\n",
    "print(f\"{s5} <= {s5b}: {s5 <= s5b}\")    # auto-generated\n",
    "print(f\"{s10} >= {s5}: {s10 >= s5}\")    # auto-generated\n",
    "print(f\"{s5} == {s5b}: {s5 == s5b}\")\n",
    "\n",
    "# Sorting works automatically\n",
    "scores = [Score(85), Score(92), Score(78), Score(95), Score(88)]\n",
    "print(f\"\\nSorted: {sorted(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: functools.wraps\n",
    "\n",
    "`wraps` is a decorator for decorators. It copies the metadata (`__name__`, `__doc__`, etc.)\n",
    "from the wrapped function to the wrapper, preventing metadata loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "\n",
    "# Without @wraps: metadata is lost\n",
    "def bad_timer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        elapsed = time.perf_counter() - start\n",
    "        print(f\"  {func.__name__} took {elapsed:.4f}s\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# With @wraps: metadata is preserved\n",
    "def good_timer(func):\n",
    "    @functools.wraps(func)  # <-- preserves metadata\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        elapsed = time.perf_counter() - start\n",
    "        print(f\"  {func.__name__} took {elapsed:.4f}s\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@bad_timer\n",
    "def process_bad(data: list[int]) -> int:\n",
    "    \"\"\"Process a list and return its sum.\"\"\"\n",
    "    return sum(data)\n",
    "\n",
    "@good_timer\n",
    "def process_good(data: list[int]) -> int:\n",
    "    \"\"\"Process a list and return its sum.\"\"\"\n",
    "    return sum(data)\n",
    "\n",
    "print(\"Without @wraps:\")\n",
    "print(f\"  Name: {process_bad.__name__}\")      # 'wrapper' (wrong!)\n",
    "print(f\"  Doc:  {process_bad.__doc__}\")        # None (lost!)\n",
    "\n",
    "print(\"\\nWith @wraps:\")\n",
    "print(f\"  Name: {process_good.__name__}\")      # 'process_good' (correct)\n",
    "print(f\"  Doc:  {process_good.__doc__}\")        # preserved\n",
    "\n",
    "# The decorated function still works\n",
    "print()\n",
    "process_good(list(range(1000000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: functools.singledispatch\n",
    "\n",
    "`singledispatch` transforms a function into a generic function that dispatches on the type\n",
    "of its first argument. This is Python's way of doing function overloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "# singledispatch: type-based function overloading\n",
    "@functools.singledispatch\n",
    "def format_value(value) -> str:\n",
    "    \"\"\"Format a value for display (default implementation).\"\"\"\n",
    "    return f\"Unknown: {value!r}\"\n",
    "\n",
    "@format_value.register(int)\n",
    "def _(value: int) -> str:\n",
    "    return f\"Integer: {value:,d}\"\n",
    "\n",
    "@format_value.register(float)\n",
    "def _(value: float) -> str:\n",
    "    return f\"Float: {value:.2f}\"\n",
    "\n",
    "@format_value.register(str)\n",
    "def _(value: str) -> str:\n",
    "    return f\"String: '{value}' (length={len(value)})\"\n",
    "\n",
    "@format_value.register(list)\n",
    "def _(value: list) -> str:\n",
    "    return f\"List with {len(value)} items: {value}\"\n",
    "\n",
    "# Dispatches based on the type of the first argument\n",
    "print(format_value(1234567))\n",
    "print(format_value(3.14159))\n",
    "print(format_value(\"hello world\"))\n",
    "print(format_value([1, 2, 3]))\n",
    "print(format_value({\"key\": \"value\"}))  # Falls back to default\n",
    "\n",
    "# Check registered implementations\n",
    "print(f\"\\nRegistered types: {list(format_value.registry.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practical example: memoized recursive computation\n",
    "import functools\n",
    "import time\n",
    "\n",
    "# Without memoization: exponential time complexity\n",
    "def fib_slow(n: int) -> int:\n",
    "    if n < 2:\n",
    "        return n\n",
    "    return fib_slow(n - 1) + fib_slow(n - 2)\n",
    "\n",
    "# With memoization: linear time complexity\n",
    "@functools.lru_cache(maxsize=128)\n",
    "def fib_fast(n: int) -> int:\n",
    "    if n < 2:\n",
    "        return n\n",
    "    return fib_fast(n - 1) + fib_fast(n - 2)\n",
    "\n",
    "# Compare performance\n",
    "start = time.perf_counter()\n",
    "result_slow = fib_slow(30)\n",
    "time_slow = time.perf_counter() - start\n",
    "\n",
    "start = time.perf_counter()\n",
    "result_fast = fib_fast(30)\n",
    "time_fast = time.perf_counter() - start\n",
    "\n",
    "print(f\"fib_slow(30) = {result_slow}, took {time_slow:.4f}s\")\n",
    "print(f\"fib_fast(30) = {result_fast}, took {time_fast:.6f}s\")\n",
    "print(f\"Speedup: {time_slow / time_fast:.0f}x faster with memoization\")\n",
    "\n",
    "# lru_cache can handle much larger inputs\n",
    "print(f\"\\nfib_fast(100) = {fib_fast(100)}\")\n",
    "print(f\"Cache info: {fib_fast.cache_info()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### functools.partial\n",
    "- Creates specialized versions of functions with pre-filled arguments\n",
    "- Useful for adapting functions to expected interfaces (e.g., `key=` functions)\n",
    "\n",
    "### functools.lru_cache / functools.cache\n",
    "- `lru_cache(maxsize=N)`: Bounded LRU memoization cache\n",
    "- `lru_cache(maxsize=None)` or `cache`: Unbounded memoization\n",
    "- Turns exponential-time recursion into linear-time with memoization\n",
    "- Use `.cache_info()` to inspect hit/miss statistics\n",
    "\n",
    "### functools.reduce\n",
    "- Cumulatively applies a binary function over a sequence\n",
    "- Useful with `operator` module functions (`operator.mul`, `operator.add`)\n",
    "- Supports an optional initial value\n",
    "\n",
    "### functools.total_ordering\n",
    "- Class decorator: define `__eq__` + one comparison, get all six\n",
    "- Enables sorting and all comparison operators automatically\n",
    "\n",
    "### functools.wraps\n",
    "- Always use in decorators to preserve function metadata\n",
    "- Copies `__name__`, `__doc__`, `__module__`, and other attributes\n",
    "\n",
    "### functools.singledispatch\n",
    "- Type-based function overloading (dispatch on first argument type)\n",
    "- Register implementations with `@func.register(type)`\n",
    "- Falls back to the base implementation for unregistered types"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}